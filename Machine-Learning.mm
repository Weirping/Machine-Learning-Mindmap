<map version="freeplane 1.9.0">
<!--To view this file, download free mind mapping software Freeplane from http://freeplane.sourceforge.net -->
<node TEXT="Machine Learning" LOCALIZED_STYLE_REF="AutomaticLayout.level.root" FOLDED="false" ID="ID_850448724" CREATED="1564976333940" MODIFIED="1584718021920" STYLE="bubble" SHAPE_HORIZONTAL_MARGIN="10 pt" SHAPE_VERTICAL_MARGIN="10 pt">
<hook NAME="accessories/plugins/AutomaticLayout.properties" VALUE="ALL"/>
<edge STYLE="sharp_bezier" COLOR="#808080" WIDTH="3"/>
<hook NAME="MapStyle">
    <conditional_styles>
        <conditional_style ACTIVE="true" LOCALIZED_STYLE_REF="AutomaticLayout.level.root" LAST="false">
            <node_level_condition VALUE="0" COMPARATION_RESULT="0" SUCCEED="true"/>
        </conditional_style>
        <conditional_style ACTIVE="true" LOCALIZED_STYLE_REF="AutomaticLayout.level,1" LAST="false">
            <node_level_condition VALUE="1" COMPARATION_RESULT="0" SUCCEED="true"/>
        </conditional_style>
    </conditional_styles>
    <properties fit_to_viewport="false" show_note_icons="true" edgeColorConfiguration="#808080ff,#ff0000ff,#0000ffff,#00ff00ff,#ff00ffff,#00ffffff,#7c0000ff,#00007cff,#007c00ff,#7c007cff,#007c7cff,#7c7c00ff"/>

<map_styles>
<stylenode LOCALIZED_TEXT="styles.root_node" STYLE="oval" UNIFORM_SHAPE="true" VGAP_QUANTITY="24 pt">
<font SIZE="24"/>
<stylenode LOCALIZED_TEXT="styles.predefined" POSITION="right" STYLE="bubble">
<stylenode LOCALIZED_TEXT="default" ID="ID_1003543353" ICON_SIZE="12 pt" COLOR="#000000" STYLE="fork">
<arrowlink SHAPE="CUBIC_CURVE" COLOR="#000000" WIDTH="2" TRANSPARENCY="200" DASH="" FONT_SIZE="9" FONT_FAMILY="SansSerif" DESTINATION="ID_1003543353" STARTARROW="NONE" ENDARROW="DEFAULT"/>
<font NAME="SansSerif" SIZE="10" BOLD="false" ITALIC="false"/>
<edge COLOR="#808080"/>
</stylenode>
<stylenode LOCALIZED_TEXT="defaultstyle.details"/>
<stylenode LOCALIZED_TEXT="defaultstyle.attributes">
<font SIZE="9"/>
</stylenode>
<stylenode LOCALIZED_TEXT="defaultstyle.note" COLOR="#000000" BACKGROUND_COLOR="#ffffff" TEXT_ALIGN="LEFT"/>
<stylenode LOCALIZED_TEXT="defaultstyle.floating">
<edge STYLE="hide_edge"/>
<cloud COLOR="#f0f0f0" SHAPE="ROUND_RECT"/>
</stylenode>
<stylenode LOCALIZED_TEXT="defaultstyle.selection" BACKGROUND_COLOR="#666666" STYLE="bubble" BORDER_COLOR_LIKE_EDGE="false" BORDER_COLOR="#4e85f8"/>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.user-defined" POSITION="right" STYLE="bubble">
<stylenode LOCALIZED_TEXT="styles.topic" COLOR="#000000" STYLE="fork">
<font NAME="Liberation Sans" SIZE="10" BOLD="true"/>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.subtopic" COLOR="#666666" STYLE="fork">
<font NAME="Liberation Sans" SIZE="10" BOLD="true"/>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.subsubtopic" COLOR="#000000">
<font NAME="Liberation Sans" SIZE="10" BOLD="true"/>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.important" COLOR="#cc0000">
<icon BUILTIN="yes"/>
</stylenode>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.AutomaticLayout" POSITION="right" STYLE="bubble">
<stylenode LOCALIZED_TEXT="AutomaticLayout.level.root" COLOR="#ffffff" BACKGROUND_COLOR="#666666" STYLE="oval" SHAPE_HORIZONTAL_MARGIN="10 pt" SHAPE_VERTICAL_MARGIN="10 pt">
<font SIZE="18" BOLD="true"/>
<edge STYLE="bezier" COLOR="#808080"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,1" COLOR="#000000">
<font SIZE="16" BOLD="true"/>
<edge STYLE="bezier" COLOR="#808080" WIDTH="3"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,2" COLOR="#333333">
<font SIZE="14" BOLD="true"/>
<edge STYLE="bezier" COLOR="#808080" WIDTH="2"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,3" COLOR="#333333">
<font SIZE="14" BOLD="false"/>
<edge STYLE="bezier" COLOR="#808080" WIDTH="1"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,4" COLOR="#333333">
<font SIZE="12" BOLD="false"/>
<edge STYLE="bezier" COLOR="#808080"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,5" COLOR="#333333" BORDER_COLOR_LIKE_EDGE="true">
<font SIZE="12" BOLD="false"/>
<edge STYLE="bezier" COLOR="#808080" WIDTH="1"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,6" COLOR="#333333">
<font BOLD="false"/>
<edge STYLE="bezier" COLOR="#808080" WIDTH="1"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,7" COLOR="#333333">
<font BOLD="false"/>
<edge STYLE="bezier" COLOR="#808080" WIDTH="1"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,8" COLOR="#333333">
<font BOLD="false"/>
<edge STYLE="bezier" COLOR="#808080" WIDTH="1"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,9" COLOR="#333333">
<font BOLD="false"/>
<edge STYLE="bezier" COLOR="#808080" WIDTH="1"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,10" COLOR="#333333">
<font BOLD="false"/>
<edge STYLE="bezier" COLOR="#808080" WIDTH="1"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,11" COLOR="#333333">
<font BOLD="false"/>
<edge STYLE="bezier" COLOR="#808080" WIDTH="1"/>
</stylenode>
</stylenode>
</stylenode>
</map_styles>
</hook>
<hook NAME="AutomaticEdgeColor" COUNTER="6" RULE="FOR_LEVELS"/>
<hook NAME="NodeConditionalStyles">
    <conditional_style ACTIVE="true" LOCALIZED_STYLE_REF="AutomaticLayout.level,1" LAST="false">
        <node_level_condition VALUE="1" COMPARATION_RESULT="0" SUCCEED="true"/>
    </conditional_style>
</hook>
<node TEXT="Mathematics" POSITION="left" ID="ID_1730054110" CREATED="1564977414620" MODIFIED="1584717762442">
<edge COLOR="#808080"/>
<node TEXT="Linear Algebra" FOLDED="true" ID="ID_1311644628" CREATED="1565660346602" MODIFIED="1584717762442">
<edge COLOR="#808080"/>
<node TEXT="Matrices" FOLDED="true" ID="ID_1374971143" CREATED="1565660355600" MODIFIED="1584717762443">
<edge COLOR="#808080"/>
<node TEXT="Basic Operations: Addition, Multiplication,Transposition" ID="ID_1819374372" CREATED="1565660405700" MODIFIED="1584717762443">
<edge COLOR="#808080"/>
</node>
<node TEXT="Transformations" ID="ID_1795107484" CREATED="1565660405708" MODIFIED="1584717762444">
<edge COLOR="#808080"/>
</node>
<node TEXT="Trace, Rank, Determinante, Inverse" ID="ID_1547532273" CREATED="1565660405711" MODIFIED="1584717762444">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Tensors" FOLDED="true" ID="ID_300294665" CREATED="1565661386559" MODIFIED="1584717762444">
<edge COLOR="#808080"/>
<node TEXT="For Machine Learning purposes, a Tensor can be described as a Multidimentional Matrix. Depending on the dimensions, the Tensor can be a Scalar, a Vector, a Matrix, or a Multidimentional Matrix." ID="ID_420175291" CREATED="1565661411995" MODIFIED="1584717762445">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Jacobian Matrix and Hessian Matrix" ID="ID_282915116" CREATED="1565660895700" MODIFIED="1584717762447">
<edge COLOR="#808080"/>
</node>
<node TEXT="Eigenvectors and Eigenvalues" ID="ID_341881898" CREATED="1565937462670" MODIFIED="1584717762447">
<edge COLOR="#808080"/>
</node>
<node TEXT="Derivatives Chain Rule" FOLDED="true" ID="ID_429105437" CREATED="1565660702824" MODIFIED="1584717762448">
<edge COLOR="#808080"/>
<node TEXT="Rule \\&#xa;$F&apos;(x)=f&apos;(g(x))g&apos;(x)$" FOLDED="true" ID="ID_1889400901" CREATED="1565660712817" MODIFIED="1584717762448" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="Leibniz Notation \\&#xa;$\frac{dz}{dx}=\frac{dz}{dy}\frac{dy}{dx}$" ID="ID_1281743668" CREATED="1565660757720" MODIFIED="1584717762449" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Gradient" FOLDED="true" ID="ID_1969363209" CREATED="1565661300239" MODIFIED="1584717762450">
<edge COLOR="#808080"/>
<node TEXT="The gradient is a multi-variable generalization of the derivative. The gradient is a vector-valued function, as opposed to a derivative, which is scalar-valued." ID="ID_1009261393" CREATED="1565661354306" MODIFIED="1584717762450">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Curse of Dimensionality" FOLDED="true" ID="ID_1125480916" CREATED="1565661437828" MODIFIED="1584717762452">
<edge COLOR="#808080"/>
<node TEXT="When the dimensionality increases, the volume of the space increases so fast that the available data become sparse. This sparsity is problematic for any method that requires statistical significance. In order to obtain a statistically sound and reliable result, the amount of data needed to support the result often grows exponentially with the dimensionality." ID="ID_580713488" CREATED="1565661489944" MODIFIED="1584717762452">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Statistics" FOLDED="true" ID="ID_894832431" CREATED="1565942510925" MODIFIED="1614644756826">
<edge COLOR="#808080"/>
<node TEXT="Central Tendency" FOLDED="true" ID="ID_1461781768" CREATED="1565796221390" MODIFIED="1584717762454">
<edge COLOR="#808080"/>
<node TEXT="Median" ID="ID_1898127788" CREATED="1565796281017" MODIFIED="1584717762454">
<edge COLOR="#808080"/>
</node>
<node TEXT="middle" ID="ID_1601941248" CREATED="1565796281017" MODIFIED="1584717762454">
<edge COLOR="#808080"/>
</node>
<node TEXT="Mode" ID="ID_1616754651" CREATED="1565796281017" MODIFIED="1584717762454">
<edge COLOR="#808080"/>
</node>
<node TEXT="Quantile" ID="ID_673888634" CREATED="1565796281017" MODIFIED="1584717762455">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Dispersion / Spread Tendency" FOLDED="true" ID="ID_629352247" CREATED="1565661521053" MODIFIED="1584717762455">
<edge COLOR="#808080"/>
<node TEXT="Range" ID="ID_1077994349" CREATED="1565796316141" MODIFIED="1584717762455">
<edge COLOR="#808080"/>
</node>
<node TEXT="Medium Absolute Deviation (MAD)" FOLDED="true" ID="ID_269929098" CREATED="1565796380759" MODIFIED="1584717762455">
<edge COLOR="#808080"/>
<node TEXT="The average of the absolute value of the deviation of each value from the mean" ID="ID_1865015919" CREATED="1565796380759" MODIFIED="1584717762456">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Inter-quartile Range (IQR)" ID="ID_565130437" CREATED="1565796430635" MODIFIED="1584717762457">
<edge COLOR="#808080"/>
</node>
<node TEXT="Variance" FOLDED="true" ID="ID_626074632" CREATED="1565796447230" MODIFIED="1584717762457">
<edge COLOR="#808080"/>
<node TEXT="Continuous \\&#xa;Var(X)=\sigma^2=\int(x-\mu)^2f(x)dx = \int x^2f(x)dx - \mu^2" ID="ID_1222647673" CREATED="1565796592733" MODIFIED="1584717762458" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="Discrete \\&#xa;$Var(X)=\frac{1}{n}\sum_{i=1}^n(x_i-\mu)^2$" ID="ID_766719514" CREATED="1565796652455" MODIFIED="1584717762459" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Standard Deviation" FOLDED="true" ID="ID_1512366963" CREATED="1565796796432" MODIFIED="1584717762460">
<edge COLOR="#808080"/>
<node TEXT="\sigma=\sqrt{\frac{1}{n}\sum_{i=1}^n(x_i-\mu)^2}" ID="ID_896100696" CREATED="1565796874499" MODIFIED="1584717762460" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Skewness" FOLDED="true" ID="ID_1653391621" CREATED="1565797086016" MODIFIED="1584717762461" LINK="https://weirping.github.io/blog/Skewness-and-Kurtosis.html">
<edge COLOR="#808080"/>
<node TEXT="三阶中心距除以标准差的三次方。描述分布偏离对称性程度的一个特征数" ID="ID_1047846919" CREATED="1565797300288" MODIFIED="1584717762461">
<edge COLOR="#808080"/>
</node>
<node TEXT="skew.png" ID="ID_52700205" CREATED="1587101180563" MODIFIED="1587101180567">
<hook URI="Machine-Learning_files/skew.png" SIZE="0.90361446" NAME="ExternalObject"/>
</node>
<node TEXT="随机变量 \\&#xa;\mathrm{Skew}(\mathbf{X}) = E[(\frac{\mathbf{X}-\mu}{\sigma})^3] = \frac{E[(\mathbf{X}-\mu)^3]}{(E[(\mathbf{X}-\mu)^2])^{3/2}}=\frac{k_3}{k_2^{3/2}}" ID="ID_1899749159" CREATED="1565797172380" MODIFIED="1584717762465" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="样本 \\&#xa;\mathrm{SK} =\frac{m_3}{m_2^{3/2}} = \frac{\frac{1}{n}\sum(x_i-\bar x)^3}{[\frac{1}{n}\sum(x_i-\bar x)^2]^{3/2}}" ID="ID_464605053" CREATED="1565797216568" MODIFIED="1584717762467" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Kurtosis" FOLDED="true" ID="ID_637256776" CREATED="1565797116734" MODIFIED="1584717762468" LINK="https://weirping.github.io/blog/Skewness-and-Kurtosis.html">
<edge COLOR="#808080"/>
<node TEXT="四阶中心矩除以标准差的平方 减去三。 用来反映频数分布曲线顶端尖峭或扁平程度的指标" ID="ID_728818179" CREATED="1565797333299" MODIFIED="1584717762468">
<edge COLOR="#808080"/>
</node>
<node TEXT="kurtosis2.jpg" ID="ID_1149276803" CREATED="1587101197447" MODIFIED="1587101197455">
<hook URI="Machine-Learning_files/kurtosis2.jpg" SIZE="1.0" NAME="ExternalObject"/>
</node>
<node TEXT="随机变量 \\&#xa;\mathrm{Kurtosis}(\mathbf{X}) = E[(\frac{\mathbf{X}-\mu}{\sigma})^4] = \frac{E[(\mathbf{X}-\mu)^4]}{(E[(\mathbf{X}-\mu)^2])^{2}}" ID="ID_1918526915" CREATED="1565797567674" MODIFIED="1584717762473" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="样本 \\&#xa;\mathrm{K} =\frac{m_4}{m_2^{2}} - 3 = \frac{\frac{1}{n}\sum(x_i-\bar x)^4}{[\frac{1}{n}\sum(x_i-\bar x)^2]^{2}} -3" ID="ID_1531282203" CREATED="1565797588988" MODIFIED="1584717762475" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Relationship" FOLDED="true" ID="ID_1521377999" CREATED="1565661526690" MODIFIED="1614644756823">
<edge COLOR="#808080"/>
<node TEXT="Correlation" FOLDED="true" ID="ID_386009637" CREATED="1565797736696" MODIFIED="1584717762477">
<edge COLOR="#808080"/>
<node TEXT="Pearson" FOLDED="true" ID="ID_1183090718" CREATED="1565797987511" MODIFIED="1584717762477" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="Correlation \\&#xa;总体: $\rho _{X,Y}=\frac {cov (X,Y)}{\sigma _{X}\sigma _{Y}}$ \\&#xa;样本: $r=\frac {\sum _{i=1}^n (x_{i}- \bar x)(y_{i}-\bar y)}    {\sqrt {\sum _{i=1}^n (x_{i}-\bar x)^2} \sqrt {\sum _{i=1}^n (y_{i}-\bar y)^2}} $" FOLDED="true" ID="ID_302710005" CREATED="1566485220986" MODIFIED="1584717762477" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="Covariance" FOLDED="true" ID="ID_1924889898" CREATED="1565797720135" MODIFIED="1584717762479">
<edge COLOR="#808080"/>
<node TEXT="总体:$Cov(X,Y)=E\{[X-E(X)][Y-E(Y)]\}$ \\&#xa;样本:$Cov(x,y)=\frac{1}{n}\sum_{i=1}^n(x_i - \bar x)(y_i - \bar y)$" ID="ID_1442962598" CREATED="1565797874987" MODIFIED="1584717762479" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node ID="ID_1377401964" CREATED="1565798219216" MODIFIED="1584717762480"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <p>
      Benchmarks linear relationship, most appropriate for measurements taken from an <b>interval scale</b>, is a measure of the linear dependence between two variables
    </p>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Spearman" FOLDED="true" ID="ID_1549961769" CREATED="1565797998150" MODIFIED="1584717762480">
<edge COLOR="#808080"/>
<node ID="ID_1561185818" CREATED="1565798185607" MODIFIED="1584717762480"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <p>
      Benchmarks monotonic relationship (whether linear or not), Spearman's coefficient is appropriate for both <b>continuous</b>&#160;and <b>discrete</b>&#160; variables, including <b>ordinal</b>&#160;variables.
    </p>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Kendall" FOLDED="true" ID="ID_931141843" CREATED="1565798159017" MODIFIED="1584717762480">
<edge COLOR="#808080"/>
<node ID="ID_1744338986" CREATED="1565798159017" MODIFIED="1584717762480"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <p>
      Is a statisticused to measure the <b>ordinal</b>&#160;association between two measured quantities.
    </p>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
</node>
<node TEXT="Contrary to the Spearman correlation, the Kendall correlation is not affected by how far from each other ranks are but only by whether the ranks between observations are equal or not, and is thus only appropriate for discrete variablesbut not defined for continuous variables." ID="ID_122356277" CREATED="1565798159017" MODIFIED="1584717762481">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Co-occurrence" ID="ID_1067604693" CREATED="1565797753361" MODIFIED="1584717762482">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Techniques" FOLDED="true" ID="ID_1271513154" CREATED="1565661535190" MODIFIED="1584717762482">
<edge COLOR="#808080"/>
<node TEXT="Hypothesis Test" FOLDED="true" ID="ID_1187417084" CREATED="1565798744805" MODIFIED="1584717762482" LINK="https://weirping.github.io/blog/hypothesis-testing.html">
<edge COLOR="#808080"/>
<node TEXT="Chi-Square Test" ID="ID_1414711160" CREATED="1566053977539" MODIFIED="1584717762482" LINK="https://weirping.github.io/blog/Chi-Square-Test.html">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="p-value" FOLDED="true" ID="ID_1926704353" CREATED="1565798744805" MODIFIED="1584717762482">
<edge COLOR="#808080"/>
<node TEXT="Five heads in a row Example" FOLDED="true" ID="ID_1673775500" CREATED="1565798744805" MODIFIED="1584717762482">
<edge COLOR="#808080"/>
<node TEXT="This demonstrates that specifying a direction (on a symmetric test statistic) halves the p-value (increases the significance) and can mean the difference between data being considered significant or not." ID="ID_1494945325" CREATED="1565798744805" MODIFIED="1584717762484">
<edge COLOR="#808080"/>
</node>
<node TEXT="Suppose a researcher flips a coin five times in a row and assumes a null hypothesis that the coin is fair. The test statistic of &quot;total number of heads&quot; can be one-tailed or two-tailed: a one-tailed test corresponds to seeing if the coin is biased towards heads, but a two-tailed test corresponds to seeing if the coin is biased either way. The researcher flips the coin five times and observes heads each time (HHHHH), yielding a test statistic of 5. In a one-tailed test, this is the upper extreme of all possible outcomes, and yields a p-value of (1/2)5 = 1/32 ≈0.03. If the researcher assumed a significance level of 0.05, this result would be deemed significant and the hypothesis that the coin is fair would be rejected. In a two-tailed test, a test statistic of zero heads (TTTTT) is just as extreme and thus the data of HHHHH would yield a p-value of 2×(1/2)5 = 1/16 ≈0.06, which is not significant at the 0.05 level." ID="ID_191318937" CREATED="1565798744805" MODIFIED="1584717762486">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="In this method, as part of experimental design, before performing the experiment, one first chooses a model (the null hypothesis) and a threshold value for p, called the significance level of the test, traditionally 5% or 1% and denoted as α. If the p-value is less than the chosen significance level (α), that suggests that the observed data is sufficiently inconsistent with the null hypothesis that the null hypothesis may be rejected. However, that does not prove that the tested hypothesis is true. For typical analysis, using the standard α = 0.05 cutoff, the null hypothesis is rejected when p &lt; .05 and not rejected when p &gt; .05. The p-value does not, in itself, support reasoning about the probabilities of hypotheses but is only a tool for deciding whether to reject the null hypothesis." FOLDED="true" ID="ID_1354474469" CREATED="1565798744805" MODIFIED="1584717762487">
<edge COLOR="#808080"/>
<node TEXT="p-value.png" ID="ID_1178872914" CREATED="1587101215762" MODIFIED="1587101215765">
<hook URI="Machine-Learning_files/p-value.png" SIZE="0.7751938" NAME="ExternalObject"/>
</node>
</node>
</node>
<node TEXT="p-hacking" FOLDED="true" ID="ID_1739850800" CREATED="1565798744805" MODIFIED="1584717762489">
<edge COLOR="#808080"/>
<node TEXT="The process of data mining involves automatically testing huge numbers of hypotheses about a single data setby exhaustively searching for combinations of variables that might show a correlation. Conventional tests of statistical significanceare based on the probability that an observation arose by chance, and necessarily accept some risk of mistaken test results, called the significance." ID="ID_1927063317" CREATED="1565798744805" MODIFIED="1584717762489">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Central Limit Theorem" FOLDED="true" ID="ID_1711043029" CREATED="1565661545578" MODIFIED="1584717762490">
<edge COLOR="#808080"/>
<node TEXT="States that a random variable defined as the average of a large number of independent and identically distributed random variables is itself approximately normally distributed." ID="ID_1274202752" CREATED="1565799249327" MODIFIED="1584717762491">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Probability" FOLDED="true" ID="ID_1635346369" CREATED="1565661863098" MODIFIED="1584717762491">
<edge COLOR="#808080"/>
<node TEXT="Distributions" FOLDED="true" ID="ID_1817553339" CREATED="1565661876332" MODIFIED="1584717762492">
<edge COLOR="#808080"/>
<node TEXT="Types" FOLDED="true" ID="ID_856618900" CREATED="1565950139117" MODIFIED="1584717762492">
<edge COLOR="#808080"/>
<node TEXT="Normal (Gaussian)" ID="ID_1410543550" CREATED="1565950182551" MODIFIED="1584717762492">
<edge COLOR="#808080"/>
</node>
<node TEXT="Poisson" ID="ID_1387228928" CREATED="1565950182551" MODIFIED="1584717762493" LINK="https://weirping.github.io/blog/exponential-distribution-and-poisson-distribution.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="exponential" ID="ID_282563771" CREATED="1566486631563" MODIFIED="1584717762494" LINK="https://weirping.github.io/blog/exponential-distribution-and-poisson-distribution.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="Uniform" ID="ID_1166879907" CREATED="1565950182552" MODIFIED="1584717762495">
<edge COLOR="#808080"/>
</node>
<node TEXT="Gamma" ID="ID_1863890725" CREATED="1565950182552" MODIFIED="1584717762496">
<edge COLOR="#808080"/>
</node>
<node TEXT="Bernoulli-Binomial-Beta&#xa;Multinoulli-Multinomial-Dirichlet" ID="ID_1834507281" CREATED="1578997638722" MODIFIED="1584717762497" LINK="https://weirping.github.io/blog/Binomial-Beta-Multinomial-Dirichlet.html">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Independence" FOLDED="true" ID="ID_1762221311" CREATED="1565942792084" MODIFIED="1584717762498">
<edge COLOR="#808080"/>
<node TEXT="定义：P(A|B)=P(A) \\&#xa;定义(推论)：P(AB)=P(A)P(B)" ID="ID_1567904177" CREATED="1565942826918" MODIFIED="1584717762498" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="conditional independence" FOLDED="true" ID="ID_1242353026" CREATED="1565943091117" MODIFIED="1584717762500" LINK="https://weirping.github.io/blog/Conditional-Independence.html">
<edge COLOR="#808080"/>
<node TEXT="定义:p(a| b, c) = p(a |c) \\&#xa;推论:p(a,b|c) = p(a|b,c)p(b|c) = p(a|c)p(b|c)" ID="ID_786526918" CREATED="1565943193718" MODIFIED="1584717762500" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="贝叶斯网条件独立性（D-separation）" ID="ID_1092249101" CREATED="1565943362118" MODIFIED="1584717762501">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Conditionality(product rule)" FOLDED="true" ID="ID_859548736" CREATED="1565942863523" MODIFIED="1584717762501">
<edge COLOR="#808080"/>
<node TEXT="p(X,Y)=p(X|Y)p(Y)" ID="ID_1522382267" CREATED="1565942882858" MODIFIED="1584717762501" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="Chain Rule" FOLDED="true" ID="ID_128098832" CREATED="1565944760535" MODIFIED="1584717762502">
<edge COLOR="#808080"/>
<node TEXT="$\mathbf{P}(\bigcap_{k=1}^n A_k)=\prod_{k=1}^n\mathbf{P}(A_{k}| \bigcap _{j=i}^{k-1}A_j)$" FOLDED="true" ID="ID_516634206" CREATED="1565948385460" MODIFIED="1584717762502" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="$ \mathbf{P}(A_4,A_3,A_2,A_1)=\mathbf{P}(A_4 | A_3,A_2,A_1)\mathbf{P}(A_3 | A_2,A_1)\mathbf{P}(A_2 | A_1)\mathbf{P}(A_1) $" ID="ID_651066745" CREATED="1565948664752" MODIFIED="1584717762502" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Law of Total Probability(sum rule)" FOLDED="true" ID="ID_628451367" CREATED="1565944412920" MODIFIED="1584717762503">
<edge COLOR="#808080"/>
<node TEXT="$ P (A) = \sum _{n} P (A\cap B_{n}) \\&#xa;or \\&#xa;P(A)=\sum _{n} P (A|B_{n}) P (B_{n}) $" ID="ID_1204922862" CREATED="1565944690998" MODIFIED="1584717762503" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Marginalisation(sum rule)" FOLDED="true" ID="ID_1521692155" CREATED="1565944171139" MODIFIED="1584717762503">
<edge COLOR="#808080"/>
<node TEXT="$p(x) = \sum _{y}p(x,y)$" ID="ID_194595727" CREATED="1565944324371" MODIFIED="1584717762504" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="$p(x)= \int_{y} p(xy)dy$" ID="ID_788331996" CREATED="1565944336129" MODIFIED="1584717762504" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Bayesian" FOLDED="true" ID="ID_361675419" CREATED="1576569158011" MODIFIED="1584717762504">
<edge COLOR="#808080"/>
<node TEXT="Frequentist vs Bayesian Probability" ID="ID_1904146284" CREATED="1565942708927" MODIFIED="1584717762504" LINK="https://weirping.github.io/blog/Bayesian-Probabilities-in-ML.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="Bayes Theorem" FOLDED="true" ID="ID_1648172527" CREATED="1565943469307" MODIFIED="1584717762505">
<edge COLOR="#808080"/>
<node TEXT="Simple Form \\&#xa;P(A|B)=\frac{P(B|A)P(A)}{P(B)}" FOLDED="true" ID="ID_1606523150" CREATED="1565943560974" MODIFIED="1584717762506" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="With Law of Total probability \\&#xd;&#xa;$P(B)=\sum_{j} P(B|A_{j})P(A_{j}) \\&#xd;&#xa;\Rightarrow P(A_{i}|B) = \frac{P(B|A_i)P(A_i)}{\sum_j P(B|A_j)P(A_j)}$" ID="ID_1989596471" CREATED="1565943954211" MODIFIED="1584717762506" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Bayesian Inference \\&#xa;$p(\mathrm{w}|\mathcal{D})=\frac{p(\mathcal{D}|\mathrm{w})p(\mathrm{w})}{p(\mathcal{D})}$" FOLDED="true" ID="ID_106484071" CREATED="1565948762138" MODIFIED="1584717762507" LINK="https://weirping.github.io/blog/Bayesian-Probabilities-in-ML.html" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="贝叶斯学派认为模型中的参数\mathrm w是一个不确定的值，使用概率分布对 \\ &#xa;其进行建模。首先我们对\mathrm{w}可能的分布做一个假设，这个假设是基于 \\&#xa;经验的、和观测数据无关的，这个分布即为先验分布p(\mathrm{w})。\\&#xa;依据训练数据集纠正后的\mathrm{w}的概率分布为后验分布p(\mathrm{w} | D)。\\&#xa;按照贝叶斯公式对后验概率分解，即：\\&#xa;&#xa;$p(\mathrm{w}|\mathcal{D})=\frac{p(\mathcal{D}|\mathrm{w})p(\mathrm{w})}{p(\mathcal{D})}$ \\&#xa;&#xa;\mathrm{w}的后验分布p(\mathrm{w}| D)可以分解为三部分: \\&#xa;1. p(\mathrm{w}) ：先验分布（prior），是关于\mathrm{w}的函数，依赖于先验知识。 \\&#xa;2. p(\mathcal{D}|\mathrm{w}) ：似然函数（likelihood），是关于\mathrm{w}的函数。 表示对于\mathrm{w}的不同值，数据集\mathcal D被观测到的概率。 \\&#xa;note，似然函数不是关于\mathrm{w}的概率分布函数，所以似然函数对w积分不是1，实际上是\mathcal D的概率分布函数。 \\&#xa;3. p(\mathcal{D}) ：归一化项，用于保证公式右边对\mathrm{w}积分是1，即，保证后验分布是一个概率密度函数。\\&#xa;p(\mathcal{D})=\int p(\mathcal{D}|\mathrm{w})p(\mathrm{w})\mathrm{dw}。" ID="ID_1485186110" CREATED="1565948987809" MODIFIED="1584717762507" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Optimization" FOLDED="true" ID="ID_1610238833" CREATED="1565661574532" MODIFIED="1584717762515">
<edge COLOR="#808080"/>
<node TEXT="Lagrange Duality" ID="ID_446260867" CREATED="1565937195940" MODIFIED="1584717762515" LINK="https://weirping.github.io/blog/Lagrange-Duality.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="Lagrange Multiplier and KKT Conditions" FOLDED="true" ID="ID_395919799" CREATED="1565937272197" MODIFIED="1584717762516" LINK="https://weirping.github.io/blog/from-Lagrange-Multiplier-to-KKT-Conditions.html">
<edge COLOR="#808080"/>
<node TEXT="拉格朗日乘数法(Lagrange multiplier)是用于解决只含等式约束的非线性规划问题的。" ID="ID_1172770841" CREATED="1589793180807" MODIFIED="1589793196937">
<edge COLOR="#808080"/>
</node>
<node TEXT="KKT条件是用于解决包含不等式约束问题的。" ID="ID_561737218" CREATED="1589793190130" MODIFIED="1589793196938">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="EM algorithm" FOLDED="true" ID="ID_1810045048" CREATED="1566576377579" MODIFIED="1584717762516" LINK="https://weirping.github.io/blog/EM-algorithm.html">
<edge COLOR="#808080"/>
<node TEXT="Jensen&apos;s Inequality" ID="ID_894214593" CREATED="1568970426145" MODIFIED="1584717762516" LINK="https://weirping.github.io/blog/Jensen-Inequality.html">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Methods" FOLDED="true" ID="ID_170677856" CREATED="1566488011347" MODIFIED="1584717762516">
<edge COLOR="#808080"/>
<node TEXT="Gradient Descent" ID="ID_579849081" CREATED="1565661589195" MODIFIED="1584717762516">
<edge COLOR="#808080"/>
</node>
<node TEXT="Newton Method" ID="ID_568823794" CREATED="1565799372620" MODIFIED="1584717762516" LINK="https://weirping.github.io/blog/Newton-Methods.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="Stochastic Gradient Descent (SGD)" ID="ID_1652332129" CREATED="1565661596026" MODIFIED="1584717762516">
<edge COLOR="#808080"/>
</node>
<node TEXT="Mini-batch Stochastic Gradient Descent" ID="ID_1232771098" CREATED="1565661605849" MODIFIED="1584717762516">
<edge COLOR="#808080"/>
</node>
<node TEXT="Momentum" FOLDED="true" ID="ID_380111363" CREATED="1565661611969" MODIFIED="1584717762516">
<edge COLOR="#808080"/>
<node TEXT="Idea: Add a fraction v of previous update to current one. When the gradient keeps pointing in the same direction, this willincrease the size of the steps taken towards the minimum." ID="ID_368549926" CREATED="1565799496946" MODIFIED="1584717762516">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Adagrad" FOLDED="true" ID="ID_1275639880" CREATED="1565661617553" MODIFIED="1584717762517">
<edge COLOR="#808080"/>
<node TEXT="Adaptive learning rates for each parameter" ID="ID_185660184" CREATED="1565799451475" MODIFIED="1584717762517">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Information Theory" FOLDED="true" ID="ID_817448982" CREATED="1566574729957" MODIFIED="1584717762517">
<edge COLOR="#808080"/>
<node TEXT="Information Theory Basic" FOLDED="true" ID="ID_972456026" CREATED="1565661891464" MODIFIED="1584717762518" LINK="https://weirping.github.io/blog/Points-in-Information-Theory.html">
<edge COLOR="#808080"/>
<node TEXT="信息量" FOLDED="true" ID="ID_1594780249" CREATED="1565951104629" MODIFIED="1584717762518">
<edge COLOR="#808080"/>
<node TEXT="$I(x)=-\log_{2}p(x)$" ID="ID_455533904" CREATED="1565951115052" MODIFIED="1584717762518" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="entropy" FOLDED="true" ID="ID_835099495" CREATED="1565951124364" MODIFIED="1584717762518">
<edge COLOR="#808080"/>
<node TEXT="$H(X)=-\sum_{k=1}^Kp(X=k) \log p(X=k)$" ID="ID_1946701572" CREATED="1565951134411" MODIFIED="1584717762518" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="联合熵" FOLDED="true" ID="ID_487700038" CREATED="1565951228845" MODIFIED="1584717762518">
<edge COLOR="#808080"/>
<node TEXT="$H(X,Y)=-\sum_{x \in X} \sum_{y \in Y} p(x, y) \log p(x, y)$" ID="ID_1698858939" CREATED="1565951243117" MODIFIED="1584717762518" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="条件熵" FOLDED="true" ID="ID_1958739994" CREATED="1565951269496" MODIFIED="1584717762519">
<edge COLOR="#808080"/>
<node TEXT="$H(Y|X)  =\sum_{x \in X} p(x)H(y|X=x)                        \\&#xa;        =-\sum_{x \in X} \sum_{y \in Y} p(x, y) \log p(y|x) \\&#xa;        =E[-\log (y \mid x)]  $" FOLDED="true" ID="ID_1626006072" CREATED="1565951289635" MODIFIED="1584717762519" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="链式规则" FOLDED="true" ID="ID_1684960473" CREATED="1565951331693" MODIFIED="1584717762519">
<edge COLOR="#808080"/>
<node TEXT="$H(X, Y) = H(Y|X) + H(X)$ \\&#xa;$H(X_1, X_2, X_3) = H(X_1) + H(X_2 \mid X_1) + H(X_3 \mid X_1, X_2) $" ID="ID_506161410" CREATED="1565951351921" MODIFIED="1584717762519" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="cross entropy" FOLDED="true" ID="ID_1898537722" CREATED="1565951439973" MODIFIED="1584717762520">
<edge COLOR="#808080"/>
<node TEXT="$H(X,q)=-\sum_{x \in X}p(x) \log q(x)$" FOLDED="true" ID="ID_1773694158" CREATED="1565951450032" MODIFIED="1584717762520" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="交叉熵可以看作是当用模型 $q$ 编码来自模型 $p$ 的变量时所需的平均bits(如果$\log$以2为底的话)" ID="ID_1141386309" CREATED="1565951508509" MODIFIED="1585637807722" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="熵率" FOLDED="true" ID="ID_642211385" CREATED="1565951535175" MODIFIED="1584717762521">
<edge COLOR="#808080"/>
<node TEXT="当如下极限存在时, 随机过程 $\{X_i\}$ 的熵率定义为: \\&#xa;$H(\chi) = \lim_{n \to \infty} \frac 1nH(x_1, x_2, \dots, x_n)$ \\&#xa;熵率 可以理解为 随机过程的 &quot;熵&quot;" ID="ID_626365542" CREATED="1565951565867" MODIFIED="1585635878424" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="相对熵(KL距离)" FOLDED="true" ID="ID_1601984795" CREATED="1565951629264" MODIFIED="1584717762523">
<edge COLOR="#808080"/>
<node TEXT="设$p(x)$ 是随机变量X的真实分布密度, $q(x)$是通过统计手段得到的X的近似分布, 则二者间相对熵定义为: \\&#xa;$D_{KL}(p||q)=-\sum_{k=1}^Kp_k \log \frac{p_k}{q_k}$ \\&#xa;$=\sum_{k}{p_k} \log{p_k} -\sum_kp_k \log q_k=-H(p)+H(p,q)$" FOLDED="true" ID="ID_766915900" CREATED="1565951665202" MODIFIED="1584717762523" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="1. 相对熵描述同一个随机变量的不同分布的差异" ID="ID_1611367295" CREATED="1565951860037" MODIFIED="1585636144979">
<edge COLOR="#808080"/>
</node>
<node TEXT="2. 相对熵描述了因为错用分布密度而增加的信息量" ID="ID_997978990" CREATED="1565951874526" MODIFIED="1585636157580">
<edge COLOR="#808080"/>
</node>
<node TEXT="3. 用模型$q$编码来自模型$p$的变量所需的额外bits！" ID="ID_242627137" CREATED="1565951874522" MODIFIED="1585636183987" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="4. 因为是“额外的”, 所以 KL的距离的值一定大于$0$, $D_{KL}=0$当且仅当$p=q$." ID="ID_333377709" CREATED="1565951874519" MODIFIED="1585636203637" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="pointwise mutual information(PMI)" FOLDED="true" ID="ID_1875802136" CREATED="1565952120368" MODIFIED="1584717762532">
<edge COLOR="#808080"/>
<node TEXT="$PMI(x,y)=\log \frac{p(x,y)}{p(x)p(y)}=\log \frac{p(x|y)}{p(x)}=\log \frac{p(y|x)}{p(y)}$" ID="ID_1691986716" CREATED="1585638519993" MODIFIED="1585638550236" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="PMI衡量了 $p(x,y)$ 和 $p(x)p(y)$ 的差异性, 即:  the discrepancy between these events occuring together compared to what would be expected by chance." ID="ID_596647503" CREATED="1585638599201" MODIFIED="1585638692409" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="Mutual Information(MI) 实际上是PMI的期望" ID="ID_1882464921" CREATED="1585638729106" MODIFIED="1585638763954">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Mutual Information" FOLDED="true" ID="ID_372405585" CREATED="1565951897781" MODIFIED="1584717762531">
<edge COLOR="#808080"/>
<node TEXT="[数学定义]一个随机变量由于已知另一个随机变量而减少的不确定性. \\&#xa;$I(X; Y)  = H(X) - H(X \mid Y)=H(Y) - H(Y \mid X) \\&#xa;         = H(X) + H(Y) - H(X, Y) \\&#xa;         = H(X, Y) - H(X \mid Y) - H(Y \mid X) $" ID="ID_1928265641" CREATED="1565951925181" MODIFIED="1585638435163" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="[推导]互信息使用相对熵度量$ p(x,y)$与$p(x)p(y)$之间的关系： \\&#xa;$$I(X; Y) = D_{KL}(p(X,Y)||p(X)p(Y))= - \sum_{x \in X}\sum_{y \in Y}p(x,y)\log \frac{p(x,y)}{p(x)p(y)}$$ \\&#xa;如X和Y互相独立, $p(x,y)=p(x)p(y)$, 对数项为0  则 $I(X, Y) = 0$. 反之 两个变量相关性越强, 则$I(X, Y)$ 越大." ID="ID_1308041011" CREATED="1585638033101" MODIFIED="1585638469426" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="cond-joint-entropy.png" ID="ID_1621817078" CREATED="1587101244974" MODIFIED="1587101244976">
<hook URI="Machine-Learning_files/cond-joint-entropy.png" SIZE="1.0" NAME="ExternalObject"/>
</node>
</node>
<node TEXT="maximal information coefficient(MIC)" FOLDED="true" ID="ID_174098236" CREATED="1565952142277" MODIFIED="1584717762532">
<edge COLOR="#808080"/>
<node FOLDED="true" ID="ID_782398671" CREATED="1565952224735" MODIFIED="1585640501210"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <p>
      &#29992;&#20110;&#34913;&#37327;&#20004;&#20010;&#21464;&#37327;X&#21644;Y&#30340;&#30456;&#20851;&#24615;&#24378;&#24230;:
    </p>
    <p>
      - &#32447;&#24615;&#20851;&#31995;
    </p>
    <p>
      <b>- &#38750;&#32447;&#24615;</b>&#30340;&#24378;&#24230;&#12290;
    </p>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
<node TEXT="不仅可以发现变量间的线性函数关系，还能发现非线性关系(如指数的，周期的)；" ID="ID_1165439799" CREATED="1585640523756" MODIFIED="1585640546764">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="在生产环境中估算 $p(x,y)$, $p(x)$,$p(y)$ 是非常麻烦的, 所以互信息求解也复杂" FOLDED="true" ID="ID_422043033" CREATED="1585639633193" MODIFIED="1585640000952" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="连续随机变量互信息定义为: \\&#xa;$$I(X, Y) = D_{KL}(p(X,Y)||p(X)p(Y)) \\&#xa;= - \int_x \int_y p(x,y)\log \frac{p(x,y)}{p(x)p(y)} dx dy$$ \\&#xa;$p（x，y）$是联合概率密度分布函数. \\" ID="ID_801389962" CREATED="1585639346054" MODIFIED="1585639656690" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="MIC的思想就是将连续变量离散化, 然后求互信息, 但是离散化方案有很多种,  从中找出能够使使归一化的互信息最大的一个, 即:$MIC = \max_{c \times r \lt B} \frac {\max_{G \in \mathcal G (c, r)} I(x_G ; y_G)} {\log \min(c, r)}$" ID="ID_1797738260" CREATED="1585639721222" MODIFIED="1585640544797" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="信息增益" FOLDED="true" ID="ID_947182812" CREATED="1565952206942" MODIFIED="1584717762532">
<edge COLOR="#808080"/>
<node TEXT="$g(D, A) = H(D) - H(D \mid A)$" FOLDED="true" ID="ID_1228786142" CREATED="1565952282384" MODIFIED="1584717762532" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="决策树ID3算法" ID="ID_805068888" CREATED="1565952247329" MODIFIED="1584717762533">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="物理意义和互信息完全相同，并且公式也是完全相同" ID="ID_592355621" CREATED="1585640621255" MODIFIED="1585640652508">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="信息增益率" FOLDED="true" ID="ID_33169762" CREATED="1565952262355" MODIFIED="1584717762533">
<edge COLOR="#808080"/>
<node TEXT="$g_r(D, A) = \frac {g(D, A)} {H(A)}$" FOLDED="true" ID="ID_1037899330" CREATED="1565952309601" MODIFIED="1584717762533" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="决策树C4.5算法" ID="ID_1811622347" CREATED="1565952273167" MODIFIED="1584717762533">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="基尼系数" FOLDED="true" ID="ID_563697219" CREATED="1565952368397" MODIFIED="1584717762533">
<edge COLOR="#808080"/>
<node TEXT="$Gini(p)  = \sum_{i=1}^m p_i (1-p_i) \\&#xa;         = 1 -   \sum_{i=1}^m p_i^2 \\&#xa;         = 1 -  \sum_{i=1}^m (\frac {| C_k |}{|D|})^2$" FOLDED="true" ID="ID_1913503192" CREATED="1565952417304" MODIFIED="1584717762533" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="决策树CART算法" ID="ID_1759541367" CREATED="1565952419375" MODIFIED="1584717762534">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="基尼系数实际上是信息熵的一阶近似" ID="ID_1984712800" CREATED="1585640726725" MODIFIED="1585640731850">
<edge COLOR="#808080"/>
</node>
<node TEXT="基尼系数越小，表示选择该特征后熵下降最快，对分类模型效果更好" ID="ID_1325220417" CREATED="1585640749847" MODIFIED="1585640753540">
<edge COLOR="#808080"/>
</node>
<node TEXT="区别于 基尼指数" ID="ID_1931335843" CREATED="1565952373742" MODIFIED="1584717762534">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Markov-chain" FOLDED="true" ID="ID_1903826478" CREATED="1566574763845" MODIFIED="1584717762534" LINK="https://weirping.github.io/blog/Stationary-Distribution-Markov-chain.html">
<edge COLOR="#808080"/>
<node TEXT="Stationary-Distribution" FOLDED="true" ID="ID_315574344" CREATED="1566575030640" MODIFIED="1584717762534">
<edge COLOR="#808080"/>
<node TEXT="平稳随机过程" ID="ID_1431347647" CREATED="1566575046422" MODIFIED="1584717762534">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Density Estimation" FOLDED="true" ID="ID_1984876498" CREATED="1565661908603" MODIFIED="1584717762534">
<edge COLOR="#808080"/>
<node TEXT="Methods" FOLDED="true" ID="ID_943712054" CREATED="1565950787413" MODIFIED="1584717762534">
<edge COLOR="#808080"/>
<node TEXT="Kernel Density Estimation" FOLDED="true" ID="ID_1831296815" CREATED="1565950798538" MODIFIED="1584717762534">
<edge COLOR="#808080"/>
<node TEXT="kernal.png" ID="ID_1035572151" CREATED="1587101262079" MODIFIED="1587101262082">
<hook URI="Machine-Learning_files/kernal.png" SIZE="0.7407407" NAME="ExternalObject"/>
</node>
</node>
<node TEXT="Cubic Spline" FOLDED="true" ID="ID_1973314514" CREATED="1565950809680" MODIFIED="1584717762534">
<edge COLOR="#808080"/>
<node TEXT="A cubic spline is a function created from cubic polynomials on each between-knot interval by pasting them together twice continuously differentiable at the knots." ID="ID_1776200892" CREATED="1565951012988" MODIFIED="1584717762535">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Similarity and DisSimilarity" FOLDED="true" ID="ID_360627699" CREATED="1566489242648" MODIFIED="1584717762535">
<edge COLOR="#808080"/>
<node TEXT="欧几里得距离" ID="ID_1448953359" CREATED="1588662892985" MODIFIED="1588662908846">
<edge COLOR="#808080"/>
</node>
<node TEXT="曼哈顿距离" ID="ID_1875784191" CREATED="1588662892985" MODIFIED="1588662908846">
<edge COLOR="#808080"/>
</node>
<node TEXT="余弦相似度" ID="ID_1669160130" CREATED="1566489278828" MODIFIED="1584717762536">
<edge COLOR="#808080"/>
</node>
<node TEXT="马氏距离" ID="ID_849895166" CREATED="1566489289030" MODIFIED="1584717762536" LINK="https://weirping.github.io/blog/Mahalanobis-distance.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="文本相似度" FOLDED="true" ID="ID_1207232823" CREATED="1566575650936" MODIFIED="1584717762536">
<edge COLOR="#808080"/>
<node TEXT="Hamming distance" FOLDED="true" ID="ID_1497202271" CREATED="1566574243860" MODIFIED="1584717762536">
<edge COLOR="#808080"/>
<node ID="ID_1227323895" CREATED="1588663015214" MODIFIED="1588663018553"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(51, 51, 51); font-family: arial, 宋体, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 28px; text-transform: none; white-space: normal; word-spacing: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none"><font color="rgb(51, 51, 51)" face="arial, 宋体, sans-serif" size="14px">两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数</font></span>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="edit distance(Levenshtein distance)" FOLDED="true" ID="ID_1025905472" CREATED="1566575675925" MODIFIED="1584717762536">
<edge COLOR="#808080"/>
<node TEXT="Levenshtein ratio" ID="ID_1514424813" CREATED="1566575691197" MODIFIED="1584717762536">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Jaccard Distance" FOLDED="true" ID="ID_1986300800" CREATED="1588662962381" MODIFIED="1588663035158">
<edge COLOR="#808080"/>
<node ID="ID_1299845701" CREATED="1588663102475" MODIFIED="1588663155253"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(51, 51, 51); font-family: arial, 宋体, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 28px; text-transform: none; white-space: normal; word-spacing: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none"><font color="rgb(51, 51, 51)" face="arial, 宋体, sans-serif" size="14px">度量两个集合之间的相似性，它被定义为两个集合交集的元素个数除以并集</font></span><font color="rgb(51, 51, 51)" face="arial, 宋体, sans-serif" size="14px"><span style="color: rgb(51, 51, 51); font-family: arial, 宋体, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 28px; text-transform: none; white-space: normal; word-spacing: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none">的元素个数</span></font>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Approximation Inference" FOLDED="true" ID="ID_593166974" CREATED="1566535993174" MODIFIED="1584717762536">
<edge COLOR="#808080"/>
<node TEXT="Laplace Approximation" ID="ID_233871062" CREATED="1566536034569" MODIFIED="1584717762536" LINK="https://weirping.github.io/blog/Laplace-Approximation.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="Variational Inference" ID="ID_1311631765" CREATED="1566536034569" MODIFIED="1584717762536">
<edge COLOR="#808080"/>
</node>
<node TEXT="Gibbs Sampling" ID="ID_955384853" CREATED="1566536034569" MODIFIED="1584717762536">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Concepts" POSITION="left" ID="ID_1125818411" CREATED="1564976643216" MODIFIED="1584717762536">
<edge COLOR="#808080"/>
<node TEXT="Motivation" FOLDED="true" ID="ID_1654785002" CREATED="1565606156788" MODIFIED="1585637338543">
<edge COLOR="#808080"/>
<node TEXT="Prediction" FOLDED="true" ID="ID_1856405639" CREATED="1565606172998" MODIFIED="1584717762537">
<edge COLOR="#808080"/>
<node TEXT="When we are interested mainly in the predicted variable as a result of the inputs, but not on the each way of the inputs affect the prediction. In a real estate example, Prediction would answer the question of: Is my house over or under valued? Non-linear models are very good at these sort of predictions, but not great for inference because the models are much less interpretable." ID="ID_1795490543" CREATED="1565606172998" MODIFIED="1584717762537">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Inference" FOLDED="true" ID="ID_493912205" CREATED="1565606172998" MODIFIED="1585637338542">
<edge COLOR="#808080"/>
<node TEXT="When we are interested in the way each one of the inputs affect the prediction. In a real estate example, Inference would answer the question of: How much would my house cost if it had a view of the sea? Linear models are more suited for inference because the models themselves are easier to understand than their non-linear" ID="ID_25610629" CREATED="1565606172998" MODIFIED="1584717762538">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Cost/Loss(Min) Functions&#xa;Objective(Max) Functions" FOLDED="true" ID="ID_1959068725" CREATED="1565661787532" MODIFIED="1586754839295">
<edge COLOR="#808080"/>
<node TEXT="Maximum Likehook Estimator" FOLDED="true" ID="ID_53290021" CREATED="1565661969652" MODIFIED="1586754836298" LINK="https://weirping.github.io/blog/Maximum-Likehook-Estimator-Cost-Functions.html">
<edge COLOR="#808080"/>
<node TEXT="Linear Regression" FOLDED="true" ID="ID_1111083758" CREATED="1565662085313" MODIFIED="1584717762540">
<edge COLOR="#808080"/>
<node TEXT="Mean Squared Error (MSE)" FOLDED="true" ID="ID_1518804702" CREATED="1565608911129" MODIFIED="1584717762540">
<edge COLOR="#808080"/>
<node TEXT="$MSE=\frac{1}{n} \sum_{i=1}^n(y_i - \hat f(x_i))^2$" ID="ID_1411173900" CREATED="1565608950354" MODIFIED="1584717762540" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="sum-of-squares error function" ID="ID_676652624" CREATED="1565662664814" MODIFIED="1584717762541">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="binary classification" FOLDED="true" ID="ID_1668892025" CREATED="1565662222471" MODIFIED="1584717762541">
<edge COLOR="#808080"/>
<node TEXT="binary cross-entropy error function" ID="ID_214673802" CREATED="1565662246414" MODIFIED="1584717762541">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="multicalss classification" FOLDED="true" ID="ID_1684647573" CREATED="1565662284927" MODIFIED="1584717762541">
<edge COLOR="#808080"/>
<node TEXT="cross-entropy error function" ID="ID_1772913168" CREATED="1565662286654" MODIFIED="1584717762541">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="note: 在分类问题中也可以使用Mean Squared Error (MSE) 和 sum-of-squares error function作为损失函数. 但是cross-entropy error 的梯度下降速度更快." FOLDED="true" ID="ID_1697940" CREATED="1586754367769" MODIFIED="1586754836295" LINK="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">
<edge COLOR="#808080"/>
<node TEXT="cross-entropy-vs-MSE.png" ID="ID_463605189" CREATED="1587101289310" MODIFIED="1587101289313">
<hook URI="Machine-Learning_files/cross-entropy-vs-MSE.png" SIZE="1.0" NAME="ExternalObject"/>
</node>
</node>
</node>
<node TEXT="0-1 Loss" FOLDED="true" ID="ID_1095108459" CREATED="1565662574192" MODIFIED="1584717762541">
<edge COLOR="#808080"/>
<node TEXT="$\frac{1}{n} \sum_{i=1}^n I(y_i \neq \hat y_i)$" ID="ID_1243982851" CREATED="1565609445582" MODIFIED="1584717762542" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Hinge Loss" FOLDED="true" ID="ID_1469695736" CREATED="1565662678986" MODIFIED="1584717762543">
<edge COLOR="#808080"/>
<node TEXT="$L(y)=\max(0, 1-t \cdot y)$" ID="ID_1179401531" CREATED="1565662685299" MODIFIED="1584717762543" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="hinge-loss-function.png" ID="ID_1809358399" CREATED="1590467261429" MODIFIED="1590467264960">
<hook URI="Machine-Learning_files/hinge-loss-function.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Regularization" FOLDED="true" ID="ID_11419241" CREATED="1565661625047" MODIFIED="1584717762550">
<edge COLOR="#808080"/>
<node TEXT="L1 norm and L2 norm" ID="ID_76200147" CREATED="1565661639267" MODIFIED="1584717762550" LINK="https://weirping.github.io/blog/Norm-Regularization.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="Early Stopping" ID="ID_1339278931" CREATED="1565661659646" MODIFIED="1584717762550">
<edge COLOR="#808080"/>
</node>
<node TEXT="Dropout" ID="ID_1190649529" CREATED="1565661665206" MODIFIED="1584717762551" LINK="https://weirping.github.io/blog/dropout.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="Sparse regularizer on columns" FOLDED="true" ID="ID_322442547" CREATED="1565661677418" MODIFIED="1584717762551">
<edge COLOR="#808080"/>
<node TEXT="This regularizer defines an L2 norm on each column and an L1 norm over all columns. It can be solved by proximal methods." FOLDED="true" ID="ID_523138470" CREATED="1565799679182" MODIFIED="1584717762551">
<edge COLOR="#808080"/>
<node TEXT="R(w)=\sum_{i=1}^D ||W||_{2,1}" ID="ID_840171304" CREATED="1565799763369" MODIFIED="1584717762552" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Nuclear norm regularization" ID="ID_68303896" CREATED="1565661686281" MODIFIED="1584717762553">
<edge COLOR="#808080"/>
</node>
<node TEXT="Mean-constrained regularization" ID="ID_505782314" CREATED="1565661694923" MODIFIED="1584717762553">
<edge COLOR="#808080"/>
</node>
<node TEXT="Clustered mean-constrained regularization" ID="ID_1840930005" CREATED="1565661702645" MODIFIED="1584717762553">
<edge COLOR="#808080"/>
</node>
<node TEXT="Graph-based similarity" ID="ID_192683552" CREATED="1565661708431" MODIFIED="1584717762553">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Optimization" FOLDED="true" ID="ID_428597335" CREATED="1567948603198" MODIFIED="1584717762553">
<edge COLOR="#808080"/>
<node TEXT="Gradient Descent" ID="ID_39662921" CREATED="1567948822358" MODIFIED="1584717762553">
<edge COLOR="#808080"/>
</node>
<node TEXT="Stochastic Gradient Descent (SGD)" ID="ID_572453435" CREATED="1567948822358" MODIFIED="1584717762553">
<edge COLOR="#808080"/>
</node>
<node TEXT="Mini-batch Stochastic Gradient Descent (SGD)" ID="ID_201391241" CREATED="1567948822359" MODIFIED="1584717762554">
<edge COLOR="#808080"/>
</node>
<node TEXT="Momentum" FOLDED="true" ID="ID_191704362" CREATED="1567948822362" MODIFIED="1584717762554">
<edge COLOR="#808080"/>
<node TEXT="Idea: Add a fraction v of previous update to current one. When the gradient keeps pointing in the same direction, this will increase the size of the steps taken towards the minimum." ID="ID_1270160800" CREATED="1567948822363" MODIFIED="1584717762554">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Adagrad" FOLDED="true" ID="ID_1705774418" CREATED="1567948822363" MODIFIED="1584717762555">
<edge COLOR="#808080"/>
<node TEXT="Adaptive learning rates for each parameter" ID="ID_1326023324" CREATED="1567948822364" MODIFIED="1584717762555">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Performance Analysis" FOLDED="true" ID="ID_55335660" CREATED="1565606204401" MODIFIED="1584717762555">
<edge COLOR="#808080"/>
<node TEXT="Confusion Matrix based" FOLDED="true" ID="ID_1386292206" CREATED="1565608776077" MODIFIED="1584717762556" LINK="https://weirping.github.io/blog/Precision-Recall-F1Score-ROC-AUC.html">
<edge COLOR="#808080"/>
<node TEXT="Confusion-Matrix .png" ID="ID_75844134" CREATED="1587101317675" MODIFIED="1587101317679">
<hook URI="Machine-Learning_files/Confusion-Matrix%20.png" SIZE="0.8902077" NAME="ExternalObject"/>
</node>
<node TEXT="Accuracy" FOLDED="true" ID="ID_1914115541" CREATED="1565606620568" MODIFIED="1584717762557">
<edge COLOR="#808080"/>
<node TEXT="Fraction of correct predictions" ID="ID_1999713816" CREATED="1565606636787" MODIFIED="1584717762559">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Precision" ID="ID_1650754605" CREATED="1565607149937" MODIFIED="1584717762559">
<edge COLOR="#808080"/>
</node>
<node TEXT="Recall" ID="ID_51668288" CREATED="1565607157235" MODIFIED="1584717762560">
<edge COLOR="#808080"/>
</node>
<node TEXT="f1 score" FOLDED="true" ID="ID_974688958" CREATED="1565607119147" MODIFIED="1584717762561">
<edge COLOR="#808080"/>
<node TEXT="Harmonic Mean of Precision and Recall" ID="ID_294186781" CREATED="1565607303306" MODIFIED="1584717762562"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      Precision and Recall &#30340;&#35843;&#21644;&#24179;&#22343;&#25968;
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="ROC - Receiver Operating Characteristics&#xa;AUC - Area Under Curve" ID="ID_1565120529" CREATED="1565607501478" MODIFIED="1584717762562">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Bias-Variance Tradeoff" ID="ID_491268842" CREATED="1565607847592" MODIFIED="1584717762563" LINK="https://weirping.github.io/blog/Bias-Variance-Decomposition.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="Coefficient of Determination(Goodness of Fit) $R^2$" FOLDED="true" ID="ID_1387482756" CREATED="1565608378456" MODIFIED="1584717762564" LINK="https://weirping.github.io/blog/Coefficient-of-Determination.html" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="回归问题模型评价指标" ID="ID_1696271178" CREATED="1566536367317" MODIFIED="1584717762564">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Metrics in LTR" FOLDED="true" ID="ID_1583246436" CREATED="1566536581552" MODIFIED="1584717762564" LINK="https://weirping.github.io/blog/Metrics-in-IR.html">
<edge COLOR="#808080"/>
<node TEXT="nDCG" FOLDED="true" ID="ID_1311776373" CREATED="1566536723280" MODIFIED="1584717762565">
<edge COLOR="#808080"/>
<node TEXT="DCG" ID="ID_1686256339" CREATED="1566536714487" MODIFIED="1584717762565">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="RR" FOLDED="true" ID="ID_1129249961" CREATED="1566536729844" MODIFIED="1584717762565">
<edge COLOR="#808080"/>
<node TEXT="MRR" ID="ID_1470963527" CREATED="1566536738266" MODIFIED="1584717762565">
<edge COLOR="#808080"/>
</node>
<node TEXT="ERR" ID="ID_1993112965" CREATED="1566536742760" MODIFIED="1584717762565">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="MAP" FOLDED="true" ID="ID_1868357561" CREATED="1566536753669" MODIFIED="1584717762565">
<edge COLOR="#808080"/>
<node TEXT="Precesion" ID="ID_1013114286" CREATED="1566536776906" MODIFIED="1584717762565">
<edge COLOR="#808080"/>
</node>
<node TEXT="Average Precision" ID="ID_1821472796" CREATED="1566536782700" MODIFIED="1584717762565">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Tuning" FOLDED="true" ID="ID_1255034950" CREATED="1565609507232" MODIFIED="1584717762565">
<edge COLOR="#808080"/>
<node TEXT="" FOLDED="true" ID="ID_598789160" CREATED="1566054935737" MODIFIED="1584717762565">
<edge COLOR="#808080"/>
<node TEXT="Underfitting" FOLDED="true" ID="ID_1006744656" CREATED="1565610860090" MODIFIED="1584717762565">
<edge COLOR="#808080"/>
<node TEXT="Opposite of Overfitting. Underfitting occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. It occurs when the model or algorithm does not fit the data enough. Underfitting occurs if the model or algorithm shows low variance but high bias (to contrast the opposite, overfitting from high variance and low bias). It is often a result of an excessively simple model." ID="ID_1271210375" CREATED="1565610860090" MODIFIED="1584717762566">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Overfitting" FOLDED="true" ID="ID_946819175" CREATED="1565610860089" MODIFIED="1584717762567">
<edge COLOR="#808080"/>
<node TEXT="When a given method yields a small training MSE (or cost), but a large test MSE (or cost), we are said to be overfitting the data. This happens because our statistical learning procedure is trying too hard to find pattens in the data, that might be due to random chance, rather than a property of our function. In other words, the algorithms may be learning the training data too well. If model overfits, try removing some features, decreasing degrees of freedom, or adding more data." ID="ID_332107013" CREATED="1565610860090" MODIFIED="1584717762567">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Cross-validation" FOLDED="true" ID="ID_728045279" CREATED="1565609529514" MODIFIED="1584717762568" LINK="https://weirping.github.io/blog/Hyperparameter-Tuning-in-Sklearn.html">
<edge COLOR="#808080"/>
<node TEXT="k-fold cross-validation" FOLDED="true" ID="ID_1837194955" CREATED="1565609578039" MODIFIED="1584717762568">
<edge COLOR="#808080"/>
<node TEXT="stratified k-fold cross-validation" FOLDED="true" ID="ID_1951124347" CREATED="1565609708260" MODIFIED="1584717762568">
<edge COLOR="#808080"/>
<node TEXT="用在分类为题中，与K-fold相比stratified k-fold保证每一个fold中各类别的比例和整个训练数据集的比例相同。实验验证该方法相对于K-fold能够更好的平衡bias and variance。" ID="ID_1049373205" CREATED="1565609714530" MODIFIED="1584717762568">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Leave-one-out cross-validation" FOLDED="true" ID="ID_1882666886" CREATED="1565609578041" MODIFIED="1584717762569">
<edge COLOR="#808080"/>
<node TEXT="是K-fold的极端形式，将K-fold中的k等于样本量。" ID="ID_89222067" CREATED="1565609781077" MODIFIED="1584717762569">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Holdout method" ID="ID_1890461874" CREATED="1565609578038" MODIFIED="1584717762569">
<edge COLOR="#808080"/>
</node>
<node TEXT="GroupKFold" FOLDED="true" ID="ID_506149372" CREATED="1565609671502" MODIFIED="1584717762569">
<edge COLOR="#808080"/>
<node TEXT="Leave One Group Out cross-validation" ID="ID_981185440" CREATED="1565609896610" MODIFIED="1584717762570">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Hyperparameters" FOLDED="true" ID="ID_521971684" CREATED="1565610223578" MODIFIED="1584717762570" LINK="https://weirping.github.io/blog/Hyperparameter-Tuning-in-Sklearn.html">
<edge COLOR="#808080"/>
<node TEXT="Grid Search" FOLDED="true" ID="ID_1146662180" CREATED="1565610223578" MODIFIED="1584717762570">
<edge COLOR="#808080"/>
<node TEXT="The traditional way of performing hyperparameter optimization has been grid search, or a parameter sweep, which is simply an exhaustive searching through a manually specified subset of the hyperparameter space of a learning algorithm. A grid search algorithm must be guided by some performance metric, typically measured by cross-validation on the training set or evaluation on a held-out validation set." ID="ID_1827303667" CREATED="1565610223578" MODIFIED="1584717762570">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Random Search" FOLDED="true" ID="ID_591887490" CREATED="1565610223578" MODIFIED="1584717762571">
<edge COLOR="#808080"/>
<node TEXT="Since grid searching is an exhaustive and therefore potentially expensive method, several alternatives have been proposed. In particular, a randomized search that simply samples parameter settings a fixed number of times has been found to be more effective in high-dimensional spaces than exhaustive search." ID="ID_854746525" CREATED="1565610223578" MODIFIED="1584717762571">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Gradient-based optimization" FOLDED="true" ID="ID_1301419742" CREATED="1565610223578" MODIFIED="1584717762572">
<edge COLOR="#808080"/>
<node TEXT="For specific learning algorithms, it is possible to compute the gradient with respect to hyperparameters and then optimize the hyperparameters using gradient descent. The first usage of these techniques was focused on neural networks. Since then, these methods have been extended to other models such as support vector machines or logistic regression." ID="ID_1737112824" CREATED="1565610223578" MODIFIED="1584717762572">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="" FOLDED="true" ID="ID_131220504" CREATED="1566054984993" MODIFIED="1584717762573">
<edge COLOR="#808080"/>
<node TEXT="Early Stopping (Regularization)" FOLDED="true" ID="ID_1599665469" CREATED="1565610860089" MODIFIED="1584717762573">
<edge COLOR="#808080"/>
<node TEXT="Early stopping rules provide guidance as to how many iterations can be run before the learner begins to over-fit, and stop the algorithm then." ID="ID_1269109897" CREATED="1565610860089" MODIFIED="1584717762573">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Bootstrap" FOLDED="true" ID="ID_1908747254" CREATED="1565610860090" MODIFIED="1584717762574">
<edge COLOR="#808080"/>
<node TEXT="Test that applies Random Sampling with Replacement of the available data, and assigns measures of accuracy (bias, variance, etc.) to sample estimates." ID="ID_73387282" CREATED="1565610860090" MODIFIED="1584717762574">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Bagging" FOLDED="true" ID="ID_1066749641" CREATED="1565610860090" MODIFIED="1584717762575">
<edge COLOR="#808080"/>
<node TEXT="An approach to ensemble learning that is based on bootstrapping. Shortly, given a training set, we produce multiple different training sets (called bootstrap samples), by sampling with replacement from the original dataset. Then, for each bootstrap sample, we build a model. The results in an ensemble of models, where each model votes with the equal weight. Typically, the goal of this procedure is to reduce the variance of the model of interest (e.g. decision trees)." ID="ID_1614538170" CREATED="1565610860090" MODIFIED="1584717762575">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Taxonomy" FOLDED="true" ID="ID_493349160" CREATED="1565621695484" MODIFIED="1584717762576">
<edge COLOR="#808080"/>
<node TEXT="" FOLDED="true" ID="ID_1776929294" CREATED="1565621713614" MODIFIED="1584717762576">
<edge COLOR="#808080"/>
<node TEXT="Regression" FOLDED="true" ID="ID_994816457" CREATED="1565621945287" MODIFIED="1584717762576">
<edge COLOR="#808080"/>
<node TEXT="A supervised problem, the outputs are continuous rather than discrete." ID="ID_1621598583" CREATED="1565621945287" MODIFIED="1584717762576">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Classification" FOLDED="true" ID="ID_1002834047" CREATED="1565621945287" MODIFIED="1584717762576">
<edge COLOR="#808080"/>
<node TEXT="Inputs are divided into two or more classes, and the learner must produce a model that assigns unseen inputs to one or more (multi-label classification) of these classes. This is typically tackled in a supervised way." ID="ID_1309177176" CREATED="1565621945287" MODIFIED="1584717762577">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Clustering" FOLDED="true" ID="ID_1532269280" CREATED="1565621945287" MODIFIED="1584717762577">
<edge COLOR="#808080"/>
<node TEXT="A set of inputs is to be divided into groups. Unlike in classification, the groups are not known beforehand, making this typically an unsupervised task." ID="ID_640157662" CREATED="1565621945287" MODIFIED="1584717762578">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Density Estimation" FOLDED="true" ID="ID_1374226559" CREATED="1565621945287" MODIFIED="1584717762578">
<edge COLOR="#808080"/>
<node TEXT="Finds the distribution of inputs in some space." ID="ID_912807268" CREATED="1565621945287" MODIFIED="1584717762578">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Dimensionality Reduction" FOLDED="true" ID="ID_1717123563" CREATED="1565621945287" MODIFIED="1584717762578">
<edge COLOR="#808080"/>
<node TEXT="Simplifies inputs by mapping them into a lower-dimensional space." ID="ID_856997294" CREATED="1565621945287" MODIFIED="1584717762578">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="" FOLDED="true" ID="ID_193310527" CREATED="1565622019749" MODIFIED="1584717762579">
<edge COLOR="#808080"/>
<node TEXT="Parametric" ID="ID_896417188" CREATED="1565622059846" MODIFIED="1584717762579">
<edge COLOR="#808080"/>
</node>
<node TEXT="Non-Parametric" ID="ID_1866487245" CREATED="1565622059846" MODIFIED="1584717762580">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="" FOLDED="true" ID="ID_1739191734" CREATED="1565622283726" MODIFIED="1592055538527">
<edge COLOR="#808080"/>
<node TEXT="Supervised" ID="ID_1250081931" CREATED="1565622288664" MODIFIED="1592055538526" HGAP_QUANTITY="15.5 pt" VSHIFT_QUANTITY="30.75 pt">
<edge COLOR="#808080"/>
</node>
<node TEXT="Semi-Supervised Learning" FOLDED="true" ID="ID_1815520531" CREATED="1587052890326" MODIFIED="1587138581124">
<edge COLOR="#808080"/>
<node TEXT="Introduction" FOLDED="true" ID="ID_484675828" CREATED="1587099837349" MODIFIED="1587138581124">
<edge COLOR="#808080"/>
<node TEXT="Semi-supervised learning Dataset" FOLDED="true" ID="ID_1881697779" CREATED="1592054754305" MODIFIED="1592054760370">
<edge COLOR="#808080"/>
<node TEXT="Semi-supervised learning Dataset: \\&#xa;labeled Dataset $\{(x^r, \hat{y}^r)\}_{r=1}^R$, \\&#xa;unlabeled data $\{x^u\}_{u=R}^{R+U}$  \\&#xa;usually $U &gt;&gt; R$" ID="ID_1295314129" CREATED="1587099769069" MODIFIED="1592054329746" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="分类" FOLDED="true" ID="ID_1162157511" CREATED="1587099917283" MODIFIED="1587102111182">
<edge COLOR="#808080"/>
<node TEXT="Transductive learning" FOLDED="true" ID="ID_1134798451" CREATED="1587099917283" MODIFIED="1592054378404">
<edge COLOR="#808080"/>
<node ID="ID_825308898" CREATED="1592054380340" MODIFIED="1592054407748"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <p>
      unlabeled data is the testing data
    </p>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Inductive learning" FOLDED="true" ID="ID_629396581" CREATED="1587099917283" MODIFIED="1592054391309">
<edge COLOR="#808080"/>
<node TEXT="unlabeled data is not the testing data" ID="ID_674585503" CREATED="1592054392970" MODIFIED="1592054407747">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="基本思想" FOLDED="true" ID="ID_1263987304" CREATED="1592054774663" MODIFIED="1592054814898">
<edge COLOR="#808080"/>
<node FOLDED="true" ID="ID_1301372506" CREATED="1592054808023" MODIFIED="1609000421716"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <p>
      The distribution of the unlabeled data tell us something.<br/>(<b>Usually with some assumption</b>)
    </p>
    <p>
      <i>如果 assumption 不合理, Semi-supervised learning 则可能是负向左右</i>
    </p>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
<font BOLD="false"/>
<node TEXT="semi-supervised-intro.png" ID="ID_464070802" CREATED="1592054863545" MODIFIED="1592054868756">
<hook URI="Machine-Learning_files/semi-supervised-intro.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="assumption &amp; approches" FOLDED="true" ID="ID_1496536520" CREATED="1609000409796" MODIFIED="1609001979361">
<edge COLOR="#808080"/>
<node TEXT="Semi-supervised Learning for Generative Model" FOLDED="true" ID="ID_1745536704" CREATED="1609000525284" MODIFIED="1609001979361">
<edge COLOR="#808080"/>
<node TEXT="Generative Model example" ID="ID_1684135380" CREATED="1609001877182" MODIFIED="1609001979361" LINK="#ID_12656461">
<edge COLOR="#808080"/>
</node>
<node TEXT="二分类的例子" FOLDED="true" ID="ID_332382388" CREATED="1609601548006" MODIFIED="1609601907004">
<edge COLOR="#808080"/>
<node TEXT="semi-supervised-generative-model-example.png" ID="ID_923017073" CREATED="1609601854105" MODIFIED="1609601902248">
<hook URI="Machine-Learning_files/semi-supervised-generative-model-example.png" SIZE="0.74254286" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
<node TEXT="求解理论思路: &#xa;\\&#xa;在数据集labeled data 和 unlabeled data上最大化如下似然函数:&#xa;\\&#xa;$\log L(\theta) = \sum_{x^r} \log P_{\theta}(x^r, \hat{y}^r) + \sum_{x^u} \log P_{\theta}(x^u | C_2)P(C_2)$&#xa;\\&#xa;$P_{\theta}(x^{u}) = P_{\theta}(x^{u} | C_1)P(C_1) + P_{\theta}(x^{u} | C_2)P(C_2)$" ID="ID_919089147" CREATED="1609602357335" MODIFIED="1609603018750" FORMAT="latexPatternFormat"/>
<node TEXT="求解算法:&#xa;\\&#xa;- Given **labelled** training examples $x^{r} \in C_1, C_2$&#xa;\\&#xa;- looking for most likely prior probability $P(C_i)$ and classdependent probability $P(x|C_i)$&#xa;\\&#xa;- $P(x|C_i)$ is a Gaussian parameterized by $\mu_i$ and $\Sigma$&#xa;\\&#xa;- with **unlabeled** data $x^u$  re-estimate $P(C_1),  P(C_2), \mu_1, \mu_2, \Sigma$;&#xa;\\&#xa;- 使用EM算法做re-esttimate:&#xa;- Initializstion $\theta = \{P(C_1),  P(C_2), \mu_1, \mu_2, \Sigma\}$; 也可以使用 $x^{r}$ 训练出的 $\theta$ 作为初始值;&#xa;- E- step: compute the posterior probability of unlabeled data $P_{\theta} (C_1 | x^{u}), P_{\theta} (C_2 | x^{u})$;&#xa;\\&#xa;- M-step: update $\theta = \{P(C_1),  P(C_2), \mu_1, \mu_2, \Sigma\}$ with posterior probability:&#xa;\\&#xa;$P(C_1) = \frac{N_1 + \sum_{x^{u} }  P_{\theta} (C_1 | x^{u}) }{N}$&#xa;\\&#xa;$\mu_1 = \frac{1}{N_1}\sum_{x^{r} \in C_1}x^{r} + \frac{1}{\sum_{x^{u}}P(C_1 | x^{u})}\sum_{x^{u}}P(C_1 | x^{u})x^{u}$&#xa;\\&#xa;$P(C_2) = \frac{N_2 + \sum_{x^{u} }  P_{\theta} (C_2 | x^{u}) }{N}$&#xa;\\&#xa;$\mu_2 = \frac{1}{N_2}\sum_{x^{r} \in C_2}x^{r} + \frac{1}{\sum_{x^{u}}P(C_2 | x^{u})}\sum_{x^{u}}P(C_2 | x^{u})x^{u}$&#xa;\\&#xa;$N$: total number of examples&#xa;\\&#xa;$N_1$: number of examples belonging to $C_1$&#xa;\\&#xa;$N_2$: number of examples belonging to $C_2$&#xa;\\&#xa;- Back to E-step." ID="ID_1006036911" CREATED="1609601566845" MODIFIED="1609603051879" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Low-density Separation Assumption" ID="ID_1339155825" CREATED="1609000525284" MODIFIED="1609001979361">
<edge COLOR="#808080"/>
</node>
<node TEXT="Smoothness Assumption" ID="ID_983001424" CREATED="1609000525284" MODIFIED="1609001979361">
<edge COLOR="#808080"/>
</node>
<node TEXT="Better Representation" ID="ID_1523418622" CREATED="1609000525284" MODIFIED="1609001979361">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Unsupervised" FOLDED="true" ID="ID_920905624" CREATED="1565622288664" MODIFIED="1584717762582">
<edge COLOR="#808080"/>
<node TEXT="No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning)." ID="ID_1289787007" CREATED="1565622288664" MODIFIED="1584717762582">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Reinforcement Learning" ID="ID_1589018726" CREATED="1565622288664" MODIFIED="1584717762583">
<edge COLOR="#808080"/>
</node>
<node TEXT="Self-Supervised Learning" LOCALIZED_STYLE_REF="AutomaticLayout.level,4" FOLDED="true" ID="ID_811437685" CREATED="1564976333940" MODIFIED="1612847274991" STYLE="fork" SHAPE_HORIZONTAL_MARGIN="10 pt" SHAPE_VERTICAL_MARGIN="10 pt">
<hook NAME="NodeConditionalStyles">
    <conditional_style ACTIVE="true" LOCALIZED_STYLE_REF="AutomaticLayout.level,1" LAST="false">
        <node_level_condition VALUE="1" COMPARATION_RESULT="0" SUCCEED="true"/>
    </conditional_style>
</hook>
<edge WIDTH="3"/>
<node TEXT="Background" FOLDED="true" ID="ID_1872385102" CREATED="1611111044578" MODIFIED="1611111057112">
<node TEXT="监督学习" FOLDED="true" ID="ID_1948880922" CREATED="1611111068383" MODIFIED="1611111077391">
<node TEXT="数据标注是监督学习中必不可少的步骤，这是耗时，费力且有噪声的。" ID="ID_477773118" CREATED="1611111132859" MODIFIED="1611111153956"/>
</node>
<node TEXT="无监督学习" FOLDED="true" ID="ID_551264401" CREATED="1611111164252" MODIFIED="1611111169840">
<node TEXT="不依赖于人工注释，" ID="ID_764564541" CREATED="1611111216010" MODIFIED="1611111287278"/>
<node TEXT="通常集中在数据良好表示（例如平滑度，稀疏性和分解）的预设先验上。" ID="ID_1159689471" CREATED="1611111287283" MODIFIED="1611111287284"/>
<node TEXT="预设先验在某些情况下不太值得信赖，甚至是错误。" ID="ID_805038871" CREATED="1611111380447" MODIFIED="1611111462971"/>
</node>
<node TEXT="半监督学习" FOLDED="true" ID="ID_664652874" CREATED="1611111499638" MODIFIED="1611111507883">
<node TEXT="The distribution of the unlabeled data tell us something. (Usually with some assumption)" ID="ID_1373098830" CREATED="1611111514825" MODIFIED="1611111625963"/>
<node TEXT="如果 assumption 不合理, Semi-supervised learning 则可能是负向作用" ID="ID_481540982" CREATED="1611111625971" MODIFIED="1611111625973"/>
</node>
</node>
<node TEXT="What" FOLDED="true" ID="ID_900617841" CREATED="1611110797549" MODIFIED="1611110809782">
<node TEXT="自监督学习主要是利用辅助任务（pretext）从大规模的无监督数据中挖掘自身的监督信息，使用监督信息对网络进行训练，从而可以学习到对下游任务有价值的表征。" ID="ID_1197532150" CREATED="1611280560810" MODIFIED="1611280560810"/>
<node TEXT="也就是说自监督学习的监督信息不是人工标注的，而是算法在大规模无监督数据中自动构造监督信息。" ID="ID_1351818189" CREATED="1611280560810" MODIFIED="1611280560810"/>
<node TEXT="大多数时候，我们称之为无监督学习，严格上讲，他应该叫自监督学习" ID="ID_176266120" CREATED="1611280560818" MODIFIED="1611280560818"/>
</node>
<node TEXT="challenges" FOLDED="true" ID="ID_1625227179" CREATED="1611280769942" MODIFIED="1611281091006">
<node TEXT="如何设计有效的辅助任务 pretext？" ID="ID_1161898936" CREATED="1611282319116" MODIFIED="1611282319116"/>
<node TEXT="如何来评测它的有效性？" FOLDED="true" ID="ID_942135160" CREATED="1611282319116" MODIFIED="1611282319116">
<node TEXT="主要由下游任务的性能来体现" FOLDED="true" ID="ID_778902683" CREATED="1611283145543" MODIFIED="1611283150120">
<node TEXT="通过 Pretrain-Fintune 的模式" ID="ID_776791328" CREATED="1611283174237" MODIFIED="1611283179878"/>
</node>
<node TEXT="pretext 任务复杂度 越高， 模型效果越好" ID="ID_1975499897" CREATED="1611282979121" MODIFIED="1611284355613" LINK="#ID_1858810419"/>
</node>
</node>
<node TEXT="How" FOLDED="true" ID="ID_1012042098" CREATED="1611110815211" MODIFIED="1611110817908">
<node TEXT="基于上下文(Context Based)" FOLDED="true" ID="ID_1076032318" CREATED="1611282347532" MODIFIED="1612847356830">
<node TEXT="NLP 中 Word2Vec" ID="ID_1060225511" CREATED="1611282399235" MODIFIED="1611282531094"/>
<node TEXT="CV：通过一种名为 Jigsaw（拼图）[7] 的方式来构造辅助任务" FOLDED="true" ID="ID_670324492" CREATED="1611282531715" MODIFIED="1612847356830">
<node TEXT="" ID="ID_1977326778" CREATED="1611282832935" MODIFIED="1611282832939">
<hook NAME="FirstGroupNode"/>
</node>
<node TEXT="将一张图分成 9 个部分，然后通过预测这几个部分的相对位置来产生损失。" FOLDED="true" ID="ID_1711086740" CREATED="1611282697642" MODIFIED="1611282703791">
<node TEXT="可以将一张图分成 9 个部分，然后通过预测这几个部分的相对位置来产生损失。比如我们输入这张图中的小猫的眼睛和右耳朵，期待让模型学习到猫的右耳朵是在脸部的右上方的，如果模型能很好的完成这个任务，那么我们就可以认为模型学习到的表征是具有语义信息的。" ID="ID_998463854" CREATED="1611282595418" MODIFIED="1611282599412"/>
</node>
<node TEXT="首先我们依然将图片分为 9 块，我们预先定义好 64 种排序方式。模型输入任意一种被打乱的序列，期待能够学习到这种序列的顺序属于哪个类(64分类)" FOLDED="true" ID="ID_1312036144" CREATED="1611282741799" MODIFIED="1611282749562">
<node TEXT="上个工作相比，这个模型需要学习到更多的相对位置信息" ID="ID_1944051051" CREATED="1611282777181" MODIFIED="1611282782477"/>
</node>
<node TEXT="抠图模式" FOLDED="true" ID="ID_423521291" CREATED="1611283247018" MODIFIED="1611283254763">
<node TEXT="就是我们随机的将图片中的一部分删掉，然后利用剩余的部分来预测扣掉的部分" ID="ID_1018808669" CREATED="1611283264391" MODIFIED="1611283268971"/>
</node>
<node TEXT="" ID="ID_693822645" CREATED="1611282832930" MODIFIED="1611282832935">
<hook NAME="SummaryNode"/>
<hook NAME="AlwaysUnfoldedNode"/>
<node TEXT="使用更强的监督信息，或者说辅助任务越难，最后的性能越好" ID="ID_1858810419" CREATED="1611282832942" MODIFIED="1611282843535"/>
</node>
</node>
</node>
<node TEXT="基于时序(Temporal Based)" FOLDED="true" ID="ID_1249740258" CREATED="1611283362838" MODIFIED="1611283369884">
<node TEXT="最能体现时序的数据类型就是视频" ID="ID_1895596119" CREATED="1611283438854" MODIFIED="1611283470929"/>
<node TEXT="样本间其实也是具有很多约束关系的" ID="ID_341341671" CREATED="1611283471655" MODIFIED="1611283475780"/>
</node>
<node TEXT="基于对比（Contrastive Based）" FOLDED="true" ID="ID_1551044476" CREATED="1611283491436" MODIFIED="1611283503763">
<node TEXT="通过学习对两个事物的相似或不相似进行编码来构建表征" ID="ID_325832613" CREATED="1611283531644" MODIFIED="1611283536050"/>
<node TEXT="如， 一段视频中， 图像和声音的对应关系" ID="ID_646200267" CREATED="1611284230627" MODIFIED="1611284256048"/>
</node>
</node>
<node TEXT="More" FOLDED="true" ID="ID_666386653" CREATED="1611112187854" MODIFIED="1611112193050">
<node TEXT="找到合适的辅助任务（pretext）对于自监督学习是最需要解决的问题。" ID="ID_991521261" CREATED="1611283783199" MODIFIED="1611283783199"/>
<node TEXT="数据和资源越多，自监督预训练的效果会更好（Bert, MoCo, SimCLR）。" ID="ID_1556131582" CREATED="1611283783199" MODIFIED="1611283783199"/>
<node TEXT="自监督直接和具体任务的结合（Task Related Self-Supervised Learning）是个可探索的方向" ID="ID_1399205941" CREATED="1611283783204" MODIFIED="1611283783204"/>
</node>
</node>
<node TEXT="主动学习&#xa;(Active Learning, AL)" LOCALIZED_STYLE_REF="AutomaticLayout.level,4" FOLDED="true" ID="ID_889594278" CREATED="1564976333940" MODIFIED="1622700594401" STYLE="fork" SHAPE_HORIZONTAL_MARGIN="10 pt" SHAPE_VERTICAL_MARGIN="10 pt">
<hook NAME="NodeConditionalStyles">
    <conditional_style ACTIVE="true" LOCALIZED_STYLE_REF="AutomaticLayout.level,1" LAST="false">
        <node_level_condition VALUE="1" COMPARATION_RESULT="0" SUCCEED="true"/>
    </conditional_style>
</hook>
<edge WIDTH="3"/>
<node TEXT="Background" FOLDED="true" ID="ID_1375719455" CREATED="1611279268568" MODIFIED="1611279340226">
<node ID="ID_1450279831" CREATED="1622619648592" MODIFIED="1622619658036"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <p>
      <b>有监督学习和半监督学习，都需要一定数量的标注数据才能进行模型的训练。但是在实际的业务场景获得样本的成本较高，那么如何通过较少成本来获得较大价值的标注数据</b>
    </p>
  </body>
</html>
</richcontent>
<font BOLD="false"/>
</node>
</node>
<node TEXT="What" FOLDED="true" ID="ID_1529939881" CREATED="1611279340765" MODIFIED="1611279344897">
<node TEXT="主动学习（Active Learning）的思路就是：通过机器学习的方法获取到那些比较“难”预测的样本数据，让人工再次确认和审核，然后将人工标注得到的数据再次使用有监督学习模型或者半监督学习模型进行训练，逐步提升模型的效果，将人工经验融入机器学习的模型中。" ID="ID_161873537" CREATED="1622619915697" MODIFIED="1622619919992"/>
</node>
<node TEXT="How" FOLDED="true" ID="ID_311436160" CREATED="1611279370912" MODIFIED="1611279374730">
<node TEXT="流程" FOLDED="true" ID="ID_887884658" CREATED="1622620443331" MODIFIED="1622620493597">
<node TEXT="Active-Learning.jpg" ID="ID_808006253" CREATED="1622700706104" MODIFIED="1622700706139">
<hook URI="Machine-Learning_files/Active-Learning.jpg" SIZE="0.72551394" NAME="ExternalObject"/>
</node>
<node TEXT="1. 机器学习模型：包括机器学习模型的训练和预测两部分；&#xa;2. 待标注的数据候选集提取：依赖主动学习中的查询函数（Query Function）；&#xa;3. 人工标注：专家经验或者业务经验的提炼；&#xa;4. 获得候选集的标注数据：获得更有价值的样本数据；&#xa;5. 机器学习模型的更新：通过增量学习或者重新学习的方式更新模型，从而将人工标注的数据融入机器学习模型中，提升模型效果." ID="ID_611430977" CREATED="1622620310340" MODIFIED="1622620485347"/>
</node>
<node FOLDED="true" ID="ID_297067011" CREATED="1622620907577" MODIFIED="1622620907577"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, Helvetica Neue, PingFang SC, Microsoft YaHei, Source Han Sans SC, Noto Sans CJK SC, WenQuanYi Micro Hei, sans-serif; font-size: 15px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none"><font color="rgb(18, 18, 18)" face="-apple-system, BlinkMacSystemFont, Helvetica Neue, PingFang SC, Microsoft YaHei, Source Han Sans SC, Noto Sans CJK SC, WenQuanYi Micro Hei, sans-serif" size="15px">查询策略（Query Strategy Frameworks）</font></span>
  </body>
</html>
</richcontent>
<node ID="ID_27390446" CREATED="1622620917934" MODIFIED="1622620917934"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, Helvetica Neue, PingFang SC, Microsoft YaHei, Source Han Sans SC, Noto Sans CJK SC, WenQuanYi Micro Hei, sans-serif; font-size: 15px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none"><font color="rgb(18, 18, 18)" face="-apple-system, BlinkMacSystemFont, Helvetica Neue, PingFang SC, Microsoft YaHei, Source Han Sans SC, Noto Sans CJK SC, WenQuanYi Micro Hei, sans-serif" size="15px">是主动学习的核心</font></span>
  </body>
</html>
</richcontent>
</node>
<node TEXT="分类" FOLDED="true" ID="ID_1350851856" CREATED="1622620921283" MODIFIED="1622620925681">
<node TEXT="不确定性采样的查询（Uncertainty Sampling）" FOLDED="true" ID="ID_1857279661" CREATED="1622621040085" MODIFIED="1622621040085">
<node TEXT="将模型中难以区分的样本数据提取出来，提供给业务专家或者标注人员进行标注" ID="ID_1327587217" CREATED="1622624161270" MODIFIED="1622624161270"/>
<node TEXT="关键：如何描述样本或者数据的不确定性&#xa;有3种方法" FOLDED="true" ID="ID_1505938259" CREATED="1622624177991" MODIFIED="1622624287235">
<node TEXT="置信度最低（Least Confident）" FOLDED="true" ID="ID_418373613" CREATED="1622624289560" MODIFIED="1622624289560">
<node ID="ID_974658155" CREATED="1622624376306" MODIFIED="1622624388145"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(34, 34, 34); font-family: consolas, lucida console, courier new, monospace; font-size: 12px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: left; text-indent: 0px; text-transform: none; white-space: pre-wrap; word-spacing: 0px; display: inline !important; float: none"><font color="rgb(34, 34, 34)" face="consolas, lucida console, courier new, monospace" size="12px">就是选择那些最大概率最小的样本进行标注</font></span>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="边缘采样（Margin Sampling）" FOLDED="true" ID="ID_344924916" CREATED="1622624289560" MODIFIED="1622624289560">
<node ID="ID_1411887874" CREATED="1622624503206" MODIFIED="1622624512879"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(34, 34, 34); font-family: consolas, lucida console, courier new, monospace; font-size: 12px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: left; text-indent: 0px; text-transform: none; white-space: pre-wrap; word-spacing: 0px; display: inline !important; float: none"><font color="rgb(34, 34, 34)" face="consolas, lucida console, courier new, monospace" size="12px">就是选择模型预测最大和第二大的概率差值最小的样本</font></span>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="熵方法（Entropy）" FOLDED="true" ID="ID_1732171721" CREATED="1622624289568" MODIFIED="1622624289568">
<node ID="ID_1207229765" CREATED="1622624580656" MODIFIED="1622624580656"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(34, 34, 34); font-family: consolas, lucida console, courier new, monospace; font-size: 12px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: left; text-indent: 0px; text-transform: none; white-space: pre-wrap; word-spacing: 0px; display: inline !important; float: none"><font color="rgb(34, 34, 34)" face="consolas, lucida console, courier new, monospace" size="12px">在二分类或者多分类的场景下，可以选择那些熵比较大的样本数据作为待定标注数据</font></span>
  </body>
</html>
</richcontent>
</node>
</node>
</node>
</node>
<node TEXT="基于委员会的查询（Query-By-Committee）" FOLDED="true" ID="ID_730031577" CREATED="1622621040085" MODIFIED="1622621040085">
<node ID="ID_616152033" CREATED="1622624658137" MODIFIED="1622624658137"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(34, 34, 34); font-family: consolas, lucida console, courier new, monospace; font-size: 12px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: left; text-indent: 0px; text-transform: none; white-space: pre-wrap; word-spacing: 0px; display: inline !important; float: none"><font color="rgb(34, 34, 34)" face="consolas, lucida console, courier new, monospace" size="12px">通过多个模型投票的模式，来选择出那些较“难”区分的样本数据</font></span>
  </body>
</html>
</richcontent>
</node>
<node TEXT="在 QBC（Query-By-Committee）的技术方案中，可以假设有 $C$ 个模型， 期参数分别是$\{\theta^{C}\}$, 并且这些模型都是通过数据集$L$训练得到的" ID="ID_198787477" CREATED="1622624698388" MODIFIED="1622626758864" FORMAT="latexPatternFormat"/>
<node TEXT="样本选择方法" FOLDED="true" ID="ID_1746537460" CREATED="1622626911703" MODIFIED="1622626978046">
<node TEXT="投票熵（Vote Entropy）：选择这些模型都无法区分的样本数据" FOLDED="true" ID="ID_484130572" CREATED="1622626922954" MODIFIED="1622626922954">
<node TEXT="用熵来衡量样本数据被这些分类器区分的难易程度,如果这些分类器都把样本数据划分到某一类，则容易区分; 如果分类器把样本数据划分到多类，则表示难以区分，需要重点关注。" ID="ID_695032831" CREATED="1622627365901" MODIFIED="1622627365901"/>
</node>
<node TEXT="平均 KL 散度（Average Kullback-Leibler Divergence）：选择 KL 散度较大的样本数据" FOLDED="true" ID="ID_1849623892" CREATED="1622626922954" MODIFIED="1622626922954">
<node TEXT="$x_{K L}^{*}=\operatorname{argmax}_{x} \frac{1}{C} \sum_{c=1}^{C} D\left(P_{\theta^{(c)}} \| P_{\mathcal{C}}\right)$ \\&#xa;\\&#xa;$P_{\mathcal{C}}\left(y_{i} \mid x\right)=\frac{1}{C} \sum_{c=1}^{C} P_{\theta^{(c)}}\left(y_{i} \mid x\right)$" ID="ID_132132382" CREATED="1622627511990" MODIFIED="1622627634706" FORMAT="latexPatternFormat"/>
<node TEXT="其中C表示分类器的个数" ID="ID_126339850" CREATED="1622627525013" MODIFIED="1622627544155"/>
</node>
</node>
</node>
<node TEXT="基于模型变化期望的查询（Expected Model Change）" FOLDED="true" ID="ID_1685062421" CREATED="1622621040089" MODIFIED="1622621040089">
<node ID="ID_1462948746" CREATED="1622627146610" MODIFIED="1622627173474"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(34, 34, 34); font-family: consolas, lucida console, courier new, monospace; font-size: 12px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: left; text-indent: 0px; text-transform: none; white-space: pre-wrap; word-spacing: 0px; display: inline !important; float: none"><font color="rgb(34, 34, 34)" face="consolas, lucida console, courier new, monospace" size="12px">选择那些使得梯度变化最大的样本数据。</font></span>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="基于误差减少的查询（Expected Error Reduction）" FOLDED="true" ID="ID_1226090302" CREATED="1622621040091" MODIFIED="1622621040091">
<node ID="ID_16185734" CREATED="1622627226522" MODIFIED="1622627226522"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(34, 34, 34); font-family: consolas, lucida console, courier new, monospace; font-size: 12px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: left; text-indent: 0px; text-transform: none; white-space: pre-wrap; word-spacing: 0px; display: inline !important; float: none"><font color="rgb(34, 34, 34)" face="consolas, lucida console, courier new, monospace" size="12px">选择那些通过增加一个样本就使得 loss 函数减少最多的样本数据</font></span>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="基于方差减少的查询（Variance Reduction）" FOLDED="true" ID="ID_847954440" CREATED="1622621040094" MODIFIED="1622621040094">
<node ID="ID_309010150" CREATED="1622627242298" MODIFIED="1622627242298"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(34, 34, 34); font-family: consolas, lucida console, courier new, monospace; font-size: 12px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: left; text-indent: 0px; text-transform: none; white-space: pre-wrap; word-spacing: 0px; display: inline !important; float: none"><font color="rgb(34, 34, 34)" face="consolas, lucida console, courier new, monospace" size="12px">选择那些方差减少最多的样本数据。</font></span>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="基于密度权重的查询（Density-Weighted Methods）" FOLDED="true" ID="ID_1848003890" CREATED="1622621040095" MODIFIED="1622621040095">
<node TEXT="对于那些分布在稠密区域的 且 难以区分的样本数据，进行人工/专家 标注的价值更大，于是，可以在使用不确定性采样或者 QBC 方法的时候，将样本数据的稠密性考虑进去。" ID="ID_531298006" CREATED="1622628060302" MODIFIED="1622628060302"/>
<node TEXT="Density-Weighted-Methods-query.jpg" ID="ID_1971836619" CREATED="1622700806515" MODIFIED="1622700806548">
<hook URI="Machine-Learning_files/Density-Weighted-Methods-query.jpg" SIZE="1.0" NAME="ExternalObject"/>
</node>
</node>
</node>
</node>
</node>
<node TEXT="conclusion" FOLDED="true" ID="ID_1882252657" CREATED="1611279375633" MODIFIED="1622621259413">
<node TEXT="主动学习（Active Learning）关键在于如何选择出合适的标注候选集给人工进行标注，而选择的方法就是所谓的查询策略（Query Strategy）。" ID="ID_226366175" CREATED="1622621341634" MODIFIED="1622621341634"/>
<node TEXT="查询策略可以基于单个机器学习模型，也可以基于多个机器学习模型，在实际使用的时候可以根据情况来决定。" ID="ID_1189507357" CREATED="1622621341634" MODIFIED="1622621341634"/>
<node TEXT="主动学习都是为了降低标注成本，迅速提升模型效果而存在的。" ID="ID_877108972" CREATED="1622621341647" MODIFIED="1622621341647"/>
</node>
<node TEXT="tool kit" FOLDED="true" ID="ID_900771449" CREATED="1622622000042" MODIFIED="1622622006609">
<node TEXT="modAL" ID="ID_687493873" CREATED="1622622017789" MODIFIED="1622622040506" LINK="https://github.com/modAL-python/modAL"/>
</node>
</node>
</node>
<node TEXT="" FOLDED="true" ID="ID_1053071426" CREATED="1565622631882" MODIFIED="1589533143852">
<edge COLOR="#808080"/>
<node TEXT="Generative Methods" FOLDED="true" ID="ID_1436859427" CREATED="1565622636999" MODIFIED="1584717762584">
<edge COLOR="#808080"/>
<node TEXT="Benefits" FOLDED="true" ID="ID_930190714" CREATED="1586755101056" MODIFIED="1586756105331">
<edge COLOR="#808080"/>
<node TEXT="With the assumption of probability distribution, more robust to the noise" ID="ID_273377487" CREATED="1586755479836" MODIFIED="1586756110024">
<edge COLOR="#808080"/>
</node>
<node TEXT="数据量: With the assumption of probability distribution, 数据量少时,Generative更有优势, 数据量大时 Discriminative 更有优势." ID="ID_1902859308" CREATED="1586755529850" MODIFIED="1586756110029">
<edge COLOR="#808080"/>
</node>
<node TEXT="Priors and class-dependent probabilities can be estimated from different sources." ID="ID_1054225220" CREATED="1586755926064" MODIFIED="1586756110031"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      &#29983;&#25104;&#27169;&#22411;&#30340;&#20808;&#39564;&#27010;&#29575;&#21644;&#27169;&#22411;&#38656;&#35201;&#20272;&#35745;&#30340;&#27010;&#29575;&#20351;&#29992;&#19981;&#21516;&#30340;&#25968;&#25454;&#28304;
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Popular models" FOLDED="true" ID="ID_1200086278" CREATED="1565622636999" MODIFIED="1584717762584">
<edge COLOR="#808080"/>
<node TEXT="Mixtures of Gaussians, Mixtures of experts, Hidden Markov Models(HMM)" ID="ID_522440271" CREATED="1565622636999" MODIFIED="1584717762584">
<edge COLOR="#808080"/>
</node>
<node TEXT="Gaussians, Naïve Bayes, Mixtures of multinomials" ID="ID_1948564411" CREATED="1565622636999" MODIFIED="1584717762586">
<edge COLOR="#808080"/>
</node>
<node TEXT="Sigmoidal belief networks, Bayesian networks, Markov random fields" ID="ID_1034377781" CREATED="1565622636999" MODIFIED="1584717762587">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="example" FOLDED="true" ID="ID_1985450469" CREATED="1609000789555" MODIFIED="1609001866230"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      二分类问题
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="- Given labelled training examples $x \in C_1, C_2$&#xa;\\&#xa;- looking for most likely prior probability $P(C_i)$ and classdependent probability $P(x|C_i)$&#xa;\\&#xa;- $P(x|C_i)$ is a Gaussian parameterized by $\mu_i$ and $\Sigma$&#xa;\\&#xa;- With $P(C_1),  P(C_2), \mu_1, \mu_2, \Sigma$&#xa;\\&#xa;$$P(C_1 | x) = \frac{P(x|C_1)  P(C_1)}{P(x|C_1)  P(C_1) + P(x|C_2)  P(C_2)}$$" FOLDED="true" ID="ID_12656461" CREATED="1609001119465" MODIFIED="1609001866230" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="class-example-Generative.png" ID="ID_1674928673" CREATED="1609001758044" MODIFIED="1609001866245">
<hook URI="Machine-Learning_files/class-example-Generative.png" SIZE="0.8746356" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Discriminative Methods" FOLDED="true" ID="ID_1183693317" CREATED="1565622636999" MODIFIED="1589533143851">
<edge COLOR="#808080"/>
<node TEXT="Directly estimate posterior probabilities. No attempt to model underlying probability istributions. Focus computational resources on given task– better performance" ID="ID_401203301" CREATED="1565622637015" MODIFIED="1584717762588">
<edge COLOR="#808080"/>
</node>
<node TEXT="Popular Models" FOLDED="true" ID="ID_29044731" CREATED="1565622637015" MODIFIED="1584717762589">
<edge COLOR="#808080"/>
<node TEXT="Logistic regression, SVMs" ID="ID_849295168" CREATED="1565622637015" MODIFIED="1584717762590">
<edge COLOR="#808080"/>
</node>
<node TEXT="Traditional neural networks, Nearest neighbor" ID="ID_402973257" CREATED="1565622637015" MODIFIED="1584717762590">
<edge COLOR="#808080"/>
</node>
<node TEXT="Conditional Random Fields (CRF)" ID="ID_528545251" CREATED="1565622637015" MODIFIED="1584717762590">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
</node>
<node TEXT="Class Imbalance" FOLDED="true" ID="ID_68227767" CREATED="1566577032441" MODIFIED="1614644956472">
<edge COLOR="#808080"/>
<node TEXT="分类问题中, 个类别的样本数据相差悬殊" ID="ID_1011399005" CREATED="1566577049257" MODIFIED="1584717762590">
<edge COLOR="#808080"/>
</node>
<node TEXT="解决方法" FOLDED="true" ID="ID_29068117" CREATED="1566577098755" MODIFIED="1614644956472">
<edge COLOR="#808080"/>
<node TEXT="过采样(over-sampling)" FOLDED="true" ID="ID_1409740924" CREATED="1566577107357" MODIFIED="1612768322881">
<edge COLOR="#808080"/>
<node FOLDED="true" ID="ID_454351798" CREATED="1612768299363" MODIFIED="1612768309978"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span class="fontstyle0">random over-sampling</span><br align="-webkit-auto" style="font-variant: normal; letter-spacing: normal; line-height: normal; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px"/>
  </body>
</html>
</richcontent>
<node ID="ID_872942675" CREATED="1612768434625" MODIFIED="1612768986252"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <p>
      随机过采样采取简单复制样本的策略来增加少数类样本，这样容易产生模型过拟合的问题，即使得模型学习到的信息过于Specific 而不够泛化(General)
    </p>
  </body>
</html>
</richcontent>
<arrowlink SHAPE="CUBIC_CURVE" COLOR="#000000" WIDTH="2" TRANSPARENCY="200" DASH="3 3" FONT_SIZE="9" FONT_FAMILY="SansSerif" DESTINATION="ID_1532651447" STARTINCLINATION="369.74999 pt;0 pt;" ENDINCLINATION="369.74999 pt;0 pt;" STARTARROW="NONE" ENDARROW="DEFAULT"/>
</node>
</node>
<node TEXT="SMOTEs" FOLDED="true" ID="ID_1532651447" CREATED="1612768366702" MODIFIED="1612768373953">
<node TEXT="introduction" FOLDED="true" ID="ID_698532505" CREATED="1611279340765" MODIFIED="1612768595983">
<node TEXT="它是随机过采样算法的一种改进方案;" ID="ID_288012994" CREATED="1612764722056" MODIFIED="1612764722056"/>
<node TEXT="基本思想：对少数类样本进行分析并根据少数类样本人工合成新样本添加到数据集中" ID="ID_1865496044" CREATED="1612764722056" MODIFIED="1612764730561"/>
</node>
<node TEXT="How" FOLDED="true" ID="ID_1018895258" CREATED="1611279370912" MODIFIED="1612769158310">
<node TEXT="SMOTE-Regular" FOLDED="true" ID="ID_628766964" CREATED="1612766163078" MODIFIED="1612766166923">
<node TEXT="SMOTE-overview.png" ID="ID_1700094166" CREATED="1612846748296" MODIFIED="1612846748320">
<hook URI="Machine-Learning_files/SMOTE-overview.png" SIZE="1.0" NAME="ExternalObject"/>
</node>
<node TEXT="方法" FOLDED="true" ID="ID_404196987" CREATED="1612769591008" MODIFIED="1612769602805">
<node TEXT="generated new synthetic examples along&#xa;the line between the minority examples and their selected nearest neighbors" ID="ID_330151699" CREATED="1612769567900" MODIFIED="1612769573241"/>
</node>
<node TEXT="步骤" FOLDED="true" ID="ID_1114393943" CREATED="1612766244904" MODIFIED="1612766251009">
<node TEXT="(1) 根据样本不平衡比例设置一个采样比例以确定采样倍率 $N$;" ID="ID_1763394904" CREATED="1612765297106" MODIFIED="1612765349132" FORMAT="latexPatternFormat"/>
<node TEXT="(2)对于少数类中每一个样本$x_i$ ，以欧氏距离为标准计算它到少数类样本集中所有样本的距离，得到其 $k$ 近邻;" ID="ID_52065961" CREATED="1612765297106" MODIFIED="1612765335341" FORMAT="latexPatternFormat"/>
<node TEXT="(3)对于每一个少数类样本 $x_i$ ，从其 $k$ 近邻中随机选择若干个样本，假设选择的近邻为 $\hat{x}_i$;" ID="ID_1409620954" CREATED="1612765297117" MODIFIED="1612765354473" FORMAT="latexPatternFormat"/>
<node TEXT="(4)对于每一个随机选出的近邻 $\hat{x}_i$ ，分别与原样本按照如下的公式构建新的样本: \\&#xa;$x_{new} = x + rand(0, 1) \times (\hat{x}_i - x) $  \\&#xa;按照倍率 $N$ 产生足够的样本。" ID="ID_1668879202" CREATED="1612765297122" MODIFIED="1612765454818" FORMAT="latexPatternFormat"/>
</node>
<node TEXT="缺陷" FOLDED="true" ID="ID_1663437966" CREATED="1612765935814" MODIFIED="1612769125138">
<arrowlink SHAPE="CUBIC_CURVE" COLOR="#000000" WIDTH="2" TRANSPARENCY="200" DASH="3 3" FONT_SIZE="9" FONT_FAMILY="SansSerif" DESTINATION="ID_703961742" STARTINCLINATION="81 pt;0 pt;" ENDINCLINATION="81 pt;0 pt;" STARTARROW="NONE" ENDARROW="DEFAULT"/>
<node TEXT="一是在近邻选择时,存在一定的盲目性。 K值的确定需要反复确认。" ID="ID_559884351" CREATED="1612765935814" MODIFIED="1612765935814"/>
<node TEXT="该算法无法克服非平衡数据集的数据分布问题,容易产生分布边缘化问题。" ID="ID_1103034636" CREATED="1612765935814" MODIFIED="1612765935814"/>
</node>
</node>
<node TEXT="SMOTE-Borderline1/SMOTE-Borderline2" FOLDED="true" ID="ID_703961742" CREATED="1612766204024" MODIFIED="1612769333827"><richcontent CONTENT-TYPE="xml/" TYPE="DETAILS" HIDDEN="true">
<html>
  <head>
    
  </head>
  <body>
    <p>
      Han H , Wang W Y , Mao B H . Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning[C]. 2005.
    </p>
  </body>
</html></richcontent>
<node TEXT="基本思想：only the minority examples near the borderline are over-sampled" ID="ID_429130642" CREATED="1612769400529" MODIFIED="1612769421142"/>
</node>
</node>
</node>
</node>
<node TEXT="欠采样(under-sampling)" FOLDED="true" ID="ID_773613534" CREATED="1566577117249" MODIFIED="1612768357816">
<edge COLOR="#808080"/>
<node ID="ID_400467663" CREATED="1612768340262" MODIFIED="1612768351799"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span class="fontstyle0">random under-sampling</span><br align="-webkit-auto" style="font-variant: normal; letter-spacing: normal; line-height: normal; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px"/>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="class sensitive Cost Function" ID="ID_19329530" CREATED="1566577122412" MODIFIED="1584717762590">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Data Processing" POSITION="left" ID="ID_1777714941" CREATED="1564977400569" MODIFIED="1584717762590" STYLE="fork">
<edge COLOR="#808080"/>
<node TEXT="Data Type" FOLDED="true" ID="ID_1304240173" CREATED="1565148775374" MODIFIED="1584717762590">
<edge COLOR="#808080"/>
<node TEXT="attribute-type.png" ID="ID_1633864227" CREATED="1587101339474" MODIFIED="1588157718697">
<hook URI="Machine-Learning_files/attribute-type.png" SIZE="0.5208333" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Data Exploration" FOLDED="true" ID="ID_1545263262" CREATED="1565150535773" MODIFIED="1584717762590">
<edge COLOR="#808080"/>
<node TEXT="Variable Identification" FOLDED="true" ID="ID_1689322430" CREATED="1565150548745" MODIFIED="1584717762591">
<edge COLOR="#808080"/>
<node TEXT="1.Identify Predictor (Input) and Target (output) variables.&#xa;2.identify the data type of the variables." ID="ID_129422306" CREATED="1565150590824" MODIFIED="1584717762591">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Univariate Analysis" FOLDED="true" ID="ID_1928342615" CREATED="1565150553215" MODIFIED="1584717762591">
<edge COLOR="#808080"/>
<node TEXT="Continuous Features" FOLDED="true" ID="ID_620820872" CREATED="1565150684308" MODIFIED="1584717762592">
<edge COLOR="#808080"/>
<node TEXT="统计量" FOLDED="true" ID="ID_1868613986" CREATED="1565151092484" MODIFIED="1584717762592">
<edge COLOR="#808080"/>
<node TEXT="Mean,Median, Mode, Variance, Standard;&#xa;Min, Max, Range, Quartile, IQR;&#xa;Deviation, Skewness and kurtosis," ID="ID_1593694653" CREATED="1565151121057" MODIFIED="1584717762592">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="图表" FOLDED="true" ID="ID_424456431" CREATED="1565151101023" MODIFIED="1584717762593">
<edge COLOR="#808080"/>
<node TEXT="PDF, Histogram, Box Plot" ID="ID_631278788" CREATED="1565151130127" MODIFIED="1584717762593">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Categorical Features" FOLDED="true" ID="ID_193430327" CREATED="1565150695403" MODIFIED="1584717762593">
<edge COLOR="#808080"/>
<node TEXT="Frequency:(频率表:用于描述一个分类变量的各类别的样本量)&#xa;Histogram(频率直方图)" ID="ID_1001812986" CREATED="1565151220606" MODIFIED="1584717762593">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Bi-variate Analysis" FOLDED="true" ID="ID_878789518" CREATED="1565150567854" MODIFIED="1584717762593">
<edge COLOR="#808080"/>
<node TEXT="Finds out the relationship between two variables." ID="ID_1116127575" CREATED="1565151355745" MODIFIED="1584717762594">
<edge COLOR="#808080"/>
</node>
<node TEXT="Scatter Plot" ID="ID_683788823" CREATED="1565151381743" MODIFIED="1584717762594">
<edge COLOR="#808080"/>
</node>
<node TEXT="Correlation Plot - Heatmap" ID="ID_1551422525" CREATED="1565151393423" MODIFIED="1584717762594">
<edge COLOR="#808080"/>
</node>
<node TEXT="" FOLDED="true" ID="ID_442802939" CREATED="1565151434946" MODIFIED="1584717762594">
<edge COLOR="#808080"/>
<node TEXT="Two-way table" FOLDED="true" ID="ID_88761914" CREATED="1565151442262" MODIFIED="1584717762594">
<edge COLOR="#808080"/>
<node TEXT="We can start analyzing the relationship by creating a two-way table of count and count%" ID="ID_85653598" CREATED="1565151498010" MODIFIED="1584717762594">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Stacked Column Chart" ID="ID_1212601012" CREATED="1565151457642" MODIFIED="1584717762595">
<edge COLOR="#808080"/>
</node>
<node TEXT="Chi-Square Test" FOLDED="true" ID="ID_1891072039" CREATED="1565151466675" MODIFIED="1584717762595" LINK="#ID_1414711160">
<edge COLOR="#808080"/>
<node TEXT="This test is used to derive the statistical  significance of relationship between the variables" ID="ID_1667490440" CREATED="1565151538673" MODIFIED="1584717762595">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Z-Test/ T-Test" ID="ID_732516650" CREATED="1565151476740" MODIFIED="1584717762596">
<edge COLOR="#808080"/>
</node>
<node TEXT="ANOVA" ID="ID_1473578885" CREATED="1565151484303" MODIFIED="1584717762596">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Feature Cleaning" FOLDED="true" ID="ID_1724386401" CREATED="1565151589845" MODIFIED="1584717762596">
<edge COLOR="#808080"/>
<node TEXT="Obvious inconsistencies" FOLDED="true" ID="ID_1362159420" CREATED="1565151621859" MODIFIED="1584717762596"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      &#26126;&#26174;&#30340;&#33258;&#30456;&#30683;&#30462;
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="eg. A person&apos;s age cannot be negative, a man cannot be pregnant" ID="ID_397399682" CREATED="1565159751361" MODIFIED="1584717762596">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Special values" FOLDED="true" ID="ID_779545416" CREATED="1565151607220" MODIFIED="1584717762597">
<edge COLOR="#808080"/>
<node TEXT="±Inf, NA and NaN" ID="ID_1121346779" CREATED="1565159622467" MODIFIED="1584717762597">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Outliers" FOLDED="true" ID="ID_165998164" CREATED="1565151614008" MODIFIED="1584717762597">
<edge COLOR="#808080"/>
<node TEXT="They should be detected, but not necessarily removed.&#xa;Their inclusion in the analysis is a statistical decision." ID="ID_412761044" CREATED="1565159655303" MODIFIED="1584717762597">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Missing Values" FOLDED="true" ID="ID_1577846678" CREATED="1565160599034" MODIFIED="1584717762598"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      Feature Imputation
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="Delete" FOLDED="true" ID="ID_1397016368" CREATED="1565160856434" MODIFIED="1584717762598">
<edge COLOR="#808080"/>
<node TEXT="delete the sample that has missing values" ID="ID_1506209513" CREATED="1565160868487" MODIFIED="1584717762598">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Hot-Deck" FOLDED="true" ID="ID_1326931978" CREATED="1565160656791" MODIFIED="1584717762598">
<edge COLOR="#808080"/>
<node TEXT="The technique then finds the first missing value and uses the cell value immediately prior to the data that are missing to impute the missing value." ID="ID_1755870683" CREATED="1565160678108" MODIFIED="1584717762598">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Cold-Deck" FOLDED="true" ID="ID_913856887" CREATED="1565160690755" MODIFIED="1584717762599">
<edge COLOR="#808080"/>
<node TEXT="Selects donors from another dataset to complete missing data." ID="ID_1554055737" CREATED="1565160706069" MODIFIED="1584717762599">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Mean-substitution" FOLDED="true" ID="ID_389559969" CREATED="1565160724500" MODIFIED="1584717762599">
<edge COLOR="#808080"/>
<node TEXT="replacing any missing value with the mean of that variable for all other cases, which has the benefit of not changing the sample mean for that variable." ID="ID_1829061985" CREATED="1565160769263" MODIFIED="1584717762599">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Regression" FOLDED="true" ID="ID_1680067205" CREATED="1565160787395" MODIFIED="1584717762600">
<edge COLOR="#808080"/>
<node TEXT="A regression model is estimated to predict observed values of a variable based on other variables, and that model is then used to impute values in cases where that variable is missing" ID="ID_1696349659" CREATED="1565160798898" MODIFIED="1584717762600">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Feature Engineering" FOLDED="true" ID="ID_1270471071" CREATED="1565160978902" MODIFIED="1614644794364">
<edge COLOR="#808080"/>
<node TEXT="Decompose" FOLDED="true" ID="ID_1453451401" CREATED="1565160987702" MODIFIED="1584717762601">
<edge COLOR="#808080"/>
<node TEXT="Converting 2014-09-20T20:45:40Z into categorical attributes like hour_of_the_day, part_of_day, etc." ID="ID_1508667188" CREATED="1565161076185" MODIFIED="1584717762601">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Discretization" FOLDED="true" ID="ID_1046728539" CREATED="1565161086610" MODIFIED="1584717762602">
<edge COLOR="#808080"/>
<node TEXT="Continuous Features" ID="ID_1374675364" CREATED="1565161098080" MODIFIED="1584717762602">
<edge COLOR="#808080"/>
</node>
<node TEXT="Categorical Features" FOLDED="true" ID="ID_1313252692" CREATED="1565161109430" MODIFIED="1584717762603">
<edge COLOR="#808080"/>
<node TEXT="eg.合并" ID="ID_314424685" CREATED="1565161148594" MODIFIED="1584717762603">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Reframe Numerical Quantities" FOLDED="true" ID="ID_1241219061" CREATED="1565161169666" MODIFIED="1614644794363" HGAP_QUANTITY="13.25 pt" VSHIFT_QUANTITY="-6 pt">
<edge COLOR="#808080"/>
<node TEXT="eg. Changing from grams to kg" ID="ID_1641557843" CREATED="1565161212482" MODIFIED="1584717762603">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Crossing" FOLDED="true" ID="ID_1223747304" CREATED="1565161226019" MODIFIED="1584717762603"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      &#29305;&#24449;&#32452;&#21512;
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="Creating new features as a combination of existing features. Could be multiplying numerical features, or combining categorical variables. This is a great way to add domain expertise knowledge to the dataset." ID="ID_241731629" CREATED="1565161266333" MODIFIED="1584717762603">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Feature Selection" FOLDED="true" ID="ID_294754808" CREATED="1565161349209" MODIFIED="1584717762604">
<edge COLOR="#808080"/>
<node TEXT="Correlation" FOLDED="true" ID="ID_18431391" CREATED="1566485048765" MODIFIED="1584717762604" LINK="#ID_302710005">
<edge COLOR="#808080"/>
<node TEXT="Features should be uncorrelated with each other and highly correlated to the feature we’re trying to predict." ID="ID_1370705219" CREATED="1566485373056" MODIFIED="1584717762604">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Dimensionality Reduction" FOLDED="true" ID="ID_580434903" CREATED="1565161379826" MODIFIED="1584717762605">
<edge COLOR="#808080"/>
<node TEXT="Principal Component Analysis (PCA)" FOLDED="true" ID="ID_411675615" CREATED="1565601317821" MODIFIED="1584717762605"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. This transformation is defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each&#160;&#160;succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components.
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="Plot the variance per feature and select the features with the largest variance." ID="ID_50764527" CREATED="1565601689360" MODIFIED="1584717762605">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Singular Value Decomposition (SVD)" FOLDED="true" ID="ID_1063787359" CREATED="1565601327474" MODIFIED="1584717762606"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      SVD is a factorization of a real or complex matrix. It is the generalization of the eigendecomposition of a positive semidefinite normal matrix (for example, a symmetric matrix with positive eigenvalues) to any m&#215;n matrix via an extension of the polar decomposition. It has many useful applications in signal processing and statistics.
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="$M=U \Sigma V$" ID="ID_124815744" CREATED="1565602281681" MODIFIED="1584717762606" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Importance" FOLDED="true" ID="ID_153493417" CREATED="1565161389137" MODIFIED="1584717762607">
<edge COLOR="#808080"/>
<node TEXT="fiter Methods" FOLDED="true" ID="ID_391421165" CREATED="1565602465531" MODIFIED="1584717762607"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      Filter type methods select features based only on general metrics like the correlation with the variable to predict. Filter methods suppress the least interesting variables. The other variables will be part of a classification or a regression model used to classify or to predict data. These methods are particularly effective in computation time and robust to overfitting.
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="Correlation" ID="ID_1666951880" CREATED="1565602519952" MODIFIED="1584717762607">
<edge COLOR="#808080"/>
</node>
<node TEXT="Linear Discriminant" ID="ID_1080598613" CREATED="1565602526324" MODIFIED="1584717762607">
<edge COLOR="#808080"/>
</node>
<node TEXT="ANOVA: Analysisi of Variance" ID="ID_126336168" CREATED="1565602549416" MODIFIED="1584717762607">
<edge COLOR="#808080"/>
</node>
<node TEXT="Chi-Square" ID="ID_1774129661" CREATED="1565602573741" MODIFIED="1584717762607">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Wrapper Methods" FOLDED="true" ID="ID_1699960240" CREATED="1565602468751" MODIFIED="1584717762607"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      Wrapper methods evaluate subsets of variables which allows, unlike filter approaches, to detect the possible interactions between variables. The two main disadvantages of these methods are : The increasing overfitting risk when the number of observations is insufficient. AND. The significant computation time when the number of variables is large.
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="Forward Selection" ID="ID_1685415896" CREATED="1565602715070" MODIFIED="1584717762608">
<edge COLOR="#808080"/>
</node>
<node TEXT="Backward Elimination" ID="ID_972229675" CREATED="1565602837695" MODIFIED="1584717762608">
<edge COLOR="#808080"/>
</node>
<node TEXT="Recursive Feature Ellimination" ID="ID_1379452818" CREATED="1565602837693" MODIFIED="1584717762608">
<edge COLOR="#808080"/>
</node>
<node TEXT="Genetic Algorithms" ID="ID_1480139912" CREATED="1565602837690" MODIFIED="1584717762608">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Embedded Methods" FOLDED="true" ID="ID_1182564700" CREATED="1565602489228" MODIFIED="1584717762608"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      Embedded methods try to combine the advantages of both previous methods. A learning algorithm takes advantage of its own variable selection process and performs feature selection and classification simultaneously.
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="Lasso regression performs L1 regularization" ID="ID_698001654" CREATED="1565602923432" MODIFIED="1584717762608">
<edge COLOR="#808080"/>
</node>
<node TEXT="Ridge regression performs L2 regularization" ID="ID_797829465" CREATED="1565602928180" MODIFIED="1584717762608">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Feature Encoding" FOLDED="true" ID="ID_1873609561" CREATED="1565603031451" MODIFIED="1584717762608"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      Machine Learning algorithms <b>perform Linear Algebra on Matrices</b>, which means all features must be numeric. Encoding helps us do this.
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="One Hot Encoding" ID="ID_596024979" CREATED="1565603073257" MODIFIED="1584717762608" LINK="#ID_849107871">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Feature Normalisation or Scaling" FOLDED="true" ID="ID_934175555" CREATED="1565603188343" MODIFIED="1584717762609"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization. Another reason why feature scaling is applied is that gradient descent converges much faster with feature scaling than without it.
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="x&apos; = \frac{x - \min(x)}{\max(x) - \min(x)}" FOLDED="true" ID="ID_1008970082" CREATED="1565603481715" MODIFIED="1584717762609" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="Rescaling" FOLDED="true" ID="ID_679768239" CREATED="1565603324232" MODIFIED="1584717762610">
<edge COLOR="#808080"/>
<node TEXT="rescaling the range of features to scale the range in [0, 1] or [−1, 1]." ID="ID_783265540" CREATED="1565603422050" MODIFIED="1584717762610">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="x&apos; = \frac{x - \bar x}{\sigma}" FOLDED="true" ID="ID_913704555" CREATED="1565603575164" MODIFIED="1584717762611" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="Standardization" FOLDED="true" ID="ID_1256758541" CREATED="1565603343576" MODIFIED="1584717762612">
<edge COLOR="#808080"/>
<node TEXT="Feature standardization makes the values of each feature in the data have zero-mean and unitvariance." ID="ID_209602981" CREATED="1565603540734" MODIFIED="1584717762612">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="$x&apos; = \frac{x}{||x||} $" FOLDED="true" ID="ID_737482120" CREATED="1565603671667" MODIFIED="1584717762613" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="Scaling to unit length" FOLDED="true" ID="ID_1022906954" CREATED="1565603351472" MODIFIED="1584717762613">
<edge COLOR="#808080"/>
<node TEXT="To scale the components of a feature vector such that the complete vector has length one." ID="ID_1409405684" CREATED="1565603615691" MODIFIED="1584717762613">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="$\frac{x}{x+k}$ \\&#xa;k is constant" ID="ID_1471911401" CREATED="1566449581957" MODIFIED="1584717762614" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Dataset Construction" FOLDED="true" ID="ID_113042362" CREATED="1565603710434" MODIFIED="1584717762615">
<edge COLOR="#808080"/>
<node TEXT="Training Dataset" FOLDED="true" ID="ID_128755810" CREATED="1565603967459" MODIFIED="1584717762615">
<edge COLOR="#808080"/>
<node TEXT="A set of examples used for learning" FOLDED="true" ID="ID_544300739" CREATED="1565603967459" MODIFIED="1584717762616">
<edge COLOR="#808080"/>
<node TEXT="To fit the parameters of the classifier in the Multilayer Perceptron, for instance, we would use the training set to find the “optimal” weights when using backprogapation." ID="ID_1117348368" CREATED="1565603967459" MODIFIED="1584717762616">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Test Dataset" FOLDED="true" ID="ID_619146717" CREATED="1565603967459" MODIFIED="1584717762617">
<edge COLOR="#808080"/>
<node TEXT="A set of examples used only to assess the performance of a fully-trained classifier" FOLDED="true" ID="ID_905023549" CREATED="1565603967461" MODIFIED="1584717762617">
<edge COLOR="#808080"/>
<node TEXT="In the Multilayer Perceptron case, we would use the test to estimate the error rate after we have chosen the final model (MLP size and actual weights) After assessing the final model on the test set, YOU MUST NOT tune the model any further." ID="ID_1201076791" CREATED="1565603967461" MODIFIED="1584717762618">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Validation Dataset" FOLDED="true" ID="ID_347795052" CREATED="1565603967461" MODIFIED="1584717762619">
<edge COLOR="#808080"/>
<node TEXT="A set of examples used to tune the parameters of a classifier" FOLDED="true" ID="ID_556514992" CREATED="1565603967461" MODIFIED="1584717762619">
<edge COLOR="#808080"/>
<node TEXT="In the Multilayer Perceptron case, we would use the validation set to find the “optimal” number of hidden units or determine a stopping point for the back-propagation algorithm" ID="ID_1018838460" CREATED="1565603967461" MODIFIED="1584717762619">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
</node>
<node TEXT="Model" LOCALIZED_STYLE_REF="AutomaticLayout.level,1" POSITION="right" ID="ID_234408247" CREATED="1564977421668" MODIFIED="1584717762620">
<edge COLOR="#808080"/>
<node TEXT="Regression" FOLDED="true" ID="ID_1705990166" CREATED="1565622906240" MODIFIED="1584717762620">
<edge COLOR="#808080"/>
<node TEXT="Linear Regression" ID="ID_1971679244" CREATED="1565623031754" MODIFIED="1584717762620">
<edge COLOR="#808080"/>
</node>
<node TEXT="Logistic Regression" ID="ID_1406992273" CREATED="1565623046147" MODIFIED="1584717762621">
<edge COLOR="#808080"/>
</node>
<node TEXT="Generalised Linear Models (GLMs)" FOLDED="true" ID="ID_795108512" CREATED="1565623115894" MODIFIED="1584717762622">
<edge COLOR="#808080"/>
<node TEXT="Is a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value." ID="ID_1673462003" CREATED="1565623221156" MODIFIED="1584717762623">
<edge COLOR="#808080"/>
</node>
<node TEXT="Link Function" FOLDED="true" ID="ID_499248085" CREATED="1565623221156" MODIFIED="1584717762624">
<edge COLOR="#808080"/>
<node TEXT="Identity" FOLDED="true" ID="ID_1217577677" CREATED="1565623221156" MODIFIED="1584717762624">
<edge COLOR="#808080"/>
<node TEXT="$​\mu=X\beta$" ID="ID_327891626" CREATED="1565623493160" MODIFIED="1584717762624" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Inverse" FOLDED="true" ID="ID_989897166" CREATED="1565623221156" MODIFIED="1584717762624">
<edge COLOR="#808080"/>
<node TEXT="$\mu=(X \beta)^{-1}$" ID="ID_874578844" CREATED="1565623466885" MODIFIED="1584717762624" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Logit" FOLDED="true" ID="ID_1047952228" CREATED="1565623221156" MODIFIED="1584717762625">
<edge COLOR="#808080"/>
<node TEXT="$\mu=\frac{1}{1+e^{(-X \beta)}}$" ID="ID_821137927" CREATED="1565623480844" MODIFIED="1584717762625" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Cost Function is found via Maximum Likelihood Estimation" ID="ID_1772839902" CREATED="1565623221156" MODIFIED="1584717762625">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="LOESS-Locally Estimated Scatterplot Smoothing" ID="ID_781046922" CREATED="1565623679234" MODIFIED="1584717762625">
<edge COLOR="#808080"/>
</node>
<node TEXT="Ridge Regression" ID="ID_1484944392" CREATED="1565623679234" MODIFIED="1584717762626">
<edge COLOR="#808080"/>
</node>
<node TEXT="LASSO-Least Absolute Shrinkage and Selection Operator" ID="ID_1404081907" CREATED="1565623679234" MODIFIED="1584717762627">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Bayesian" FOLDED="true" ID="ID_568003604" CREATED="1565622930089" MODIFIED="1584717762628">
<edge COLOR="#808080"/>
<node TEXT="Naive Bayes \\&#xa;$p(C_k | x) = \frac{p(C_k)p(x | C_k)}{p(x)}$" FOLDED="true" ID="ID_1834364947" CREATED="1565623781171" MODIFIED="1584717762628" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="$\hat y = \arg\max_{k \in \{1, \dots, K\}} p(C_k)\prod_{i=1}^n p(x_i | C_k)$ \\&#xa;Naive Bayes Classifier. We neglect the denominator as we calculate for every class and pick the max of the numerator" ID="ID_1923761228" CREATED="1565623964105" MODIFIED="1584717762629" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Bayesian Belieg Network" ID="ID_278330904" CREATED="1566832672174" MODIFIED="1584717762629">
<edge COLOR="#808080"/>
</node>
<node TEXT="Multinomial Naive Bayes" ID="ID_1838946566" CREATED="1565623801040" MODIFIED="1584717762629">
<edge COLOR="#808080"/>
</node>
<node TEXT="Gaussian Naive Bayes" ID="ID_1093671090" CREATED="1566832646654" MODIFIED="1584717762630">
<edge COLOR="#808080"/>
</node>
<node TEXT="probabilistic graphical models" FOLDED="true" ID="ID_970079624" CREATED="1565624579369" MODIFIED="1584717762630">
<edge COLOR="#808080"/>
<node TEXT="Bayesian Networks" FOLDED="true" ID="ID_785230072" CREATED="1565624809357" MODIFIED="1584717762630"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      <font color="rgb(85, 85, 85)" face="Lato, PingFang SC, Microsoft YaHei, sans-serif" size="16px">&#36830;&#25509;&#20855;&#26377;&#26041;&#21521; &#30340; &#27010;&#29575;&#22270;&#27169;&#22411;, &#20063;&#31216;&#20026;&#21448;&#21521;&#22270;&#27169;&#22411;</font>
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="图模型与联合分布的对应关系" FOLDED="true" ID="ID_633127503" CREATED="1565624809357" MODIFIED="1584717762630">
<edge COLOR="#808080"/>
<node TEXT="- 使用圆圈表示随机变量；" ID="ID_654554160" CREATED="1565624809357" MODIFIED="1584717762630">
<edge COLOR="#808080"/>
</node>
<node TEXT="- 观测到的变量使用实心圆圈表示，隐变量使用空心圆圈表示；" ID="ID_1560777437" CREATED="1565624809357" MODIFIED="1584717762632">
<edge COLOR="#808080"/>
</node>
<node TEXT="- 使用一个方框(box)表示重复节点，其中右下角的N 表示重复次数；" ID="ID_802009031" CREATED="1565624809357" MODIFIED="1584717762634">
<edge COLOR="#808080"/>
</node>
<node TEXT="- 模型参数表示为实心小圆点，连随机变量的联合分布中是条件变量部分" ID="ID_1626205245" CREATED="1565624809357" MODIFIED="1584717762635">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="贝叶斯回归（图模型）" FOLDED="true" ID="ID_622336133" CREATED="1565624809357" MODIFIED="1584717762636" LINK="https://weirping.github.io/blog/Bayesian-Networks-regression.html">
<edge COLOR="#808080"/>
<node TEXT="参数估计" ID="ID_493575583" CREATED="1565624809357" MODIFIED="1584717762636">
<edge COLOR="#808080"/>
</node>
<node TEXT="预测分布" ID="ID_35340550" CREATED="1565624809357" MODIFIED="1584717762636">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="条件独立性" FOLDED="true" ID="ID_717281048" CREATED="1565624809357" MODIFIED="1584717762636" LINK="#ID_1242353026">
<edge COLOR="#808080"/>
<node TEXT="D-Separation(条件独立性工具)" ID="ID_1674078600" CREATED="1566537766434" MODIFIED="1584717762636">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Markov random fields" FOLDED="true" ID="ID_47503815" CREATED="1565624626480" MODIFIED="1584717762636"><richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      <font color="rgb(85, 85, 85)" face="Lato, PingFang SC, Microsoft YaHei, sans-serif" size="16px">&#36830;&#25509;&#26159;&#26080;&#26041;&#21521;&#24615; &#27010;&#29575;&#22270;&#27169;&#22411;, &#20063;&#31216;&#20026; &#26080;&#21521;&#22270;&#27169;&#22411;</font>
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
<node TEXT="条件独立性" ID="ID_1661314627" CREATED="1565624866980" MODIFIED="1584717762636" LINK="#ID_717281048">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Dimensionality Reduction" FOLDED="true" ID="ID_1407881926" CREATED="1565622951389" MODIFIED="1587137764090">
<edge COLOR="#808080"/>
<node TEXT="Principal Component Analysis (PCA)" ID="ID_723598189" CREATED="1565624934350" MODIFIED="1584717762637">
<edge COLOR="#808080"/>
</node>
<node TEXT="Kernel Principal Component Analysis (Kernel PCA)" ID="ID_1929375334" CREATED="1587103459592" MODIFIED="1587103595526">
<edge COLOR="#808080"/>
</node>
<node TEXT="Independent Component Analysis(ICA)" ID="ID_184689954" CREATED="1587103556917" MODIFIED="1587103595524">
<edge COLOR="#808080"/>
</node>
<node TEXT="Linear Discriminant Analysis (LDA)" ID="ID_1936268771" CREATED="1565624934365" MODIFIED="1587137764088">
<edge COLOR="#808080"/>
</node>
<node TEXT="" ID="ID_625399292" CREATED="1587137794383" MODIFIED="1587137794389">
<hook NAME="FirstGroupNode"/>
</node>
<node TEXT="Locally Linear Embedding (LLE)" FOLDED="true" ID="ID_480049787" CREATED="1587133336109" MODIFIED="1587135315767">
<edge COLOR="#808080"/>
<node TEXT="1. 学习每个点与其周围K(超参)个点的关系 $w_{ij}$" FOLDED="true" ID="ID_130092108" CREATED="1587133600889" MODIFIED="1587135315768" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="LLE-alg-1.png" ID="ID_1719940062" CREATED="1587133618463" MODIFIED="1589531525962">
<hook URI="Machine-Learning_files/LLE-alg-1.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="2. 固定上一步学到的所有 $w_{ij}$, 最小化  $\sum_i||z^i - \sum_j w_{ij}z^j||$, 产生的数据集 $\{z^i\}$, 就是新的数据" FOLDED="true" ID="ID_1809710183" CREATED="1587133798059" MODIFIED="1587135315768" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="LLE-alg-2.png" ID="ID_661731954" CREATED="1587134060376" MODIFIED="1587135315769">
<hook URI="Machine-Learning_files/LLE-alg-2.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="problem" FOLDED="true" ID="ID_791935878" CREATED="1587135088706" MODIFIED="1587135315769">
<edge COLOR="#808080"/>
<node TEXT="Similar data are close, but different data may collapse(相似样本点落到一起, 但是不同样本也会叠到一起)" FOLDED="true" ID="ID_1443423045" CREATED="1587135099761" MODIFIED="1587135315766">
<edge COLOR="#808080"/>
<node TEXT="LLE-data-collapse.png" ID="ID_1114216923" CREATED="1589532454124" MODIFIED="1589532457798">
<hook URI="Machine-Learning_files/LLE-data-collapse.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="T-distributed Stochastic Neighbor Embedding (t-SNE)" FOLDED="true" ID="ID_615212784" CREATED="1587134901078" MODIFIED="1587135315769">
<edge COLOR="#808080"/>
<node TEXT="t-SNE-alg.png" ID="ID_211145827" CREATED="1587135709027" MODIFIED="1587137199542">
<hook URI="Machine-Learning_files/t-SNE-alg.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
<node TEXT="相似度计算公式" FOLDED="true" ID="ID_1833629384" CREATED="1587136294582" MODIFIED="1587137199543">
<edge COLOR="#808080"/>
<node TEXT="原始数据上 $s(x^i, x^j) = exp(-||x^i - x^j||_2)$" ID="ID_476595166" CREATED="1587136313962" MODIFIED="1587137199544" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="在降维后的数据上 $s^“(z^i, z^j) = \frac{1}{1 + ||z^i - z^j||_2}$" ID="ID_1659002065" CREATED="1587136409161" MODIFIED="1587137199546" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="采用不同相似度度量原因" FOLDED="true" ID="ID_626146148" CREATED="1587136811131" MODIFIED="1587137199548">
<edge COLOR="#808080"/>
<node TEXT="t-SNE-sim-func.png" ID="ID_1537026735" CREATED="1587136614236" MODIFIED="1587137199530">
<hook URI="Machine-Learning_files/t-SNE-sim-func.png" SIZE="1.0" NAME="ExternalObject"/>
<richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      &#27178;&#36724;&#34920;&#31034;&#24231;&#26631;&#31354;&#38388;&#19978;&#30340;&#27431;&#27663;&#36317;&#31163;(&#21407;&#24231;&#26631;&#31354;&#38388;&#21644;&#26032;&#30340;&#25237;&#24433;&#31354;&#38388;),
    </p>
    <p>
      &#23558;x&#25237;&#24433;&#21040;z&#21518;:
    </p>
    <p>
      &#22914;&#26524;&#21407;&#22987;&#24231;&#26631;&#31354;&#38388;&#19978;&#30340;&#20004;&#20010;&#28857;&#36317;&#31163;&#36739;&#36828;, &#25237;&#24433;&#21040;&#26032;&#30340;&#24231;&#26631;&#31354;&#38388;&#21518;&#30340;&#36317;&#31163;&#20250;&#34987;&#25289;&#20280;&#30340;&#26356;&#36828;;
    </p>
    <p>
      &#22914;&#26524;&#21407;&#22987;&#24231;&#26631;&#31354;&#38388;&#19978;&#30340;&#20004;&#20010;&#28857;&#36317;&#31163;&#36739;&#36817;, &#25237;&#24433;&#21040;&#26032;&#30340;&#24231;&#26631;&#31354;&#38388;&#21518;&#30340;&#36317;&#22522;&#26412;&#24067;&#36941;(&#26410;&#34987;&#25289;&#20280;).
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="效果" FOLDED="true" ID="ID_440661575" CREATED="1589533040562" MODIFIED="1589533063105">
<edge COLOR="#808080"/>
<node TEXT="t-SNE-res.png" ID="ID_1025308636" CREATED="1589533054577" MODIFIED="1589533063104">
<hook URI="Machine-Learning_files/t-SNE-res.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="" ID="ID_228511725" CREATED="1587137794380" MODIFIED="1587137794383">
<hook NAME="SummaryNode"/>
<hook NAME="AlwaysUnfoldedNode"/>
<node TEXT="Manifold Learning" ID="ID_1019080084" CREATED="1587137794393" MODIFIED="1587137799952"/>
</node>
<node TEXT="Auto-Encoders" FOLDED="true" ID="ID_1481805563" CREATED="1566538011839" MODIFIED="1587137310033" LINK="https://weirping.github.io/blog/AutoEncoder.html">
<edge COLOR="#808080"/>
<node TEXT="Auto-Encoders.png" ID="ID_511756126" CREATED="1587137709393" MODIFIED="1587137726264">
<hook URI="Machine-Learning_files/Auto-Encoders.png" SIZE="0.94043887" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
<node TEXT="The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for the purpose of dimensionality reduction." ID="ID_448821999" CREATED="1567950999755" MODIFIED="1587137638916" VSHIFT_QUANTITY="2.25 pt">
<edge COLOR="#808080"/>
<font BOLD="false"/>
</node>
</node>
</node>
<node TEXT="Instance Based" FOLDED="true" ID="ID_273037839" CREATED="1565622967789" MODIFIED="1584717762637">
<edge COLOR="#808080"/>
<node TEXT="k-nearest Neighbour (kNN)" FOLDED="true" ID="ID_263635244" CREATED="1565624972563" MODIFIED="1584717762638">
<edge COLOR="#808080"/>
<node TEXT="特点" FOLDED="true" ID="ID_864901764" CREATED="1588661902390" MODIFIED="1588661983197">
<edge COLOR="#808080"/>
<node ID="ID_50563660" CREATED="1588661799863" MODIFIED="1588661983213"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(49, 70, 89); font-family: Lato, PingFang SC, Microsoft YaHei, sans-serif; font-size: 15px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: -webkit-left; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none"><font color="rgb(49, 70, 89)" face="Lato, PingFang SC, Microsoft YaHei, sans-serif" size="15px">一种分类(classification)算法</font></span>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
</node>
<node ID="ID_1871099888" CREATED="1588661825061" MODIFIED="1588661983213"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(49, 70, 89); font-family: Lato, PingFang SC, Microsoft YaHei, sans-serif; font-size: 15px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: -webkit-left; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none"><font color="rgb(49, 70, 89)" face="Lato, PingFang SC, Microsoft YaHei, sans-serif" size="15px">属于懒惰学习（lazy learning）即KNN没有显式的学习过程</font></span>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="思想" FOLDED="true" ID="ID_844014913" CREATED="1588661929883" MODIFIED="1588661983197">
<edge COLOR="#808080"/>
<node TEXT="knn-alg.png" ID="ID_1702843084" CREATED="1588661967654" MODIFIED="1588661983213">
<hook URI="Machine-Learning_files/knn-alg.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
<node TEXT="如果一个样本在特征空间中的k个最邻近的样本中的大多数属于某一个类别，则该样本也划分为这个类别。" ID="ID_1646067006" CREATED="1588661839076" MODIFIED="1588661983197">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="计算流程" FOLDED="true" ID="ID_460324165" CREATED="1588662125105" MODIFIED="1588662150287">
<edge COLOR="#808080"/>
<node TEXT="1）计算测试数据与各个训练数据之间的距离；" ID="ID_1483975228" CREATED="1588662135087" MODIFIED="1588662150287">
<edge COLOR="#808080"/>
</node>
<node TEXT="2）按照距离的递增关系进行排序；" ID="ID_621386162" CREATED="1588662135087" MODIFIED="1588662150287">
<edge COLOR="#808080"/>
</node>
<node TEXT="3）选取距离最小的K个点；" ID="ID_3470546" CREATED="1588662135087" MODIFIED="1588662150287">
<edge COLOR="#808080"/>
</node>
<node TEXT="4）确定前K个点所在类别的出现频率；" ID="ID_1621469801" CREATED="1588662135087" MODIFIED="1588662150287">
<edge COLOR="#808080"/>
</node>
<node TEXT="5）返回前K个点中出现频率最高的类别作为测试数据的预测分类" ID="ID_633482211" CREATED="1588662135102" MODIFIED="1588662150287">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="超参调整" FOLDED="true" ID="ID_1689156216" CREATED="1588662293382" MODIFIED="1588662534799">
<edge COLOR="#808080"/>
<node TEXT="K的取值过小时,容易受噪声影响. 相当于模型复杂度大.&#xa;K的值取的过大时，就相当于用较大邻域中的训练实例进行预测，学习的近似误差会增大。相当于模型复杂度小" ID="ID_603411674" CREATED="1588662523379" MODIFIED="1588662633478">
<edge COLOR="#808080"/>
</node>
<node TEXT="常用的方法是从K=1开始，使用检验集估计分类器的误差率。重复该过程，每次K增值1。选取产生最小误差率的K。&#xa;一般k的取值不超过20，上限是n的开方，随着数据集的增大，K的值也要增大。" ID="ID_1813203067" CREATED="1588662636914" MODIFIED="1588662726570">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="support vector machine (SVM)" LOCALIZED_STYLE_REF="styles.important" FOLDED="true" ID="ID_1772695711" CREATED="1589533513372" MODIFIED="1589798642282">
<edge COLOR="#808080"/>
<node TEXT="训练样本" FOLDED="true" ID="ID_90965433" CREATED="1589539397858" MODIFIED="1589539694377">
<edge COLOR="#808080"/>
<node TEXT="$\{x^{(i)}, y^{(i)}\}$ \\&#xa;$x$是特征，$y$ 是结果标签。\\&#xa;$i$ 表示第 $i$ 个样本, $i \in [1, n]$ \\&#xa;$y^{(i)} \in \{1, -1\}$" ID="ID_1518726642" CREATED="1589539561999" MODIFIED="1589539694375" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="模型" FOLDED="true" ID="ID_473320976" CREATED="1589539031198" MODIFIED="1589540830152">
<edge COLOR="#808080"/>
<node TEXT="$h_{w,b}(x) = g(z) = g(w^Tx+b)$" FOLDED="true" ID="ID_520202533" CREATED="1589539037394" MODIFIED="1589540830152" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="g(z)=&#xa;\left \{&#xa;\begin {align}&#xa;1; z \ge 0 \\&#xa;-1; z \lt 0&#xa;\end {align}&#xa;\right ." ID="ID_1126564049" CREATED="1589539122513" MODIFIED="1589539694377" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="两个间隔" FOLDED="true" ID="ID_509065046" CREATED="1589540173979" MODIFIED="1589540197658">
<edge COLOR="#808080"/>
<node TEXT="函数间隔" FOLDED="true" ID="ID_237650579" CREATED="1589539348055" MODIFIED="1589539694378">
<edge COLOR="#808080"/>
<node TEXT="$$ \hat \gamma^{(i)} = y^{(i)} (w^Tx^{(i)}  + b)$$" FOLDED="true" ID="ID_1135652012" CREATED="1589539726063" MODIFIED="1589539834914" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="等价于&#xa;$$&#xa;|w^tx{(i)}+ b|&#xa;$$" ID="ID_254505748" CREATED="1589539872296" MODIFIED="1589540099562" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="点$(x^{(i)}, y^{(i)})$到 分割平面 距离 的 ||W|| 倍数" FOLDED="true" ID="ID_573312967" CREATED="1589540054206" MODIFIED="1589540099560" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="svm-functional-margin.png" ID="ID_1879698824" CREATED="1589540159211" MODIFIED="1589787472794">
<hook URI="Machine-Learning_files/svm-functional-margin.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="全局函数间隔" FOLDED="true" ID="ID_1329403919" CREATED="1589540532030" MODIFIED="1589540789585">
<edge COLOR="#808080"/>
<node TEXT="$$\hat \gamma = \min_{i\in[1, m]} \hat \gamma^{(i)}$$" FOLDED="true" ID="ID_798204827" CREATED="1589540544491" MODIFIED="1589788595730" FORMAT="latexPatternFormat">
<node TEXT="在训练样本上分类正例和负例到分割平面距离最近的那个样本的函数间隔" ID="ID_1904677386" CREATED="1589540668147" MODIFIED="1589540789584">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="几何间隔" FOLDED="true" ID="ID_1278651156" CREATED="1589539357735" MODIFIED="1589540480593">
<edge COLOR="#808080"/>
<node TEXT="$$\gamma^{(i)} = y^{(i)}  \frac {w^Tx^{(i)}  + b}{|w|}$$" ID="ID_1611752875" CREATED="1589540296587" MODIFIED="1589540472594" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="点$(x^{(i)}, y^{(i)})$到 分割平面 距离 \\&#xa;归一化后的函数间隔" FOLDED="true" ID="ID_438408161" CREATED="1589540054206" MODIFIED="1589540480593" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="svm-functional-margin.png" ID="ID_596517314" CREATED="1589540159211" MODIFIED="1589540789584">
<hook URI="Machine-Learning_files/svm-functional-margin.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="全局结合间隔" FOLDED="true" ID="ID_408906240" CREATED="1589540735190" MODIFIED="1589540789585">
<edge COLOR="#808080"/>
<node TEXT="$$\gamma = \min_{i\in[1, m]} \gamma^{(i)}$$" FOLDED="true" ID="ID_1314053168" CREATED="1589540745641" MODIFIED="1589788639761" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="在训练样本上分类正例和负例到分割平面距离最近的那个样本的几何间隔" ID="ID_1597569486" CREATED="1589540668147" MODIFIED="1589540789582">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
</node>
<node TEXT="目标函数" FOLDED="true" ID="ID_1865988730" CREATED="1589540836425" MODIFIED="1589787385300">
<edge COLOR="#808080"/>
<node TEXT="几何间隔最大" ID="ID_119225343" CREATED="1589792790506" MODIFIED="1589792813236">
<edge COLOR="#808080"/>
</node>
<node TEXT="\begin {align}&#xa;\max_{w, b} &amp; \;\; \gamma \\&#xa;\text{ s.t. } &amp; y^{(i)}(w^Tx^{(i)} + b) \ge \gamma, i\in [1, m] \\&#xa;&amp; \|w\| = 1&#xa;\end {align}" FOLDED="true" ID="ID_668078186" CREATED="1589791543059" MODIFIED="1589792635506" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="等价与 \\&#xa;\begin {align}&#xa;\min_{w, b} &amp; \;\; \frac{1}{2}\|w\|^2 \\&#xa;\text{ s.t. } &amp; y^{(i)}(w^Tx^{(i)} + b) \ge 1, i\in [1, m] \\&#xa;\end {align}" ID="ID_963547155" CREATED="1589792705540" MODIFIED="1589797889269" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="引入核函数" FOLDED="true" ID="ID_802866047" CREATED="1589795509858" MODIFIED="1589796757862">
<edge COLOR="#808080"/>
<node TEXT="核函数" FOLDED="true" ID="ID_355948794" CREATED="1589793477654" MODIFIED="1589793955446">
<edge COLOR="#808080"/>
<node TEXT="定义" FOLDED="true" ID="ID_1785431245" CREATED="1589793937830" MODIFIED="1589793955445">
<edge COLOR="#808080"/>
<node TEXT="设$x,z \in X$, $X$属于 $R^{(n)}$ 空间,非线性函数 $\phi$ 将输入空间$X$到特征空间$F$的映射($F$为$m$维), 其中$F$属于$R^{(m)}$, 且 $n&lt;&lt;m$。核函数形式化定义为：\\&#xa;$$&#xa;K(x, z) = \phi(x)^T \phi(z)&#xa;$$" ID="ID_349058615" CREATED="1589793941098" MODIFIED="1589793955446" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="作用" FOLDED="true" ID="ID_1364741265" CREATED="1589795218922" MODIFIED="1589795434351">
<edge COLOR="#808080"/>
<node TEXT="样例可能存在线性不可分的情况，而将特征映射到高维空间后，往往就可分了" ID="ID_1353129388" CREATED="1589795223946" MODIFIED="1589795434351">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="" FOLDED="true" ID="ID_687675658" CREATED="1589794338043" MODIFIED="1589795434352">
<edge COLOR="#808080"/>
<node TEXT="多项式核函数" FOLDED="true" ID="ID_492598753" CREATED="1589794339738" MODIFIED="1589795434352">
<edge COLOR="#808080"/>
<node TEXT="$k(x, z) = (x^Tz + c)^d$" ID="ID_910699805" CREATED="1589795070003" MODIFIED="1589795434352" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="高斯核函数" FOLDED="true" ID="ID_1641858104" CREATED="1589794354309" MODIFIED="1589795434352">
<edge COLOR="#808080"/>
<node TEXT="$$K(x, z) = \exp(-\frac{\|x-z\|^2}{2 \sigma^2})$$" ID="ID_1231468232" CREATED="1589794526981" MODIFIED="1589795434352" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="如果 $x$ 和 $z$ 很相近$(\|x − z\| \approx  0)$，那么核函数值为 1，如果 $x$ 和 $z$ 相差很大 $\|x − z\|  \gg 0$，那么核函数值约等于 0。由于这个函数类似于高斯分布，因此称为高斯核函数，也叫做径向基函数(Radial Basis Function  简称 RBF)。" ID="ID_1559112778" CREATED="1589794856117" MODIFIED="1589795434354" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="它能够把原始特征映射到无穷维。" ID="ID_1926225192" CREATED="1589794440102" MODIFIED="1589795434354">
<edge COLOR="#808080"/>
</node>
<node TEXT="gaussian-kernel.png" ID="ID_553295615" CREATED="1589795425186" MODIFIED="1589795434351">
<hook URI="Machine-Learning_files/gaussian-kernel.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
</node>
<node TEXT="Hinge Loss: 松弛变量" FOLDED="true" ID="ID_825060700" CREATED="1589797629212" MODIFIED="1590467388073" LINK="#ID_1469695736">
<edge COLOR="#808080"/>
<node TEXT="解决线性不可分的情况" ID="ID_1897924387" CREATED="1589864470199" MODIFIED="1589864479416">
<edge COLOR="#808080"/>
</node>
<node TEXT="svm-non-separable.png" ID="ID_1753551873" CREATED="1589797678690" MODIFIED="1589797830574">
<hook URI="Machine-Learning_files/svm-non-separable.png" SIZE="1.0" NAME="ExternalObject"/>
<richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      一个离群点（可能是噪声）可以造成超平面的移动，间隔缩小，可见以前的模型对噪声非常敏感。再有甚者，如果离群点在另外一个类中，那么这时候就是线性不可分了。
    </p>
  </body>
</html></richcontent>
<edge COLOR="#808080"/>
</node>
<node TEXT="$$&#xa;\begin {align}&#xa;\min_{w, b} &amp; \;\; \frac{1}{2}\|w\|^2 + C\sum_{i=1}^m \xi_i \\&#xa;\text{ s.t. } &amp; y^{(i)}(w^Tx^{(i)} + b) \ge 1 - \xi_i, i\in [1, m] \\&#xa;&amp; xi_i \ge 0, i\in [1, m] \\&#xa;\end {align}&#xa;$$" ID="ID_1505234957" CREATED="1589798057305" MODIFIED="1589798085604" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="求解用到的方法" FOLDED="true" ID="ID_849615692" CREATED="1589792877197" MODIFIED="1589793078943">
<edge COLOR="#808080"/>
<node TEXT="拉格朗日对偶（Lagrange duality）" ID="ID_1588360838" CREATED="1589792905557" MODIFIED="1589793282736" LINK="#ID_446260867">
<edge COLOR="#808080"/>
</node>
<node TEXT="KKT条件" FOLDED="true" ID="ID_1275606180" CREATED="1589793039187" MODIFIED="1589793282738" LINK="#ID_395919799">
<edge COLOR="#808080"/>
<node TEXT="svm-kkt.png" ID="ID_1512663095" CREATED="1589798161980" MODIFIED="1589798224377">
<hook URI="Machine-Learning_files/svm-kkt.png" SIZE="1.0" NAME="ExternalObject"/>
<richcontent TYPE="NOTE" CONTENT-TYPE="xml/">
<html>
  <head>
    
  </head>
  <body>
    <p>
      第一个式子表明在两条间隔线外的样本点前面的系数为 0，离群样本点前面的系数为 C，而支持向量（也就是在超平面两边的最大间隔线上）的样本点前面系数在(0,C)上。
    </p>
  </body>
</html></richcontent>
</node>
</node>
<node TEXT="SMO 优化算法（Sequential minimal optimization）" FOLDED="true" ID="ID_327847724" CREATED="1589798291117" MODIFIED="1589798337946">
<edge COLOR="#808080"/>
<node TEXT="SMO 算法由 Microsoft Research 的 John C. Platt 在 1998 年提出，并成为最快的二次规划优化算法，特别针对线性 SVM 和数据稀疏时性能更优。" ID="ID_1064725963" CREATED="1589798323791" MODIFIED="1589798337945">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="最优间隔分类器(optimal margin classifier)" FOLDED="true" ID="ID_1003638947" CREATED="1589796766661" MODIFIED="1589796804013">
<edge COLOR="#808080"/>
<node TEXT="$$&#xa;\begin {align}&#xa;w^Tx + b &amp;= \Big(\sum_{i=1}^m \alpha_i y^{(i)} x^{(i)} \Big)^T x + b \\&#xa; &amp;= \sum_{i=1}^m \alpha_i y^{(i)} &lt;x^{(i)}, x&gt; + b&#xa;\end {align}&#xa;$$" FOLDED="true" ID="ID_489915504" CREATED="1589796806180" MODIFIED="1589797476453" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="$\alpha_i$ 为目标函数中(类似与拉格朗日乘数法)不等式约束项的系数, $\bf \alpha = {\alpha_1, \dots, \alpha_m}$称为支持向量" ID="ID_1100436416" CREATED="1589797414507" MODIFIED="1589797476453" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="按照模型定义: 要确定测试样本的类别, 首先根据 $w$ 和 $b$ 做一次线性运算，然后看求的结果是大于 0 还是小于 0,来判断正例还是负例。&#xa;\\&#xa;实际上有了$\alpha_i$, 我们不需要求出 $w$，只需将测试样本和训练数据中的所有样本做内积和即可." ID="ID_825773106" CREATED="1589797446773" MODIFIED="1589797476451" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="当模型中引入了核函数时, 只需要将 只需将&lt;x^{(i)},x&gt;替换成K(x^{(i)}, x) 即可." ID="ID_1905931971" CREATED="1589798412325" MODIFIED="1589798600581" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="与 logistic regression 的区别" FOLDED="true" ID="ID_920967443" CREATED="1589787653475" MODIFIED="1589787844144">
<edge COLOR="#808080"/>
<node TEXT="logistic regression, 要求所有的点都尽量远离分割超平面.&#xa;即. 已经远离的点可能通过调整中间线使其能够更加远离." ID="ID_1859173501" CREATED="1589788061818" MODIFIED="1589788452999">
<edge COLOR="#808080"/>
</node>
<node TEXT="SVM 更应该关心靠近分割超平面的点，希望这些点尽可能地远分割超平面, 不考虑远离分割超平面的点.&#xa;即. 只考虑局部最优（不关心已经确定远离的点）" ID="ID_1359808524" CREATED="1589787877700" MODIFIED="1589788452998">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Tree Based" FOLDED="true" ID="ID_1644028801" CREATED="1566832837765" MODIFIED="1584717762638">
<edge COLOR="#808080"/>
<node TEXT="Decision Tree" FOLDED="true" ID="ID_1479976465" CREATED="1565622983395" MODIFIED="1584717762638">
<edge COLOR="#808080"/>
<node TEXT="Classification and Regression Tree (CART)" ID="ID_154253200" CREATED="1565624990058" MODIFIED="1584717762638">
<edge COLOR="#808080"/>
</node>
<node TEXT="C4.5" ID="ID_688195699" CREATED="1566833683881" MODIFIED="1584717762638">
<edge COLOR="#808080"/>
</node>
<node TEXT="C5.0" ID="ID_112396880" CREATED="1566833689790" MODIFIED="1584717762638">
<edge COLOR="#808080"/>
</node>
<node TEXT="Conditional Decision Trees" ID="ID_515554500" CREATED="1565624990058" MODIFIED="1584717762638">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Ensemble" FOLDED="true" ID="ID_1840026485" CREATED="1566832896908" MODIFIED="1584717762638">
<edge COLOR="#808080"/>
<node TEXT="Bagging-Booststrapped Aggregation" FOLDED="true" ID="ID_1885652903" CREATED="1566833022793" MODIFIED="1584717762638">
<edge COLOR="#808080"/>
<node TEXT="Random Forest" FOLDED="true" ID="ID_342582071" CREATED="1565624990058" MODIFIED="1584717762638">
<edge COLOR="#808080"/>
<node TEXT="train L different models and then make predictions using the average of the predictions made by each model" ID="ID_1639142722" CREATED="1566833035856" MODIFIED="1584717762638">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Boosting" FOLDED="true" ID="ID_694055638" CREATED="1566833107986" MODIFIED="1584717762639">
<edge COLOR="#808080"/>
<node TEXT="training multiple models in sequence in which the error function used to train a particular model depends on the performance of the previous models" ID="ID_896497945" CREATED="1566833168875" MODIFIED="1584717762639">
<edge COLOR="#808080"/>
</node>
<node TEXT="AdaBoost" ID="ID_361392904" CREATED="1566833524475" MODIFIED="1584717762640">
<edge COLOR="#808080"/>
</node>
<node TEXT="Gradient Boost" FOLDED="true" ID="ID_863663718" CREATED="1566833599218" MODIFIED="1584717762640">
<edge COLOR="#808080"/>
<node TEXT="Gradient Boosted Regression Trees (GBRT)" FOLDED="true" ID="ID_580020835" CREATED="1565624990058" MODIFIED="1584717762640" LINK="https://weirping.github.io/blog/GBDT.html">
<edge COLOR="#808080"/>
<node TEXT="Xgboost" ID="ID_1925814597" CREATED="1566489914856" MODIFIED="1584717762641" LINK="#ID_994376312">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="GBM-Gradient Boosting Machines" ID="ID_1827805813" CREATED="1566833795398" MODIFIED="1584717762641">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="GBDT知识体系" LOCALIZED_STYLE_REF="AutomaticLayout.level,5" FOLDED="true" ID="ID_142943693" CREATED="1564976333940" MODIFIED="1612850102369" STYLE="fork" SHAPE_HORIZONTAL_MARGIN="10 pt" SHAPE_VERTICAL_MARGIN="10 pt">
<hook NAME="NodeConditionalStyles">
    <conditional_style ACTIVE="true" LOCALIZED_STYLE_REF="AutomaticLayout.level,1" LAST="false">
        <node_level_condition VALUE="1" COMPARATION_RESULT="0" SUCCEED="true"/>
    </conditional_style>
</hook>
<node TEXT="原理" FOLDED="true" ID="ID_1499191559" CREATED="1588748140624" MODIFIED="1588748173131">
<edge COLOR="#808080"/>
<node TEXT="Gradient" FOLDED="true" ID="ID_109545228" CREATED="1588748177023" MODIFIED="1588750269784">
<edge COLOR="#808080"/>
<node TEXT="对于一个优化目标函数 \\&#xa;&#xa;$$\min_{\Theta} \mathcal J(\Theta) $$ \\&#xa;&#xa;其中 $\Theta$ 为参数。求解$\Theta$ 的迭代公式为: \\&#xa;&#xa;$$\Theta^{i+1} = \Theta^i - \alpha \nabla \mathcal J(\Theta)|_{\Theta^i} $$\\&#xa;&#xa;其中 $\alpha$ 为学习率\\" ID="ID_1402577284" CREATED="1588748286829" MODIFIED="1588763341473" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Boosting" FOLDED="true" ID="ID_1774778850" CREATED="1588748417753" MODIFIED="1588926269294">
<edge COLOR="#808080"/>
<node TEXT="对于一个预测任务，使用了M个模型， 那么对于一条数据$x_i$ 的预测值可以表示为： \\&#xa;$$\hat y_i = \sum_{m=1}^M \beta_m b(x_i, \gamma_m)$$ \\&#xa;那么, 预测任务的优化目标就是: \\&#xa;$$\min_{\{\beta_m, \gamma_m\}_1^M}  \sum_{i=1}^N L[y_i,  \sum_{m=1}^M \beta_m b(x_i, \gamma_m)]$$ \\&#xa;其中： $N$ 为训练样本量。 \\" FOLDED="true" ID="ID_1368824605" CREATED="1588749726729" MODIFIED="1588926269290" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="- $b$ : 基础模型， 对于分类任务来说，也称为 基分类器 \\" ID="ID_1967014430" CREATED="1588750994368" MODIFIED="1588751016260" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="- $\beta$: 每个基础模型在总的预测结果中占有的权重 \\" ID="ID_820761014" CREATED="1588750994368" MODIFIED="1588751016262" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="- $\gamma$: 每个基础模型的参数 \\" ID="ID_1525523886" CREATED="1588750994377" MODIFIED="1588751016262" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Gradient + Boosting" FOLDED="true" ID="ID_1866098128" CREATED="1588750246293" MODIFIED="1588750269786">
<edge COLOR="#808080"/>
<node TEXT="给定样本量为 $N$ 样本集, 求预测模型 $f(x)$ \\&#xa;$$\vec f = {\arg\min}_{\vec f} \mathcal L(\vec y, \vec f)  ={\arg\min}_{\vec f}   \sum_{i=1}^N L[y_i,  f(x_i)]$$ \\" FOLDED="true" ID="ID_569132354" CREATED="1588750286101" MODIFIED="1588763467294" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="$\vec f = \{f(x_1), f(x_2), \dots , f(x_N) \}$ \\" ID="ID_1504707742" CREATED="1588751044288" MODIFIED="1588751065950" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="$\vec y = y_1, y_2, \dots, y_N $ , 向量的长度和样本量相同 \\" ID="ID_1403483654" CREATED="1588751044288" MODIFIED="1588751065952" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="$\mathcal L(\vec y, \vec f)$ 是整个样本集的损失函数 \\" ID="ID_1295531426" CREATED="1588751044291" MODIFIED="1588751065952" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="应用Gradient原理" FOLDED="true" ID="ID_943142619" CREATED="1588751921204" MODIFIED="1588752027729" FORMAT_AS_HYPERLINK="false">
<edge COLOR="#808080"/>
<node TEXT="认为 $\vec f$ 为参数, 求能使损失函数最小的$\vec f$, 使用梯度下降的理论求解$\min_{\vec f}\mathcal L(\vec y, \vec f)$ 在$ \vec f_{m-1}$ 处的梯度： \\&#xa;$$\vec g_m = [\frac{\partial \mathcal L(\vec y, \vec f)}{\partial {\vec f}}] | _{\vec f = \vec f_{m-1}}$$ \\&#xa;那么求解$\vec f_m$ 的迭代公式为:  \\&#xa;$$\vec f_m = \vec f_{m-1} + \alpha_m (- \vec g_m)$$  \\&#xa;其中： $\alpha$ 为每一步的步长.  在GBDT里为超参。" ID="ID_288078592" CREATED="1588750601269" MODIFIED="1588763486196" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="应用Boosting" FOLDED="true" ID="ID_1536634075" CREATED="1588751953401" MODIFIED="1588752452036">
<edge COLOR="#808080"/>
<node TEXT="使用梯度下降法进行 $m$ 轮迭代后, $\vec f_m$为:  \\&#xa;$$\vec f_m =  \alpha_0 (- \vec g_0) + \alpha_1 (- \vec g_1) + \alpha_2 (- \vec g_2) + \dots + \alpha_m (- \vec g_m)$$" FOLDED="true" ID="ID_692744879" CREATED="1588752133942" MODIFIED="1588763528453" FORMAT="latexPatternFormat">
<font BOLD="true"/>
<edge COLOR="#808080"/>
<node TEXT="每一步的 $(- \vec g)$ 都表示一个基础模型的预测结果。\\&#xa;那么最终的模型预测结果是所有单个模型预测结果的累加；" ID="ID_1891582015" CREATED="1588752194724" MODIFIED="1588752268868" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="增加新的模型，使结果在前一步的基础上更加逼近最优点；" ID="ID_1375676904" CREATED="1588752194724" MODIFIED="1588752277962" FORMAT="STANDARD_FORMAT">
<edge COLOR="#808080"/>
</node>
<node TEXT="新模型预测的目标值的是上一个模型的残差。" ID="ID_532786565" CREATED="1588752194732" MODIFIED="1588752310745" FORMAT="STANDARD_FORMAT">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="(DT)Regression Tree" FOLDED="true" ID="ID_1223845531" CREATED="1588752591701" MODIFIED="1588752633409">
<edge COLOR="#808080"/>
<node TEXT="决策树可以被定义为： \\&#xa;$T(x; \Theta) = \sum_{j=i}^J \gamma_j I(x \in R_j)$ \\" FOLDED="true" ID="ID_71771371" CREATED="1588752703489" MODIFIED="1588752922174" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="$\Theta = \{R_j, \gamma_j\}_1^J$  表示模型参数; \\&#xa;$J$ 表示决策树叶子节点的数量; \\" ID="ID_1541744943" CREATED="1588752777249" MODIFIED="1588752950385" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="使用决策树预测每个 $-\vec g_i$" ID="ID_845125769" CREATED="1588756222255" MODIFIED="1588936058465" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="实现" FOLDED="true" ID="ID_433109473" CREATED="1588748147670" MODIFIED="1588748173132">
<edge COLOR="#808080"/>
<node TEXT="基本流程" FOLDED="true" ID="ID_512264523" CREATED="1588760831956" MODIFIED="1588760859854">
<edge COLOR="#808080"/>
<node TEXT="gbdt-alg.png" FOLDED="true" ID="ID_887704567" CREATED="1588756567335" MODIFIED="1588756742654">
<hook URI="Machine-Learning_files/gbdt-alg.png" SIZE="0.86580086" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
<node TEXT="单次迭代的流程: \\&#xa;1, 计算梯度$[\frac{\partial \mathcal L(\vec y, \vec f)}{\partial {\vec f}}] | _{\vec f = \vec f_{m-1}}$; \\&#xa;2, 确定决策树的结构; \\&#xa;3, 确定决策输叶子节点的预测值; \\&#xa;4, 更新$f(x)$. \\" ID="ID_1764360441" CREATED="1588756887275" MODIFIED="1588936257625" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Xgboost实现" FOLDED="true" ID="ID_1227010371" CREATED="1588760866593" MODIFIED="1588760876084">
<edge COLOR="#808080"/>
<node TEXT="模型定义" FOLDED="true" ID="ID_1200321801" CREATED="1588762861283" MODIFIED="1588762890883">
<edge COLOR="#808080"/>
<node TEXT="Tree Ensemble 模型定义为 由 $K$ 个回归树相加组成的模型：\\&#xa;&#xa;$$\hat y_i= \sum_{i=1}^K f_k(x_i), f_k \in \mathcal F$$ \\&#xa;&#xa;其中: $\mathcal F$ 表示回归树的集合, 定义为: \\&#xa;&#xa;$$\mathcal F = \{ f(x) = w_{q(x)}\} (q: R^m \to T, w \in R^T)$$ \\" FOLDED="true" ID="ID_1929336232" CREATED="1588762871551" MODIFIED="1588763267322" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="$q$ 表示一个树的结构，其作用就是将一个具有 $m$ 维特征的 sample 映射到 $T$ 个叶子节点上。 \\&#xa;即，$q: R^m \to T$ 。 $q(x)$ 表示叶子节点的序号。" ID="ID_1365342174" CREATED="1588763048865" MODIFIED="1588763125775" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="$w$ 是一个$T$维向量，每个维度对应树的一个叶子节点, \\&#xa;表示回归树中每个叶子节点的取值。 \\&#xa;$w_{q(x)}$ 表示样本 $x$ 在回归树上的预测值。" ID="ID_475148307" CREATED="1588763048865" MODIFIED="1588763193861" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Target Function" FOLDED="true" ID="ID_312704144" CREATED="1588762900643" MODIFIED="1588763605342">
<edge COLOR="#808080"/>
<node TEXT="$$&#xa;\begin {align}&#xa;obj = \sum_{i=1}^N L(y_i, \hat y_i)  + \sum_{k=1}^K \Omega (f_k) \\&#xa;where\ \ \Omega (f) = \gamma T + \frac 12 \lambda||w||^2&#xa;\end {align}&#xa;$$" FOLDED="true" ID="ID_127107048" CREATED="1588763233837" MODIFIED="1589863862298" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="Loss Function $L(y_i, \hat y_i)$" FOLDED="true" ID="ID_382797977" CREATED="1588763550387" MODIFIED="1588763737941" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="不同的任务选用不同的Loss Function" ID="ID_400095208" CREATED="1588763675065" MODIFIED="1588763734365">
<edge COLOR="#808080"/>
</node>
<node TEXT="回归" FOLDED="true" ID="ID_574105867" CREATED="1588763707150" MODIFIED="1588763734366">
<edge COLOR="#808080"/>
<node TEXT="(Square loss)  $L(y_i, \hat y_i) = (y- \hat y_i)^2 $" ID="ID_1084540387" CREATED="1588763769350" MODIFIED="1588763824439" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="分类" FOLDED="true" ID="ID_1398025289" CREATED="1588763711568" MODIFIED="1588763734366">
<edge COLOR="#808080"/>
<node TEXT="交叉熵损失函数" ID="ID_1534510231" CREATED="1588763799841" MODIFIED="1588763824439">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Ranking" FOLDED="true" ID="ID_972609222" CREATED="1588763713698" MODIFIED="1588763734366">
<edge COLOR="#808080"/>
<node TEXT="NDCG" ID="ID_5727250" CREATED="1588763817278" MODIFIED="1588763824438">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="模型正则项" FOLDED="true" ID="ID_1305615277" CREATED="1588763646313" MODIFIED="1588763737941">
<edge COLOR="#808080"/>
<node TEXT="" ID="ID_181120757" CREATED="1588763956235" MODIFIED="1588763956236">
<hook NAME="FirstGroupNode"/>
</node>
<node TEXT="$\gamma T$ 倾向于选择叶子节点少的回归树（结构简单）；" ID="ID_1477000297" CREATED="1588763917714" MODIFIED="1588763928816" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="$\frac 12 \lambda||w||^2$倾向于预测值稳定的树（预测值）" ID="ID_936029511" CREATED="1588763917714" MODIFIED="1588763928815" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="" ID="ID_1759006295" CREATED="1588763956234" MODIFIED="1588763956235">
<hook NAME="SummaryNode"/>
<hook NAME="AlwaysUnfoldedNode"/>
<node TEXT="Intuitively, the regularized objective will tend to select a model employing simple and predictive functions." ID="ID_376015101" CREATED="1588763956237" MODIFIED="1588763963088">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="$K$: 回归树的数量" ID="ID_821392410" CREATED="1588936423743" MODIFIED="1588936448028" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="第t颗数的产生" FOLDED="true" ID="ID_468876926" CREATED="1588822214119" MODIFIED="1588822352532">
<edge COLOR="#808080"/>
<node TEXT="优化目标" FOLDED="true" ID="ID_847902030" CREATED="1588822377248" MODIFIED="1588822391635">
<edge COLOR="#808080"/>
<node TEXT="$$\tilde{\mathcal L}^{(t)} = \sum_{i=1}^N [ g_i f_t(x_i) + \frac 12 h_i f^2_t(x_i)]  + \Omega (f_t)$$ \\&#xa;&#xa;其中:\\&#xa;&#xa;$$ &#xa;\hat y_i^{(t)} = \sum_{k=1}^t f_k(x_i)  = \hat y_i^{(t-1)} +  f_t(x_i) \\&#xa;g_i = \frac {\partial L(y_i, \hat y_i )} {\partial \hat y_i }|_{\hat y_i^{(t-1)}} \\&#xa;h_i= \frac {\partial ^2 L(y_i, \hat y_i )} {\partial \hat y_i^2 }|_{\hat y_i^{(t-1)}}&#xa;$$" FOLDED="true" ID="ID_512103602" CREATED="1588822356502" MODIFIED="1588822614349" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="使用了 Target Function 以$f_t(x_x)$为变量的二级泰勒展开" ID="ID_1944042593" CREATED="1588822459727" MODIFIED="1588822680890" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="\tilde{\mathcal L}^{(t)}对第 t 步所有可能的候选决策树$f_t$进行打分，能够使 $\tilde{\mathcal L}^{(t)}$ 最小的一个 $f_t$ 就是这一步需要的决策树。" ID="ID_444421503" CREATED="1588822718531" MODIFIED="1588823002729" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="对上式整理: \\&#xa;$$\tilde{\mathcal L}^{(t)} =  \sum_{j=1}^T [G_j w_j + \frac 12 (H_j + \lambda) w_j^2 ]  + \gamma T$$" FOLDED="true" ID="ID_820098785" CREATED="1588823190317" MODIFIED="1588823277388" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="$G_j, H_j$ 只与树结构 $q$ 有关" ID="ID_1186176508" CREATED="1588823301510" MODIFIED="1588823426434" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
<node TEXT="$\tilde{\mathcal L}^{(t)}$ 只与 $q$ 和 $w$ 有关" FOLDED="true" ID="ID_3759284" CREATED="1588823416766" MODIFIED="1588823647274" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="可以先确定q再确定w" ID="ID_1234909250" CREATED="1588823650015" MODIFIED="1588823672410"/>
</node>
</node>
</node>
<node TEXT="叶子节点预测值$w$" FOLDED="true" ID="ID_120640338" CREATED="1588823179602" MODIFIED="1588823513904" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="对于确定的数的结构 $q$ \\&#xa;$\hat w_j = - \frac {G_j}{H_j + \lambda}$" ID="ID_1913799796" CREATED="1588823563067" MODIFIED="1588823712784" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="决策树结构$q$" FOLDED="true" ID="ID_649935728" CREATED="1588823775672" MODIFIED="1588823983633" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="的结构分(structure score) \\&#xa;$$&#xa;\begin {aligned}&#xa;\tilde{\mathcal L}^{(t)} &amp;= - \frac 12 \sum_{j=1}^T \frac {G_j^2}{H_j + \lambda}  + \gamma T \\&#xa;&amp;= - \frac 12 \sum_{j=1}^T \frac {(\sum_{i \in I_j} g_i)^2}{(\sum_{i \in I_j} h_i) + \lambda}  + \gamma T&#xa;\end {aligned}&#xa;$$" FOLDED="true" ID="ID_241501066" CREATED="1588823857034" MODIFIED="1588824107500" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="对于一个结构确定的回归树 $q$，$\tilde{\mathcal L}^{(t)}$ 的取值与$w$ 是无关的。" ID="ID_791001208" CREATED="1588824069486" MODIFIED="1588824076085" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="枚举所有可能的结构, 选 出能够使 Structure Score 最小的一个" FOLDED="true" ID="ID_1505270510" CREATED="1588824185701" MODIFIED="1588824587760">
<edge COLOR="#808080"/>
<node TEXT="1. Start from tree with depth 0" ID="ID_1499646724" CREATED="1588824323015" MODIFIED="1588824444134">
<edge COLOR="#808080"/>
</node>
<node TEXT="2. For each leaf node of the tree, try to add a split." ID="ID_668113131" CREATED="1588824323015" MODIFIED="1612850078360">
<arrowlink SHAPE="CUBIC_CURVE" COLOR="#000000" WIDTH="2" TRANSPARENCY="200" DASH="2 7" FONT_SIZE="9" FONT_FAMILY="SansSerif" DESTINATION="ID_216792838" STARTINCLINATION="424.49999 pt;0 pt;" ENDINCLINATION="424.49999 pt;0 pt;" STARTARROW="NONE" ENDARROW="NONE"/>
<edge COLOR="#808080"/>
</node>
<node TEXT="3. 重复第二步，直到达到最大深度" ID="ID_1965180029" CREATED="1588824323020" MODIFIED="1588824444135">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="节点的分割点划分" FOLDED="true" ID="ID_216792838" CREATED="1588824258650" MODIFIED="1588824444135">
<edge COLOR="#808080"/>
<node TEXT="$$&#xa;\begin {aligned}&#xa;\mathrm{gain} &amp;=  \mathcal L -  (\mathcal L_L + \mathcal L_R) \\&#xa;&amp;= \frac 12 \left[ \frac {(\sum_{i \in I_L} g_i)^2}{(\sum_{i \in I_L} h_i)} + \frac {(\sum_{i \in I_R} g_i)^2}{(\sum_{i \in I_R} h_i)} - \frac {(\sum_{i \in I} g_i)^2}{(\sum_{i \in I} h_i)} \right] - \gamma&#xa;\end {aligned}&#xa;$$" FOLDED="true" ID="ID_619973220" CREATED="1588824736114" MODIFIED="1588824833612" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
<node TEXT="$I_L$ 和$I_R$ 分别表示一个叶子节点split后左边和右边节点的样本集合， $I = I_L \cup I_R$" ID="ID_827066716" CREATED="1588824822342" MODIFIED="1588824833614" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="选取够使Structure Score减少最多的一个特征分割方案" FOLDED="true" ID="ID_72987506" CREATED="1588824556203" MODIFIED="1588824643733">
<edge COLOR="#808080"/>
<node TEXT="所有特征的所有值作为候选分割点" ID="ID_1322990178" CREATED="1588824653454" MODIFIED="1588824697548">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="xgboost-gen-tree-alg.png" ID="ID_1383935918" CREATED="1588824973472" MODIFIED="1588824983781">
<hook URI="Machine-Learning_files/xgboost-gen-tree-alg.png" SIZE="0.9584665" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="categorical-features处理" FOLDED="true" ID="ID_1341670258" CREATED="1588820979176" MODIFIED="1588821059255">
<edge COLOR="#808080"/>
<node TEXT="One-Hot" FOLDED="true" ID="ID_1690855671" CREATED="1588821044082" MODIFIED="1588821544541">
<edge COLOR="#808080"/>
<node TEXT="可能无法在这个类别特征上进行切分" FOLDED="true" ID="ID_1041655031" CREATED="1588821265855" MODIFIED="1588821544541">
<edge COLOR="#808080"/>
<node TEXT="当特征维度高时，每个类别上的数据都会比较少，这时候产生的切分不平衡，切分增益（split gain）也会很小" ID="ID_1218541319" CREATED="1588821251292" MODIFIED="1588821544541">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="会影响决策树的学习" FOLDED="true" ID="ID_506515100" CREATED="1588821282210" MODIFIED="1588825325039">
<edge COLOR="#808080"/>
<node ID="ID_684927390" CREATED="1588821331127" MODIFIED="1588825325039"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(77, 77, 77); font-family: Microsoft YaHei, SF Pro Display, Roboto, Noto, Arial, PingFang SC, sans-serif; font-size: 16px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none"><font color="rgb(77, 77, 77)" face="Microsoft YaHei, SF Pro Display, Roboto, Noto, Arial, PingFang SC, sans-serif" size="16px">决策树学习时利用的是切分数据的统计信息，onehot编码可能把数据切分成很多零散的小数据集, 在这些数据量小的空间上，统计信息不准确，学习会变差.</font></span>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node FOLDED="true" ID="ID_373392571" CREATED="1588821095006" MODIFIED="1588825554724"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(77, 77, 77); font-family: Microsoft YaHei, SF Pro Display, Roboto, Noto, Arial, PingFang SC, sans-serif; font-size: 16px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none"><font color="rgb(77, 77, 77)" face="Microsoft YaHei, SF Pro Display, Roboto, Noto, Arial, PingFang SC, sans-serif" size="16px">类别特征的最优切分</font></span>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
<node TEXT="lightGBM实现了该方法" ID="ID_230490970" CREATED="1588821099608" MODIFIED="1588821544543">
<edge COLOR="#808080"/>
</node>
<node TEXT="categorical-features-split-lgbm.png" ID="ID_490566903" CREATED="1588821154220" MODIFIED="1588821544543">
<hook URI="Machine-Learning_files/categorical-features-split-lgbm.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="类别特征embeding" FOLDED="true" ID="ID_1200017519" CREATED="1588821499620" MODIFIED="1588821544543">
<edge COLOR="#808080"/>
<node ID="ID_714225351" CREATED="1588821533532" MODIFIED="1588821544543"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span style="color: rgb(77, 77, 77); font-family: Microsoft YaHei, SF Pro Display, Roboto, Noto, Arial, PingFang SC, sans-serif; font-size: 16px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; word-spacing: 0px; background-color: rgb(255, 255, 255); display: inline !important; float: none"><font color="rgb(77, 77, 77)" face="Microsoft YaHei, SF Pro Display, Roboto, Noto, Arial, PingFang SC, sans-serif" size="16px">把类别特征转成one-hot coding扔到NN里训练个embedding</font></span>
  </body>
</html>
</richcontent>
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="其他" FOLDED="true" ID="ID_1324497192" CREATED="1588825243198" MODIFIED="1588825310557">
<edge COLOR="#808080"/>
<node TEXT="Shrinkage" ID="ID_394460210" CREATED="1588825304334" MODIFIED="1588825310558">
<edge COLOR="#808080"/>
</node>
<node TEXT="Subsampling" ID="ID_1278932922" CREATED="1588825304334" MODIFIED="1588825310558">
<edge COLOR="#808080"/>
</node>
<node TEXT="Column Subsampling" ID="ID_704653892" CREATED="1588825304336" MODIFIED="1588825310558">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="特点" FOLDED="true" ID="ID_1160080906" CREATED="1588825476164" MODIFIED="1588825527200">
<edge COLOR="#808080"/>
<node TEXT="1. 增加了模型正则项，GBDT算法中并没有使用正则化项；" ID="ID_1716997588" CREATED="1588825520198" MODIFIED="1588825523768">
<edge COLOR="#808080"/>
</node>
<node TEXT="2. 还使用了多种技术解决过拟合问题，如subsample，Shrinkage，Column Subsampling；" ID="ID_1986403057" CREATED="1588825520198" MODIFIED="1588825523772">
<edge COLOR="#808080"/>
</node>
<node TEXT="3. 使用了二阶泰勒展开式近似目标函数，GBDT中使用的是直接使用的一阶梯度。即, 求解方式分别使用了牛顿法和梯度下降法" ID="ID_279278725" CREATED="1588825520207" MODIFIED="1588825523774">
<edge COLOR="#808080"/>
</node>
<node TEXT="4. 节点划分" FOLDED="true" ID="ID_1515769558" CREATED="1589864175590" MODIFIED="1589864205304">
<edge COLOR="#808080"/>
<node TEXT="sklearn中的决策树通常使用Gini importance作为criterion" ID="ID_1593771241" CREATED="1588760228969" MODIFIED="1588760297768">
<edge COLOR="#808080"/>
</node>
<node TEXT="xgboost中使用了其定义的 structure-score作为criterion" ID="ID_1619903967" CREATED="1588762318681" MODIFIED="1588762347690">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="lightGBM实现" FOLDED="true" ID="ID_1346208841" CREATED="1588762362554" MODIFIED="1588825178554">
<edge COLOR="#808080"/>
<node TEXT="模型训练速度比XGboost快, 效果差不多" ID="ID_104572504" CREATED="1588762389455" MODIFIED="1588825178553">
<edge COLOR="#808080"/>
</node>
<node ID="ID_368560587" TREE_ID="ID_373392571">
<node ID="ID_196829347" TREE_ID="ID_230490970"/>
<node ID="ID_1725889303" TREE_ID="ID_490566903"/>
</node>
</node>
</node>
<node TEXT="应用" FOLDED="true" ID="ID_1173451234" CREATED="1588748153142" MODIFIED="1588748173132">
<edge COLOR="#808080"/>
<node TEXT="特征选择" FOLDED="true" ID="ID_846767339" CREATED="1588759944774" MODIFIED="1588760092260">
<edge COLOR="#808080"/>
<node TEXT="The importance 定义为: feature使评价指标(criterion)在所有节点上减少的总和" FOLDED="true" ID="ID_378882983" CREATED="1588760116904" MODIFIED="1588760218180">
<edge COLOR="#808080"/>
<node TEXT="sklearn中的决策树通常使用Gini importance作为criterion" ID="ID_444007721" CREATED="1588760228969" MODIFIED="1588760297768">
<edge COLOR="#808080"/>
</node>
<node TEXT="xgboost中使用了其定义的 structure-score作为criterion" ID="ID_505065198" CREATED="1588762318681" MODIFIED="1588762347690">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="特征组合" FOLDED="true" ID="ID_267989967" CREATED="1588760342041" MODIFIED="1588760347960">
<edge COLOR="#808080"/>
<node TEXT="经典应用" FOLDED="true" ID="ID_131484727" CREATED="1588760415633" MODIFIED="1588760433762">
<edge COLOR="#808080"/>
<node TEXT="GBDT+FM" ID="ID_1192714132" CREATED="1588760422968" MODIFIED="1588760433762">
<edge COLOR="#808080"/>
</node>
<node TEXT="GBDT+LR" ID="ID_500849303" CREATED="1588760426451" MODIFIED="1588760433761">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="原理" FOLDED="true" ID="ID_682427926" CREATED="1588760790179" MODIFIED="1588760802252">
<edge COLOR="#808080"/>
<node TEXT="gbdt-feature-compose-1.png" ID="ID_1502892332" CREATED="1588760643914" MODIFIED="1588760667267">
<hook URI="Machine-Learning_files/gbdt-feature-compose-1.png" SIZE="0.795756" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
<node TEXT="gbdt-feature-compose-2.png" ID="ID_1770482229" CREATED="1588760656839" MODIFIED="1588760667267">
<hook URI="Machine-Learning_files/gbdt-feature-compose-2.png" SIZE="0.7751938" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="" ID="ID_76850285" CREATED="1588825134345" MODIFIED="1588825134345">
<hook NAME="FirstGroupNode"/>
</node>
<node TEXT="分类任务" ID="ID_1398004530" CREATED="1588756701027" MODIFIED="1588756726607">
<edge COLOR="#808080"/>
</node>
<node TEXT="回归" ID="ID_340329153" CREATED="1588756719466" MODIFIED="1588756726606">
<edge COLOR="#808080"/>
</node>
<node TEXT="ranking" ID="ID_1950014251" CREATED="1588759935864" MODIFIED="1588760092261">
<edge COLOR="#808080"/>
</node>
<node TEXT="" ID="ID_385600729" CREATED="1588825134343" MODIFIED="1588825134345">
<hook NAME="SummaryNode"/>
<hook NAME="AlwaysUnfoldedNode"/>
<node TEXT="根据目标定义 loss function $L$" ID="ID_837649140" CREATED="1588825134346" MODIFIED="1588825531616" FORMAT="latexPatternFormat">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="现存问题" FOLDED="true" ID="ID_786908863" CREATED="1589864245678" MODIFIED="1589864279756">
<edge COLOR="#808080"/>
<node TEXT="预测时模型稳定性低" FOLDED="true" ID="ID_552826516" CREATED="1589864262556" MODIFIED="1589864279756">
<edge COLOR="#808080"/>
<node TEXT="对初始参数敏感" ID="ID_1431596950" CREATED="1589864288162" MODIFIED="1589864357775">
<edge COLOR="#808080"/>
</node>
<node TEXT="对训练样本的变动敏感" ID="ID_1096629010" CREATED="1589864303657" MODIFIED="1589864357775">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
</node>
</node>
</node>
<node TEXT="Clustering" FOLDED="true" ID="ID_347535302" CREATED="1565622997672" MODIFIED="1584717762641">
<edge COLOR="#808080"/>
<node TEXT="Algorithms" FOLDED="true" ID="ID_1997215111" CREATED="1565625266317" MODIFIED="1584717762641">
<edge COLOR="#808080"/>
<node TEXT="DBSCAN" ID="ID_588035025" CREATED="1565625266317" MODIFIED="1584717762641">
<edge COLOR="#808080"/>
</node>
<node TEXT="Hierarchical Clustering" FOLDED="true" ID="ID_77812109" CREATED="1565625266317" MODIFIED="1584717762641">
<edge COLOR="#808080"/>
<node TEXT="Linkage" FOLDED="true" ID="ID_1756170827" CREATED="1565625266317" MODIFIED="1584717762641">
<edge COLOR="#808080"/>
<node TEXT="complete" ID="ID_1208092371" CREATED="1565625266317" MODIFIED="1584717762641">
<edge COLOR="#808080"/>
</node>
<node TEXT="single" ID="ID_1972160937" CREATED="1565625266317" MODIFIED="1584717762641">
<edge COLOR="#808080"/>
</node>
<node TEXT="average" ID="ID_1509886615" CREATED="1565625266317" MODIFIED="1584717762641">
<edge COLOR="#808080"/>
</node>
<node TEXT="centroid" ID="ID_1601041285" CREATED="1565625266317" MODIFIED="1584717762641">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Hierarchical Agglomerative Clustering (HAC)" FOLDED="true" ID="ID_555380159" CREATED="1587101822337" MODIFIED="1587101997632">
<edge COLOR="#808080"/>
<node TEXT="HAC-alg.png" ID="ID_600484901" CREATED="1587101959359" MODIFIED="1587101997635">
<hook URI="Machine-Learning_files/HAC-alg.png" SIZE="1.0" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="k-Means" FOLDED="true" ID="ID_634270328" CREATED="1565625266317" MODIFIED="1584717762641">
<edge COLOR="#808080"/>
<node TEXT="How many clusters do we select?" ID="ID_1435413324" CREATED="1565625266317" MODIFIED="1584717762641">
<edge COLOR="#808080"/>
</node>
<node TEXT="K-means-alg.png" ID="ID_1253007596" CREATED="1587100987804" MODIFIED="1587100987804">
<hook URI="Machine-Learning_files/K-means-alg.png" SIZE="0.74349445" NAME="ExternalObject"/>
</node>
</node>
<node TEXT="k-Medians" ID="ID_1837174793" CREATED="1565625266317" MODIFIED="1584717762642">
<edge COLOR="#808080"/>
</node>
<node TEXT="Fuzzy C-Means" ID="ID_1174809125" CREATED="1565625266317" MODIFIED="1584717762642">
<edge COLOR="#808080"/>
</node>
<node TEXT="Self-Organising Maps (SOM)" ID="ID_734207299" CREATED="1565625266317" MODIFIED="1584717762642">
<edge COLOR="#808080"/>
</node>
<node TEXT="Gaussian-Mixture-Model" FOLDED="true" ID="ID_1673710128" CREATED="1570847894017" MODIFIED="1584717762642">
<edge COLOR="#808080"/>
<node TEXT="gaussiam-mixture-model-alg.png" ID="ID_744768189" CREATED="1592055412280" MODIFIED="1592055479043">
<hook URI="Machine-Learning_files/gaussiam-mixture-model-alg.png" SIZE="0.75" NAME="ExternalObject"/>
<edge COLOR="#808080"/>
</node>
<node TEXT="求解算法: EM algorithm" ID="ID_1590156758" CREATED="1570847952635" MODIFIED="1592055470970" LINK="https://weirping.github.io/blog/EM-algorithm.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="一种 生成模型" ID="ID_1207014062" CREATED="1592055489982" MODIFIED="1592055631415" LINK="#ID_1436859427">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Spectral clustering" ID="ID_1885552005" CREATED="1587134802455" MODIFIED="1587135315770">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Validation" FOLDED="true" ID="ID_301753569" CREATED="1565625266317" MODIFIED="1584717762642">
<edge COLOR="#808080"/>
<node TEXT="Data Structure Metrics" FOLDED="true" ID="ID_205978568" CREATED="1565625266317" MODIFIED="1584717762642">
<edge COLOR="#808080"/>
<node TEXT="Dunn Index" ID="ID_790042298" CREATED="1565625266317" MODIFIED="1584717762642">
<edge COLOR="#808080"/>
</node>
<node TEXT="Connectivity" ID="ID_589536022" CREATED="1565625266317" MODIFIED="1584717762642">
<edge COLOR="#808080"/>
</node>
<node TEXT="Silhouette Width" ID="ID_324026588" CREATED="1565625266317" MODIFIED="1584717762642">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Stability Metrics" FOLDED="true" ID="ID_860686444" CREATED="1565625266317" MODIFIED="1584717762642">
<edge COLOR="#808080"/>
<node TEXT="Non-overlap APN" ID="ID_1880395625" CREATED="1565625266317" MODIFIED="1584717762642">
<edge COLOR="#808080"/>
</node>
<node TEXT="Average Distance AD" ID="ID_1582534659" CREATED="1565625266317" MODIFIED="1584717762651">
<edge COLOR="#808080"/>
</node>
<node TEXT="Figure of Merit FOM" ID="ID_1739971471" CREATED="1565625266317" MODIFIED="1584717762651">
<edge COLOR="#808080"/>
</node>
<node TEXT="Average Distance Between Means ADM" ID="ID_1332989382" CREATED="1565625266317" MODIFIED="1584717762651">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
<node TEXT="Series analysis" FOLDED="true" ID="ID_849123291" CREATED="1566487640198" MODIFIED="1584717762652">
<edge COLOR="#808080"/>
<node TEXT="Hidden Markov Models(HMM)" ID="ID_810892703" CREATED="1566487645666" MODIFIED="1584717762652" LINK="https://weirping.github.io/blog/HMM.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="n-gram" ID="ID_241754336" CREATED="1566574466004" MODIFIED="1584717762652" LINK="https://weirping.github.io/blog/n-gram-model.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="Maximum Entropy Model" ID="ID_1017835365" CREATED="1566575367660" MODIFIED="1584717762652" LINK="https://weirping.github.io/blog/Maximum-Entropy-Model.html">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Topic Model" FOLDED="true" ID="ID_755349175" CREATED="1566834020133" MODIFIED="1584717762652">
<edge COLOR="#808080"/>
<node TEXT="Latent Dirichlet allocation(LDA)" ID="ID_1189621183" CREATED="1566834035498" MODIFIED="1587103534631">
<edge COLOR="#808080"/>
</node>
<node TEXT="PLSI" ID="ID_1353886122" CREATED="1566834039819" MODIFIED="1584717762652">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Toolkit" POSITION="right" ID="ID_1659483563" CREATED="1565937397861" MODIFIED="1584717762673">
<edge COLOR="#808080"/>
<node TEXT="Numpy" ID="ID_559353990" CREATED="1565937411266" MODIFIED="1584717762673">
<edge COLOR="#808080"/>
</node>
<node TEXT="Pandas" ID="ID_787921348" CREATED="1565937417305" MODIFIED="1584717762673">
<edge COLOR="#808080"/>
</node>
<node TEXT="Sklearn" FOLDED="true" ID="ID_1825490415" CREATED="1565937420354" MODIFIED="1584717762673">
<edge COLOR="#808080"/>
<node TEXT="OneHotEncoder in Sklearn" ID="ID_849107871" CREATED="1566054767956" MODIFIED="1584717762673" LINK="https://weirping.github.io/blog/OneHotEncoder-in-Sklearn.html">
<edge COLOR="#808080"/>
</node>
<node TEXT="Hyperparameter Tuning" ID="ID_1138872453" CREATED="1566579627433" MODIFIED="1584717762674" LINK="https://weirping.github.io/blog/Hyperparameter-Tuning-in-Sklearn.html">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Tensorflow" ID="ID_1959349199" CREATED="1565937436364" MODIFIED="1584717762674">
<edge COLOR="#808080"/>
</node>
<node TEXT="Xgboost" ID="ID_994376312" CREATED="1566489933677" MODIFIED="1584717762674" LINK="https://weirping.github.io/blog/xgboost.html">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Process" LOCALIZED_STYLE_REF="AutomaticLayout.level,1" POSITION="right" ID="ID_1305670503" CREATED="1564977431378" MODIFIED="1584717762674">
<edge COLOR="#808080"/>
<node TEXT="Question" FOLDED="true" ID="ID_1791001204" CREATED="1565625834318" MODIFIED="1584717762674">
<edge COLOR="#808080"/>
<node TEXT="Classification - Is this A or B?" ID="ID_1664382026" CREATED="1565625834318" MODIFIED="1584717762674">
<edge COLOR="#808080"/>
</node>
<node TEXT="Regression - How much, or how many of these?" ID="ID_1618373717" CREATED="1565625834318" MODIFIED="1584717762674">
<edge COLOR="#808080"/>
</node>
<node TEXT="Anomaly Detection - Is this anomalous?" ID="ID_1761619324" CREATED="1565625834318" MODIFIED="1584717762674">
<edge COLOR="#808080"/>
</node>
<node TEXT="Clustering - How can these elements be grouped?" ID="ID_1573125256" CREATED="1565625834318" MODIFIED="1584717762674">
<edge COLOR="#808080"/>
</node>
<node TEXT="Reinforcement Learning - What should I do now?" ID="ID_587000097" CREATED="1565625834318" MODIFIED="1584717762675">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Data Precessing" FOLDED="true" ID="ID_1021447701" CREATED="1565625957042" MODIFIED="1584717762675" LINK="#ID_1777714941">
<edge COLOR="#808080"/>
<node TEXT="Collect" ID="ID_1350357321" CREATED="1565625957042" MODIFIED="1584717762675">
<edge COLOR="#808080"/>
</node>
<node TEXT="Explore" ID="ID_1287567045" CREATED="1565625957042" MODIFIED="1584717762675">
<edge COLOR="#808080"/>
</node>
<node TEXT="Clean Features" ID="ID_1606219012" CREATED="1565625957042" MODIFIED="1584717762675">
<edge COLOR="#808080"/>
</node>
<node TEXT="Impute Features" ID="ID_667641039" CREATED="1565625957042" MODIFIED="1584717762675">
<edge COLOR="#808080"/>
</node>
<node TEXT="Engineer Features" ID="ID_865899715" CREATED="1565625957042" MODIFIED="1584717762675">
<edge COLOR="#808080"/>
</node>
<node TEXT="Select Features" ID="ID_963960256" CREATED="1565625957042" MODIFIED="1584717762675">
<edge COLOR="#808080"/>
</node>
<node TEXT="Encode Features" ID="ID_435101728" CREATED="1565625957042" MODIFIED="1584717762675">
<edge COLOR="#808080"/>
</node>
<node TEXT="Build Datasets" ID="ID_771786815" CREATED="1565625957042" MODIFIED="1584717762676">
<edge COLOR="#808080"/>
</node>
</node>
<node TEXT="Model Selection" FOLDED="true" ID="ID_199946267" CREATED="1565626067182" MODIFIED="1584717762676">
<edge COLOR="#808080"/>
<node TEXT="Select Algorithm based on question and data available" ID="ID_1084618403" CREATED="1565626067182" MODIFIED="1584717762676">
<edge COLOR="#808080"/>
</node>
<node TEXT="Choosing-the-right-estimator-in-scikit-learn.png" ID="ID_1728043440" CREATED="1587101392152" MODIFIED="1587101392157">
<hook URI="Machine-Learning_files/Choosing-the-right-estimator-in-scikit-learn.png" SIZE="0.42704627" NAME="ExternalObject"/>
</node>
</node>
<node TEXT="Tuning" FOLDED="true" ID="ID_1360527308" CREATED="1565626276613" MODIFIED="1584717762677" LINK="https://weirping.github.io/blog/Hyperparameter-Tuning-in-Sklearn.html">
<edge COLOR="#808080"/>
<node TEXT="Cross Validation" ID="ID_920610574" CREATED="1566051815331" MODIFIED="1584717762677">
<edge COLOR="#808080"/>
</node>
<node TEXT="Grid Search" ID="ID_888222069" CREATED="1566051829345" MODIFIED="1584717762677">
<edge COLOR="#808080"/>
</node>
<node TEXT="Random Search" ID="ID_1895612006" CREATED="1566051847248" MODIFIED="1584717762677">
<edge COLOR="#808080"/>
</node>
<node TEXT="validation curves" FOLDED="true" ID="ID_1513204368" CREATED="1566051886934" MODIFIED="1584717762677">
<edge COLOR="#808080"/>
<node TEXT="validation curves可以理解为一张图表，其纵坐标为模型performance (score) ，行坐标为模型的一个参数。其表示的是随着参数的变化，模型在训练集和测试集上达到的效果。" ID="ID_239351658" CREATED="1566051926562" MODIFIED="1584717762677">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Results and Benchmarking" FOLDED="true" ID="ID_1736895389" CREATED="1565626397229" MODIFIED="1584717762678" LINK="#ID_55335660">
<edge COLOR="#808080"/>
<node TEXT="Analyse the performance of each algorithms and discuss results." FOLDED="true" ID="ID_1678513956" CREATED="1565626397229" MODIFIED="1584717762679">
<edge COLOR="#808080"/>
<node TEXT="matric - Are the results good enough for production?" ID="ID_790774823" CREATED="1565626397229" MODIFIED="1584717762679">
<edge COLOR="#808080"/>
</node>
<node TEXT="time - Is the ML algorithm training and inference completing in a reasonable timeframe?" ID="ID_967134152" CREATED="1565626397229" MODIFIED="1584717762680">
<edge COLOR="#808080"/>
</node>
</node>
</node>
<node TEXT="Deployment and Operationalisation" FOLDED="true" ID="ID_558003427" CREATED="1565626562979" MODIFIED="1584717762681">
<edge COLOR="#808080"/>
<node TEXT="real time - How can feature manipulation be done for training and inference in real-time?" ID="ID_575938834" CREATED="1565626562979" MODIFIED="1584717762681">
<edge COLOR="#808080"/>
</node>
<node TEXT="How to make sure that the algorithm is retrained periodically and deployed into production?" ID="ID_471279578" CREATED="1565626562979" MODIFIED="1584717762683">
<edge COLOR="#808080"/>
</node>
<node TEXT="How will the ML algorithms be integrated with other systems?" ID="ID_1256510053" CREATED="1565626562979" MODIFIED="1584717762684">
<edge COLOR="#808080"/>
</node>
</node>
</node>
</node>
</map>
